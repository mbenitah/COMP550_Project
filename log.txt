================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', '[MASK]', 'could', 'be', '.', 'just', 'listen', 'to', 'what', 'party', 'leaders', 'said', 'following', 'the', 'election', 'of', 'the', 'speaker', 'of', 'the', 'house', 'of', '[MASK]', '.', 'their', 'speeches', 'were', 'rep', '##lete', 'with', 'references', 'to', 'the', 'c', '@', '-', '@', 'word', '[MASK]', 'collaboration', '.', 'over', 'and', 'over', ',', 'canadians', 'heard', 'their', 'political', 'leaders', 'promise', '[MASK]', 'have', 'received', 'the', '[MASK]', 'they', 'were', 'sent', 'in', 'the', '[MASK]', ':', 'voters', 'want', 'them', 'to', 'work', 'together', 'for', '[MASK]', 'better', '[MASK]', 'of', 'our', 'country', '.', '[SEP]']
{5: 'it', 42: ':', 74: 'the', 76: '##ment', 26: 'commons', 55: 'to', 59: 'message', 65: 'election'}
loss:  19.38413429260254
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 75.00%
Average score: 13.36
{'it': 'it', ':': 'of', 'the': 'the', '##ment': '##ment', 'commons': 'commons', 'to': 'to', 'message': 'message', 'election': 'mail'}
{'it': tensor(10.4313), ':': tensor(11.1310), 'the': tensor(14.9592), '##ment': tensor(13.1147), 'commons': tensor(20.5888), 'to': tensor(13.8943), 'message': tensor(14.0431), 'election': tensor(8.7467)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', 'be', '.', '[MASK]', 'listen', 'to', 'what', '[MASK]', 'leaders', 'said', '[MASK]', 'the', '[MASK]', 'of', 'the', 'speaker', 'of', 'the', 'house', 'of', 'commons', '.', 'their', 'speeches', 'were', 'rep', '##lete', 'with', 'references', 'to', 'the', 'c', '[MASK]', '-', '[MASK]', 'word', ':', 'collaboration', '.', 'over', 'and', 'over', ',', '[MASK]', 'heard', 'their', 'political', 'leaders', 'promise', 'to', 'have', 'received', 'the', '[MASK]', 'they', 'were', 'sent', 'in', 'the', 'election', ':', 'voters', 'want', 'them', 'to', 'work', 'together', 'for', 'the', 'better', '##ment', 'of', 'our', 'country', '.', '[SEP]']
{40: '@', 9: 'just', 18: 'election', 59: 'message', 13: 'party', 49: 'canadians', 16: 'following', 38: '@'}
loss:  17.063404083251953
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 12.50%
Average score: 10.92
{'@': '##zar', 'just': 'people', 'election': 'office', 'message': 'message', 'party': 'the', 'canadians': 'they', 'following': 'in'}
{'@': tensor(10.7993), 'just': tensor(11.2211), 'election': tensor(10.7433), 'message': tensor(12.5784), 'party': tensor(10.4395), 'canadians': tensor(10.5107), 'following': tensor(10.1597)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', 'be', '.', 'just', 'listen', '[MASK]', 'what', 'party', 'leaders', 'said', 'following', 'the', 'election', 'of', 'the', 'speaker', 'of', 'the', 'house', 'of', 'commons', '.', '[MASK]', 'speeches', 'were', 'rep', '##lete', 'with', 'references', 'to', 'the', 'c', '@', '-', '@', 'word', ':', 'collaboration', '.', 'over', '[MASK]', '[MASK]', ',', 'canadians', 'heard', 'their', 'political', 'leaders', 'promise', 'to', 'have', 'received', 'the', 'message', 'they', 'were', 'sent', 'in', 'the', 'election', '[MASK]', '[MASK]', 'want', 'them', 'to', 'work', 'together', 'for', '[MASK]', 'better', '##ment', 'of', 'our', 'country', '[MASK]', '[SEP]']
{80: '.', 74: 'the', 67: 'voters', 66: ':', 47: 'over', 46: 'and', 28: 'their', 11: 'to'}
loss:  21.50371742248535
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 37.50%
Average score: 13.50
{'.': '.', 'the': 'the', 'voters': 'i', ':': 'and', 'over': 'time', 'and': 'the', 'their': 'the', 'to': 'to'}
{'.': tensor(18.3338), 'the': tensor(16.9452), 'voters': tensor(12.8175), ':': tensor(11.3187), 'over': tensor(10.7446), 'and': tensor(12.1151), 'their': tensor(10.6536), 'to': tensor(15.1038)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', 'be', '.', 'just', 'listen', 'to', 'what', 'party', 'leaders', 'said', 'following', 'the', 'election', 'of', 'the', 'speaker', 'of', 'the', 'house', 'of', 'commons', '.', 'their', 'speeches', 'were', 'rep', '##lete', 'with', 'references', 'to', 'the', 'c', '@', '-', '@', 'word', ':', 'collaboration', '.', 'over', 'and', 'over', '[MASK]', 'canadians', '[MASK]', 'their', 'political', '[MASK]', 'promise', 'to', 'have', 'received', 'the', '[MASK]', 'they', 'were', 'sent', '[MASK]', '[MASK]', 'election', ':', '[MASK]', 'want', 'them', 'to', '[MASK]', 'together', 'for', 'the', 'better', '##ment', 'of', 'our', 'country', '.', '[SEP]']
{53: 'leaders', 63: 'in', 67: 'voters', 48: ',', 64: 'the', 71: 'work', 59: 'message', 50: 'heard'}
loss:  18.39238929748535
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 62.50%
Average score: 11.88
{'leaders': 'leaders', 'in': 'after', 'voters': 'we', ',': ',', 'the': 'the', 'work': 'work', 'message': 'message', 'heard': 'made'}
{'leaders': tensor(12.5397), 'in': tensor(11.1177), 'voters': tensor(15.3341), ',': tensor(10.5111), 'the': tensor(10.6779), 'work': tensor(14.5710), 'message': tensor(10.4302), 'heard': tensor(9.8775)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', '[MASK]', '[MASK]', 'just', 'listen', 'to', 'what', 'party', '[MASK]', 'said', 'following', 'the', 'election', '[MASK]', 'the', 'speaker', 'of', 'the', 'house', 'of', 'commons', '.', 'their', 'speeches', 'were', 'rep', '##lete', 'with', 'references', 'to', 'the', 'c', '[MASK]', '-', '@', 'word', ':', 'collaboration', '.', 'over', 'and', 'over', '[MASK]', 'canadians', 'heard', 'their', 'political', 'leaders', 'promise', 'to', 'have', 'received', 'the', '[MASK]', '[MASK]', 'were', 'sent', 'in', 'the', 'election', ':', 'voters', 'want', 'them', 'to', 'work', 'together', 'for', 'the', 'better', '##ment', 'of', 'our', 'country', '.', '[SEP]']
{60: 'they', 48: ',', 59: 'message', 14: 'leaders', 19: 'of', 7: 'be', 8: '.', 38: '@'}
loss:  17.8659725189209
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 75.00%
Average score: 11.33
{'they': 'they', ',': ',', 'message': 'message', 'leaders': 'leaders', 'of': 'of', 'be': 'be', '.': 'be', '@': '##g'}
{'they': tensor(13.7267), ',': tensor(10.7025), 'message': tensor(12.1056), 'leaders': tensor(11.0269), 'of': tensor(12.7367), 'be': tensor(11.0518), '.': tensor(9.4326), '@': tensor(9.8345)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', 'the', '[MASK]', 'canadians', 'is', 'widely', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', 'executive', 'meng', 'wan', '##zhou', 'on', 'dec', '.', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '[MASK]', 'technologies', 'was', 'arrested', 'in', 'vancouver', 'at', 'the', 'request', 'of', '[MASK]', 'united', 'states', ',', '[MASK]', 'wants', 'her', '[MASK]', '##dit', '##ed', 'to', 'face', 'fraud', 'charges', 'for', 'allegedly', 'violating', '[MASK]', 'against', '[MASK]', '.', '[SEP]']
{71: 'iran', 56: 'which', 42: '##wei', 69: 'sanctions', 59: 'extra', 5: 'two', 52: 'the'}
loss:  20.03324317932129
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 85.71%
Average score: 14.20
{'iran': 'china', 'which': 'which', '##wei': '##wei', 'sanctions': 'sanctions', 'extra': 'extra', 'two': 'two', 'the': 'the'}
{'iran': tensor(10.8192), 'which': tensor(13.6243), '##wei': tensor(16.1015), 'sanctions': tensor(13.1053), 'extra': tensor(17.7511), 'two': tensor(12.3287), 'the': tensor(15.6996)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', 'the', '[MASK]', 'canadians', 'is', '[MASK]', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', '[MASK]', 'meng', '[MASK]', '##zhou', 'on', 'dec', '.', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '##wei', 'technologies', 'was', 'arrested', 'in', 'vancouver', 'at', 'the', 'request', 'of', 'the', 'united', 'states', ',', 'which', 'wants', '[MASK]', 'extra', '##dit', '##ed', 'to', 'face', '[MASK]', 'charges', 'for', 'allegedly', 'violating', '[MASK]', 'against', 'iran', '.', '[SEP]']
{58: 'her', 26: 'wan', 64: 'fraud', 8: 'widely', 24: 'executive', 69: 'sanctions', 5: 'two'}
loss:  17.7369327545166
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 42.86%
Average score: 12.34
{'her': 'him', 'wan': 'yan', 'fraud': 'criminal', 'widely': 'widely', 'executive': 'ceo', 'sanctions': 'sanctions', 'two': 'two'}
{'her': tensor(13.9189), 'wan': tensor(7.9687), 'fraud': tensor(10.2943), 'widely': tensor(13.0516), 'executive': tensor(10.2185), 'sanctions': tensor(18.3855), 'two': tensor(12.5480)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', 'the', 'two', 'canadians', '[MASK]', 'widely', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', 'executive', 'meng', 'wan', '##zhou', 'on', 'dec', '.', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '##wei', 'technologies', '[MASK]', 'arrested', 'in', 'vancouver', 'at', 'the', 'request', '[MASK]', 'the', '[MASK]', 'states', ',', 'which', 'wants', 'her', 'extra', '##dit', '##ed', 'to', '[MASK]', 'fraud', 'charges', 'for', 'allegedly', 'violating', 'sanctions', '[MASK]', '[MASK]', '.', '[SEP]']
{7: 'is', 63: 'face', 70: 'against', 53: 'united', 51: 'of', 44: 'was', 71: 'iran'}
loss:  20.590618133544922
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 71.43%
Average score: 14.64
{'is': 'is', 'face': 'face', 'against': 'on', 'united': 'united', 'of': 'of', 'was': 'was', 'iran': 'china'}
{'is': tensor(14.8417), 'face': tensor(13.6831), 'against': tensor(10.1679), 'united': tensor(19.4235), 'of': tensor(16.2356), 'was': tensor(14.7960), 'iran': tensor(13.3019)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'detention', 'of', 'the', '[MASK]', '[MASK]', 'is', 'widely', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '[MASK]', '-', '@', 'tech', 'executive', 'meng', 'wan', '##zhou', 'on', 'dec', '.', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '##wei', 'technologies', 'was', 'arrested', 'in', 'vancouver', 'at', 'the', '[MASK]', 'of', 'the', 'united', 'states', ',', 'which', 'wants', 'her', 'extra', '##dit', '##ed', 'to', 'face', '[MASK]', 'charges', 'for', 'allegedly', 'violating', '[MASK]', 'against', 'iran', '.', '[SEP]']
{64: 'fraud', 5: 'two', 6: 'canadians', 20: '@', 69: 'sanctions', 50: 'request', 1: 'the'}
loss:  17.8195743560791
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 42.86%
Average score: 12.45
{'fraud': 'criminal', 'two': 'canadian', 'canadians': 'suspects', '@': 'tech', 'sanctions': 'sanctions', 'request': 'request', 'the': 'the'}
{'fraud': tensor(10.5050), 'two': tensor(7.4249), 'canadians': tensor(8.9808), '@': tensor(12.6745), 'sanctions': tensor(18.2609), 'request': tensor(16.9396), 'the': tensor(12.3879)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', 'the', '[MASK]', 'canadians', 'is', 'widely', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', 'executive', 'meng', 'wan', '##zhou', 'on', 'dec', '.', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', '[MASK]', 'of', 'hua', '##wei', '[MASK]', 'was', 'arrested', 'in', 'vancouver', '[MASK]', 'the', 'request', '[MASK]', 'the', '[MASK]', 'states', ',', 'which', 'wants', 'her', 'extra', '##dit', '##ed', '[MASK]', 'face', 'fraud', 'charges', 'for', 'allegedly', 'violating', 'sanctions', 'against', 'iran', '.', '[SEP]']
{62: 'to', 5: 'two', 53: 'united', 43: 'technologies', 39: 'officer', 48: 'at', 51: 'of'}
loss:  21.075796127319336
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 85.71%
Average score: 14.97
{'to': 'to', 'two': 'two', 'united': 'united', 'technologies': 'taiwan', 'officer': 'officer', 'at': 'at', 'of': 'of'}
{'to': tensor(14.9184), 'two': tensor(12.4007), 'united': tensor(19.5163), 'technologies': tensor(9.9667), 'officer': tensor(17.9560), 'at': tensor(14.0524), 'of': tensor(15.9541)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'spin', '##ney', 'voiced', 'and', 'operated', 'the', 'two', 'popular', 'mu', '[MASK]', '##s', '[MASK]', 'nearly', '50', 'years', 'and', 'performed', 'them', 'almost', 'exclusively', 'into', 'his', '80s', 'on', '[MASK]', 'pbs', 'kids', '[MASK]', 'television', 'show', 'that', 'later', 'moved', '[MASK]', 'hbo', '.', 'he', 'retired', 'from', 'vo', '##icing', 'big', 'bird', 'last', 'year', '[MASK]', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '[MASK]', '##t', 'the', 'frog', ',', 'took', 'over', '.', '[MASK]', 'i', "'", 'll', 'always', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', '[MASK]', 'in', '2014', '.', 'the', 'longtime', 'puppet', '##eer', 'received', '[MASK]', 'star', 'on', 'the', 'hollywood', 'walk', '[MASK]', 'fame', 'in', '1994', '.', 'in', '2000', ',', 'he', 'received', '[MASK]', 'u', '.', 's', '.', 'library', 'of', 'congress', "'", 's', 'living', 'legend', 'award', ',', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{103: 'the', 57: '##rmi', 87: 'a', 65: '"', 34: 'to', 46: 'and', 12: 'for', 78: 'said', 28: "'", 25: 'the', 10: '##ppet', 93: 'of'}
loss:  23.363332748413086
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 91.67%
Average score: 17.44
{'the': 'a', '##rmi': '##rmi', 'a': 'a', '"': '"', 'to': 'to', 'and': 'and', 'for': 'for', 'said': 'said', "'": "'", '##ppet': '##ppet', 'of': 'of'}
{'the': tensor(13.5169), '##rmi': tensor(21.2859), 'a': tensor(16.3935), '"': tensor(20.1232), 'to': tensor(17.2429), 'and': tensor(13.6209), 'for': tensor(16.4631), 'said': tensor(16.1537), "'": tensor(11.7048), '##ppet': tensor(22.8724), 'of': tensor(22.5143)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'spin', '##ney', 'voiced', 'and', '[MASK]', 'the', 'two', 'popular', 'mu', '##ppet', '##s', 'for', 'nearly', '50', '[MASK]', 'and', 'performed', '[MASK]', 'almost', 'exclusively', 'into', 'his', '80s', 'on', 'the', 'pbs', 'kids', "'", 'television', 'show', 'that', 'later', 'moved', 'to', 'hbo', '.', 'he', 'retired', 'from', 'vo', '##icing', 'big', '[MASK]', 'last', 'year', 'and', '[MASK]', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '##rmi', '##t', 'the', 'frog', '[MASK]', 'took', 'over', '.', '[MASK]', 'i', "'", 'll', 'always', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', 'said', '[MASK]', '2014', '.', 'the', '[MASK]', 'puppet', '[MASK]', 'received', 'a', 'star', 'on', 'the', 'hollywood', 'walk', 'of', 'fame', 'in', '1994', '.', 'in', '2000', ',', 'he', 'received', 'the', 'u', '.', 's', '[MASK]', 'library', 'of', 'congress', "'", 's', 'living', 'legend', 'award', ',', 'in', 'recognition', 'of', '[MASK]', 'creative', 'contributions', '.', '[SEP]']
{65: '"', 61: ',', 5: 'operated', 43: 'bird', 120: 'his', 15: 'years', 18: 'them', 79: 'in', 47: 'his', 107: '.', 85: '##eer', 83: 'longtime'}
loss:  21.299020767211914
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 75.00%
Average score: 14.64
{'"': '"', ',': ',', 'operated': 'voiced', 'bird': 'brother', 'his': 'his', 'years': 'years', 'them': 'them', 'in': 'in', '.': '.', '##eer': '##eer', 'longtime': 'original'}
{'"': tensor(20.6478), ',': tensor(15.0379), 'operated': tensor(13.2738), 'bird': tensor(9.2195), 'his': tensor(12.6760), 'years': tensor(20.2786), 'them': tensor(13.8169), 'in': tensor(15.3006), '.': tensor(19.5227), '##eer': tensor(13.0596), 'longtime': tensor(8.1866)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'spin', '##ney', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'two', 'popular', 'mu', '##ppet', '##s', 'for', '[MASK]', '50', 'years', 'and', 'performed', 'them', 'almost', 'exclusively', '[MASK]', 'his', '80s', 'on', 'the', 'pbs', 'kids', "'", '[MASK]', 'show', 'that', 'later', 'moved', 'to', 'hbo', '.', 'he', 'retired', 'from', 'vo', '##icing', '[MASK]', 'bird', 'last', 'year', 'and', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '##rmi', '[MASK]', 'the', 'frog', ',', 'took', 'over', '.', '"', 'i', '[MASK]', 'll', 'always', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', 'said', 'in', '2014', '.', 'the', 'longtime', 'puppet', '##eer', 'received', 'a', 'star', 'on', 'the', 'hollywood', 'walk', 'of', 'fame', 'in', '1994', '.', 'in', '2000', ',', 'he', 'received', 'the', 'u', '.', 's', '[MASK]', '[MASK]', 'of', 'congress', "'", 's', 'living', 'legend', 'award', ',', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{29: 'television', 42: 'big', 58: '##t', 13: 'nearly', 21: 'into', 108: 'library', 3: 'voiced', 6: 'the', 67: "'", 5: 'operated', 4: 'and', 107: '.'}
loss:  21.7624454498291
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 41.67%
Average score: 13.82
{'television': 'television', 'big': 'the', '##t': '##t', 'nearly': 'over', 'into': 'in', 'library': 'library', 'voiced': 'has', 'the': 'voiced', "'": "'", 'operated': 'had', 'and': 'also', '.': '.'}
{'television': tensor(11.4673), 'big': tensor(9.6223), '##t': tensor(22.4469), 'nearly': tensor(14.2583), 'into': tensor(13.7765), 'library': tensor(14.3904), 'voiced': tensor(9.9393), 'the': tensor(9.6044), "'": tensor(22.8051), 'operated': tensor(8.4409), 'and': tensor(8.7681), '.': tensor(20.3370)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'spin', '[MASK]', 'voiced', '[MASK]', 'operated', 'the', 'two', 'popular', 'mu', '##ppet', '##s', 'for', 'nearly', '50', 'years', 'and', 'performed', 'them', '[MASK]', '[MASK]', 'into', 'his', '80s', 'on', 'the', 'pbs', 'kids', "'", 'television', 'show', 'that', 'later', 'moved', 'to', 'hbo', '.', 'he', 'retired', 'from', 'vo', '##icing', 'big', 'bird', 'last', 'year', 'and', 'his', 'apprentice', ',', '[MASK]', 'vogel', ',', 'who', 'also', 'plays', 'ke', '##rmi', '##t', 'the', 'frog', ',', 'took', 'over', '.', '"', 'i', "'", 'll', 'always', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', 'said', 'in', '2014', '.', 'the', 'longtime', 'puppet', '[MASK]', 'received', 'a', 'star', 'on', 'the', '[MASK]', 'walk', '[MASK]', 'fame', 'in', '1994', '.', 'in', '2000', ',', '[MASK]', '[MASK]', 'the', 'u', '.', '[MASK]', '.', 'library', 'of', 'congress', "'", 's', 'living', 'legend', '[MASK]', ',', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{4: 'and', 102: 'received', 20: 'exclusively', 101: 'he', 2: '##ney', 106: 's', 91: 'hollywood', 50: 'matt', 85: '##eer', 93: 'of', 19: 'almost', 115: 'award'}
loss:  21.84245491027832
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 75.00%
Average score: 16.07
{'and': 'and', 'received': 'received', 'exclusively': 'well', 'he': 'he', '##ney': '##ney', 's': 's', 'hollywood': 'hollywood', 'matt': 'mike', '##eer': '##eer', 'of': 'of', 'almost': 'well', 'award': 'award'}
{'and': tensor(16.6544), 'received': tensor(16.7132), 'exclusively': tensor(13.7437), 'he': tensor(12.6975), '##ney': tensor(21.1311), 's': tensor(23.6391), 'hollywood': tensor(14.8578), 'matt': tensor(8.0711), '##eer': tensor(16.7226), 'of': tensor(21.7320), 'almost': tensor(11.8381), 'award': tensor(15.0803)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'spin', '##ney', 'voiced', '[MASK]', 'operated', 'the', 'two', 'popular', 'mu', '##ppet', '##s', 'for', 'nearly', '50', 'years', 'and', 'performed', '[MASK]', 'almost', '[MASK]', 'into', 'his', '80s', 'on', 'the', 'pbs', 'kids', "'", 'television', '[MASK]', 'that', 'later', 'moved', 'to', 'hbo', '.', 'he', 'retired', '[MASK]', 'vo', '##icing', '[MASK]', 'bird', 'last', 'year', 'and', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', '[MASK]', 'ke', '[MASK]', '##t', 'the', 'frog', ',', 'took', 'over', '.', '"', '[MASK]', "'", 'll', 'always', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', 'said', 'in', '2014', '.', 'the', 'longtime', 'puppet', '##eer', '[MASK]', 'a', 'star', 'on', 'the', 'hollywood', 'walk', 'of', 'fame', 'in', '1994', '.', 'in', '2000', ',', 'he', 'received', 'the', 'u', '.', 's', '.', 'library', 'of', 'congress', '[MASK]', 's', 'living', 'legend', 'award', '[MASK]', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{111: "'", 66: 'i', 39: 'from', 30: 'show', 57: '##rmi', 4: 'and', 86: 'received', 18: 'them', 55: 'plays', 20: 'exclusively', 116: ',', 42: 'big'}
loss:  20.902145385742188
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 66.67%
Average score: 14.65
{"'": "'", 'i': 'i', 'from': 'from', 'show': 'network', '##rmi': '##rmi', 'and': 'and', 'received': 'received', 'them': 'them', 'plays': 'voiced', 'exclusively': 'well', ',': ',', 'big': 'the'}
{"'": tensor(18.3148), 'i': tensor(14.2802), 'from': tensor(15.3841), 'show': tensor(11.7716), '##rmi': tensor(21.0884), 'and': tensor(16.4322), 'received': tensor(16.3287), 'them': tensor(12.9672), 'plays': tensor(15.5064), 'exclusively': tensor(10.7845), ',': tensor(13.6316), 'big': tensor(9.2506)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', '[MASK]', 'been', 'running', 'rampant', '.', 'in', '[MASK]', 'year', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", 's', '[MASK]', 'ann', '[MASK]', 'ho', '##rri', '##bilis', '[MASK]', 'of', '1992', ',', 'there', 'has', '[MASK]', 'speculation', 'about', 'who', "'", 's', 'been', 'making', 'the', 'decisions', 'at', 'buckingham', 'palace', ',', 'and', 'whether', 'the', '93', '[MASK]', '-', '@', 'year', '@', '-', '@', 'old', 'monarch', 'might', 'ultimately', '[MASK]', '[MASK]', 'back', 'from', 'her', 'role', 'in', 'the', '[MASK]', '@', '-', '@', 'too', '@', '-', '@', 'distant', 'future', '.', 'headlines', 'in', 'the', '[MASK]', '.', 'k', '.', 'in', 'recent', 'days', 'suggested', 'she', 'might', 'give', 'up', 'the', 'throne', 'in', 'two', 'years', '—', 'at', 'age', '95', '.', '[SEP]']
{75: 'not', 17: 'a', 67: 'step', 26: '"', 32: '"', 28: '##us', 38: 'been', 68: 'further', 89: 'u', 11: 'have', 56: '@'}
loss:  19.979358673095703
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 54.55%
Average score: 13.51
{'not': 'new', 'a': 'a', 'step': 'come', '"': 'act', '##us': '##us', 'been': 'been', 'further': 'come', 'u': 'u', 'have': 'have', '@': '@'}
{'not': tensor(6.2276), 'a': tensor(13.2118), 'step': tensor(12.1815), '"': tensor(10.2735), '##us': tensor(11.5178), 'been': tensor(18.5823), 'further': tensor(11.8137), 'u': tensor(24.0649), 'have': tensor(17.2966), '@': tensor(9.9760)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', 'have', 'been', 'running', 'rampant', '.', '[MASK]', 'a', 'year', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", 's', '[MASK]', 'ann', '##us', '[MASK]', '##rri', '##bilis', '"', 'of', '1992', ',', '[MASK]', 'has', 'been', 'speculation', 'about', 'who', "'", 's', 'been', '[MASK]', 'the', 'decisions', 'at', 'buckingham', 'palace', ',', 'and', 'whether', 'the', '93', '@', '-', '@', 'year', '@', '-', '@', 'old', 'monarch', 'might', 'ultimately', 'step', '[MASK]', 'back', 'from', 'her', '[MASK]', 'in', 'the', 'not', '@', '-', '@', 'too', '[MASK]', '[MASK]', '@', 'distant', 'future', '.', 'headlines', 'in', 'the', 'u', '[MASK]', 'k', '.', 'in', 'recent', 'days', 'suggested', 'she', 'might', 'give', 'up', 'the', 'throne', 'in', '[MASK]', 'years', '—', 'at', 'age', '95', '.', '[SEP]']
{26: '"', 72: 'role', 80: '@', 36: 'there', 104: 'two', 29: 'ho', 45: 'making', 68: 'further', 16: 'in', 81: '-', 90: '.'}
loss:  19.87590789794922
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 72.73%
Average score: 13.66
{'"': '"', 'role': 'throne', '@': '-', 'there': 'there', 'two': '90', 'ho': 'ho', 'making': 'making', 'further': 'further', 'in': 'in', '-': '-', '.': '.'}
{'"': tensor(17.1770), 'role': tensor(11.5426), '@': tensor(10.2206), 'there': tensor(19.1258), 'two': tensor(9.1488), 'ho': tensor(16.5631), 'making': tensor(15.4738), 'further': tensor(9.0897), 'in': tensor(11.7422), '-': tensor(9.4238), '.': tensor(20.7704)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', '[MASK]', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', '[MASK]', 'been', 'running', 'rampant', '.', 'in', 'a', 'year', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", 's', '"', 'ann', '[MASK]', 'ho', '##rri', '##bilis', '"', '[MASK]', '1992', '[MASK]', 'there', 'has', 'been', 'speculation', 'about', 'who', "'", 's', 'been', 'making', 'the', 'decisions', 'at', 'buckingham', '[MASK]', ',', 'and', 'whether', 'the', '93', '@', '-', '@', 'year', '@', '[MASK]', '@', 'old', 'monarch', '[MASK]', 'ultimately', 'step', 'further', 'back', 'from', 'her', 'role', 'in', 'the', 'not', '@', '-', '@', 'too', '@', '-', '@', '[MASK]', 'future', '.', 'headlines', 'in', 'the', 'u', '.', 'k', '.', 'in', 'recent', 'days', 'suggested', 'she', 'might', 'give', 'up', 'the', 'throne', 'in', 'two', 'years', '—', 'at', '[MASK]', '95', '.', '[SEP]']
{11: 'have', 33: 'of', 2: 'the', 1: 'amid', 61: '-', 28: '##us', 65: 'might', 50: 'palace', 35: ',', 83: 'distant', 108: 'age'}
loss:  19.81992530822754
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 54.55%
Average score: 12.59
{'have': 'have', 'of': 'in', 'the': 'the', 'amid': 'with', '-': '-', '##us': '##o', 'might': 'will', 'palace': 'palace', ',': ',', 'distant': 'old', 'age': 'age'}
{'have': tensor(17.0122), 'of': tensor(11.3104), 'the': tensor(11.0746), 'amid': tensor(11.9501), '-': tensor(9.2890), '##us': tensor(13.0184), 'might': tensor(14.5188), 'palace': tensor(18.4245), ',': tensor(13.3363), 'distant': tensor(7.0301), 'age': tensor(11.5339)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', '[MASK]', 'been', 'running', 'rampant', '.', 'in', 'a', '[MASK]', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", 's', '"', 'ann', '##us', 'ho', '##rri', '##bilis', '"', '[MASK]', '1992', ',', 'there', '[MASK]', 'been', '[MASK]', 'about', 'who', "'", 's', 'been', 'making', '[MASK]', 'decisions', 'at', '[MASK]', 'palace', ',', 'and', 'whether', '[MASK]', '93', '@', '-', '@', 'year', '[MASK]', '-', '@', 'old', 'monarch', 'might', 'ultimately', 'step', 'further', 'back', 'from', 'her', 'role', 'in', 'the', 'not', '@', '-', '@', 'too', '@', '-', '@', 'distant', 'future', '.', '[MASK]', 'in', 'the', 'u', '.', 'k', '.', 'in', 'recent', 'days', 'suggested', 'she', '[MASK]', 'give', 'up', 'the', 'throne', 'in', 'two', 'years', '—', 'at', 'age', '95', '.', '[SEP]']
{49: 'buckingham', 46: 'the', 33: 'of', 60: '@', 98: 'might', 54: 'the', 86: 'headlines', 37: 'has', 18: 'year', 11: 'have', 39: 'speculation'}
loss:  19.057632446289062
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 63.64%
Average score: 12.86
{'buckingham': 'the', 'the': 'the', 'of': 'in', '@': '@', 'might': 'might', 'headlines': 'news', 'has': 'has', 'year': 'story', 'have': 'have', 'speculation': 'speculation'}
{'buckingham': tensor(12.3158), 'the': tensor(10.3814), 'of': tensor(11.6067), '@': tensor(8.9848), 'might': tensor(15.0319), 'headlines': tensor(10.5819), 'has': tensor(17.5747), 'year': tensor(10.3377), 'have': tensor(17.0563), 'speculation': tensor(14.7692)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', 'have', 'been', 'running', 'rampant', '.', 'in', 'a', 'year', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", '[MASK]', '"', 'ann', '##us', 'ho', '[MASK]', '##bilis', '"', 'of', '1992', ',', '[MASK]', 'has', 'been', 'speculation', 'about', 'who', "'", 's', '[MASK]', 'making', 'the', 'decisions', 'at', 'buckingham', 'palace', ',', 'and', 'whether', 'the', '93', '@', '-', '@', '[MASK]', '@', '-', '@', 'old', 'monarch', 'might', 'ultimately', 'step', 'further', '[MASK]', 'from', 'her', 'role', 'in', '[MASK]', 'not', '@', '-', '@', 'too', '@', '-', '@', 'distant', 'future', '.', 'headlines', 'in', '[MASK]', 'u', '.', 'k', '.', 'in', 'recent', 'days', 'suggested', 'she', 'might', '[MASK]', 'up', '[MASK]', 'throne', 'in', 'two', 'years', '—', 'at', '[MASK]', '95', '.', '[SEP]']
{44: 'been', 25: 's', 59: 'year', 36: 'there', 69: 'back', 30: '##rri', 88: 'the', 108: 'age', 74: 'the', 101: 'the', 99: 'give'}
loss:  21.479761123657227
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 63.64%
Average score: 14.60
{'been': 'actually', 's': 's', 'year': '-', 'there': 'there', 'back': 'away', '##rri': '##rri', 'the': 'the', 'age': 'age', 'give': 'take'}
{'been': tensor(11.7710), 's': tensor(20.0242), 'year': tensor(9.0119), 'there': tensor(19.1585), 'back': tensor(14.1520), '##rri': tensor(18.0332), 'the': tensor(12.5355), 'age': tensor(12.1973), 'give': tensor(14.5220)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '##is', 'was', 'diagnosed', 'with', 'ho', '[MASK]', '##g', '##kin', "'", 's', 'disease', 'last', '[MASK]', 'and', 'has', 'had', 'to', 'undergo', 'some', 'pretty', 'uncomfortable', 'medical', '[MASK]', 'at', 'the', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '@', '-', '@', 'year', '@', '-', '@', 'old', 'has', 'had', '[MASK]', 'cat', '##het', '##er', 'inserted', 'into', 'a', '[MASK]', 'vein', 'and', 'threaded', 'through', 'to', 'her', 'heart', ',', 'in', 'order', '[MASK]', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '[MASK]', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', 'growth', 'was', '[MASK]', '[MASK]', 'her', 'inner', 'thigh', '.', '[SEP]']
{52: 'a', 12: '##d', 29: 'procedures', 88: 'discovered', 70: 'for', 78: '.', 59: 'peripheral', 19: 'april', 89: 'on'}
loss:  19.05512237548828
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 55.56%
Average score: 13.36
{'a': 'a', '##d': '##d', 'procedures': 'procedures', 'discovered': 'found', 'for': 'for', '.': '.', 'peripheral': 'small', 'april': 'year', 'on': 'in'}
{'a': tensor(13.7564), '##d': tensor(18.3227), 'procedures': tensor(13.8233), 'discovered': tensor(11.8303), 'for': tensor(14.3189), '.': tensor(11.8845), 'peripheral': tensor(9.9516), 'april': tensor(13.2448), 'on': tensor(13.1354)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '[MASK]', '##is', 'was', 'diagnosed', 'with', 'ho', '##d', '##g', '##kin', "'", 's', 'disease', 'last', 'april', 'and', 'has', 'had', 'to', 'undergo', 'some', 'pretty', 'uncomfortable', '[MASK]', 'procedures', 'at', 'the', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '[MASK]', 'the', 'nine', '@', '-', '@', 'year', '@', '-', '@', '[MASK]', 'has', '[MASK]', 'a', 'cat', '[MASK]', '##er', 'inserted', 'into', 'a', 'peripheral', 'vein', 'and', 'threaded', 'through', 'to', 'her', 'heart', ',', 'in', 'order', 'for', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '.', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', '[MASK]', 'was', '[MASK]', 'on', 'her', 'inner', 'thigh', '[MASK]', '[SEP]']
{88: 'discovered', 39: '.', 93: '.', 54: '##het', 28: 'medical', 6: '##nco', 49: 'old', 51: 'had', 86: 'growth'}
loss:  19.66964340209961
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 44.44%
Average score: 14.15
{'discovered': 'found', '.': '.', '##het': '##het', 'medical': 'surgical', '##nco': '##nc', 'old': 'patient', 'had': 'had', 'growth': 'tumor'}
{'discovered': tensor(12.8814), '.': tensor(18.7031), '##het': tensor(19.2092), 'medical': tensor(11.2361), '##nco': tensor(16.8246), 'old': tensor(9.0224), 'had': tensor(14.4481), 'growth': tensor(10.8531)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '[MASK]', 'was', 'diagnosed', 'with', 'ho', '##d', '##g', '##kin', '[MASK]', 's', 'disease', 'last', 'april', 'and', 'has', '[MASK]', 'to', 'undergo', '[MASK]', 'pretty', 'uncomfortable', 'medical', 'procedures', 'at', 'the', 'montreal', 'children', "'", 's', 'hospital', 'since', '[MASK]', '.', 'the', 'nine', '@', '-', '@', 'year', '@', '-', '@', 'old', 'has', 'had', 'a', 'cat', '##het', '[MASK]', 'inserted', 'into', 'a', 'peripheral', 'vein', 'and', 'threaded', 'through', 'to', 'her', '[MASK]', ',', 'in', '[MASK]', 'for', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '.', 'she', 'underwent', '[MASK]', 'bio', '##psy', 'when', 'a', 'growth', 'was', 'discovered', 'on', 'her', 'inner', 'thigh', '.', '[SEP]']
{66: 'heart', 69: 'order', 22: 'had', 55: '##er', 38: 'then', 15: "'", 25: 'some', 7: '##is', 81: 'a'}
loss:  21.688722610473633
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 77.78%
Average score: 16.13
{'heart': 'brain', 'order': 'preparation', 'had': 'had', '##er': '##er', 'then': 'then', "'": "'", 'some': 'some', '##is': '##is', 'a': 'a'}
{'heart': tensor(12.2805), 'order': tensor(14.9610), 'had': tensor(15.8351), '##er': tensor(23.8793), 'then': tensor(11.6943), "'": tensor(24.7148), 'some': tensor(16.3021), '##is': tensor(12.8986), 'a': tensor(12.5756)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '##is', 'was', 'diagnosed', 'with', 'ho', '##d', '##g', '##kin', "'", 's', 'disease', '[MASK]', '[MASK]', 'and', 'has', 'had', '[MASK]', 'undergo', 'some', 'pretty', '[MASK]', 'medical', 'procedures', 'at', 'the', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '@', '-', '[MASK]', 'year', '@', '-', '[MASK]', 'old', 'has', 'had', '[MASK]', 'cat', '##het', '##er', 'inserted', 'into', 'a', 'peripheral', 'vein', 'and', 'threaded', 'through', 'to', 'her', 'heart', ',', 'in', 'order', 'for', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '.', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', 'growth', '[MASK]', 'discovered', 'on', '[MASK]', 'inner', 'thigh', '.', '[SEP]']
{44: '@', 48: '@', 87: 'was', 19: 'april', 18: 'last', 90: 'her', 23: 'to', 52: 'a', 27: 'uncomfortable'}
loss:  19.19095230102539
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 44.44%
Average score: 12.76
{'@': 'year', 'was': 'was', 'april': '2004', 'last': 'in', 'her': 'her', 'to': 'to', 'a': 'a', 'uncomfortable': 'aggressive'}
{'@': tensor(9.5140), 'was': tensor(15.1837), 'april': tensor(11.0754), 'last': tensor(9.9012), 'her': tensor(16.3161), 'to': tensor(16.4336), 'a': tensor(14.2091), 'uncomfortable': tensor(9.4597)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '##is', 'was', 'diagnosed', 'with', 'ho', '##d', '##g', '##kin', "'", 's', '[MASK]', 'last', 'april', 'and', 'has', 'had', 'to', 'undergo', '[MASK]', 'pretty', 'uncomfortable', 'medical', '[MASK]', 'at', 'the', '[MASK]', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '@', '[MASK]', '@', 'year', '@', '-', '@', 'old', 'has', 'had', 'a', 'cat', '[MASK]', '##er', 'inserted', 'into', 'a', '[MASK]', 'vein', 'and', 'threaded', '[MASK]', 'to', 'her', 'heart', ',', 'in', 'order', 'for', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '.', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', 'growth', 'was', 'discovered', '[MASK]', 'her', 'inner', 'thigh', '.', '[SEP]']
{63: 'through', 32: 'montreal', 43: '-', 89: 'on', 29: 'procedures', 54: '##het', 25: 'some', 17: 'disease', 59: 'peripheral'}
loss:  18.610857009887695
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 33.33%
Average score: 12.88
{'through': 'it', 'montreal': 'local', '-': '-', 'on': 'in', 'procedures': 'procedure', '##het': '##het', 'some': 'a', 'disease': 'disease', 'peripheral': 'small'}
{'through': tensor(10.9886), 'montreal': tensor(9.0783), '-': tensor(8.5690), 'on': tensor(13.9525), 'procedures': tensor(13.1109), '##het': tensor(18.7584), 'some': tensor(14.9790), 'disease': tensor(16.6647), 'peripheral': tensor(9.7897)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '[MASK]', '-', '@', 'scale', 'study', 'looking', '[MASK]', '[MASK]', 'outcomes', 'across', 'age', 'groups', 'in', 'multiple', 'my', '##elo', '##ma', 'patients', 'found', 'similar', '[MASK]', 'of', 'non', '##rel', '##ap', '##se', 'mortality', ',', 're', '##la', '##pse', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', 'survival', ',', 'and', '[MASK]', 'survival', 'between', 'patients', 'who', 'were', '[MASK]', '70', 'years', 'and', 'older', 'and', 'those', 'who', 'were', 'aged', '60', '@', '-', '@', '69', 'years', '.', '[SEP]']
{9: 'at', 51: 'aged', 10: 'transplant', 45: 'overall', 3: '@', 23: 'rates'}
loss:  17.455476760864258
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 66.67%
Average score: 12.45
{'at': 'at', 'aged': 'aged', 'transplant': 'for', 'overall': 'lifetime', '@': '@', 'rates': 'rates'}
{'at': tensor(15.9146), 'aged': tensor(17.1760), 'transplant': tensor(9.6856), 'overall': tensor(8.2712), '@': tensor(9.0685), 'rates': tensor(14.6132)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '@', '-', '@', 'scale', '[MASK]', 'looking', '[MASK]', 'transplant', 'outcomes', 'across', '[MASK]', 'groups', 'in', 'multiple', 'my', '##elo', '##ma', 'patients', 'found', '[MASK]', 'rates', 'of', 'non', '##rel', '##ap', '##se', 'mortality', ',', 're', '##la', '##pse', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', 'survival', ',', 'and', 'overall', '[MASK]', '[MASK]', 'patients', 'who', 'were', 'aged', '70', 'years', 'and', 'older', 'and', 'those', 'who', 'were', 'aged', '60', '@', '-', '@', '69', 'years', '.', '[SEP]']
{46: 'survival', 7: 'study', 47: 'between', 9: 'at', 22: 'similar', 13: 'age'}
loss:  18.246103286743164
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 50.00%
Average score: 12.52
{'survival': 'mortality', 'study': 'study', 'between': 'in', 'at': 'at', 'similar': 'higher', 'age': 'age'}
{'survival': tensor(10.5180), 'study': tensor(12.8180), 'between': tensor(13.5734), 'at': tensor(16.1482), 'similar': tensor(10.8050), 'age': tensor(11.2602)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '@', '-', '@', '[MASK]', 'study', 'looking', 'at', 'transplant', 'outcomes', 'across', 'age', 'groups', 'in', 'multiple', 'my', '##elo', '##ma', 'patients', '[MASK]', 'similar', 'rates', 'of', '[MASK]', '##rel', '##ap', '##se', 'mortality', ',', '[MASK]', '##la', '##pse', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', 'survival', ',', 'and', 'overall', 'survival', 'between', 'patients', 'who', 'were', 'aged', '70', 'years', 'and', 'older', 'and', '[MASK]', 'who', 'were', 'aged', '60', '@', '-', '@', '69', '[MASK]', '.', '[SEP]']
{57: 'those', 31: 're', 25: 'non', 21: 'found', 66: 'years', 6: 'scale'}
loss:  19.613018035888672
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 66.67%
Average score: 14.16
{'those': 'patients', 're': 're', 'non': 'non', 'found': 'found', 'years': 'years', 'scale': 'free'}
{'those': tensor(15.5095), 're': tensor(19.0677), 'non': tensor(13.4269), 'found': tensor(15.0545), 'years': tensor(13.5976), 'scale': tensor(8.3254)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '@', '-', '@', 'scale', 'study', 'looking', 'at', 'transplant', 'outcomes', 'across', 'age', 'groups', 'in', 'multiple', 'my', '##elo', '##ma', 'patients', 'found', 'similar', 'rates', 'of', 'non', '##rel', '##ap', '##se', '[MASK]', ',', 're', '##la', '##pse', '/', 'progression', ',', 'progression', '@', '-', '[MASK]', 'free', 'survival', ',', 'and', 'overall', 'survival', 'between', 'patients', '[MASK]', 'were', 'aged', '70', 'years', 'and', 'older', 'and', '[MASK]', 'who', '[MASK]', 'aged', '[MASK]', '@', '-', '@', '69', 'years', '.', '[SEP]']
{59: 'were', 61: '60', 49: 'who', 57: 'those', 40: '@', 29: 'mortality'}
loss:  19.55537986755371
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 50.00%
Average score: 14.19
{'were': 'were', '60': 'progression', 'who': 'who', 'those': 'patients', '@': '@', 'mortality': 'survival'}
{'were': tensor(14.6805), '60': tensor(7.1493), 'who': tensor(18.8744), 'those': tensor(15.1352), '@': tensor(16.2280), 'mortality': tensor(13.0681)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '[MASK]', '-', '@', 'scale', 'study', 'looking', 'at', 'transplant', 'outcomes', 'across', 'age', 'groups', 'in', '[MASK]', 'my', '##elo', '##ma', 'patients', 'found', 'similar', 'rates', 'of', 'non', '##rel', '##ap', '##se', 'mortality', '[MASK]', 're', '##la', '##pse', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', 'survival', ',', '[MASK]', 'overall', 'survival', 'between', 'patients', 'who', 'were', '[MASK]', '70', 'years', 'and', 'older', 'and', 'those', 'who', 'were', 'aged', '60', '@', '[MASK]', '@', '69', 'years', '.', '[SEP]']
{44: 'and', 16: 'multiple', 63: '-', 3: '@', 51: 'aged', 30: ','}
loss:  18.56205940246582
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 83.33%
Average score: 12.26
{'and': 'and', 'multiple': 'multiple', '-': '-', '@': '-', 'aged': 'aged', ',': ','}
{'and': tensor(14.3433), 'multiple': tensor(12.8945), '-': tensor(8.9058), '@': tensor(6.8230), 'aged': tensor(18.5032), ',': tensor(12.0904)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', 'without', 'facial', 'der', '##mat', '[MASK]', ',', 'men', 'with', 'facial', 'der', '##mat', '##itis', 'were', 'more', 'likely', 'to', 'react', 'to', 'dime', '##thy', '##lam', '##ino', '##pro', '##py', '##lam', '##ine', '(', 'a', 'surf', '##act', '##ant', '[MASK]', 'or', '[MASK]', '##ph', '##en', '[MASK]', '[MASK]', '##iam', '##ine', '(', 'a', 'constituent', '[MASK]', 'hair', '/', '[MASK]', '/', 'beard', '/', 'eyebrows', 'dye', ')', 'and', 'less', 'likely', 'to', 'have', 'clinical', '##ly', 'relevant', 'reactions', 'to', 'traditional', '[MASK]', '##er', '##genic', 'pre', '##ser', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '##er', '##gens', '[MASK]', 'personal', 'care', 'products', 'and', 'topical', 'medications', ',', 'while', '[MASK]', 'sources', 'of', 'ir', '##ritan', '##ts', 'included', 'personal', '@', '-', '@', 'care', 'products', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{47: 'of', 35: ')', 8: '##itis', 41: '##ned', 68: 'all', 40: '##yle', 91: 'top', 82: 'included', 37: 'para', 50: 'mustache'}
loss:  21.73332977294922
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 50.00%
Average score: 16.44
{'of': 'of', ')': ')', '##itis': '##itis', '##ned': 'th', 'all': 'all', '##yle': '##yl', 'top': 'other', 'included': 'included', 'para': 'try', 'mustache': 'beard'}
{'of': tensor(14.6403), ')': tensor(19.3440), '##itis': tensor(26.6423), '##ned': tensor(13.6324), 'all': tensor(19.6267), '##yle': tensor(19.0725), 'top': tensor(10.9327), 'included': tensor(16.8895), 'para': tensor(8.9932), 'mustache': tensor(14.6559)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', 'without', 'facial', 'der', '[MASK]', '##itis', ',', 'men', 'with', 'facial', 'der', '##mat', '##itis', 'were', 'more', 'likely', 'to', 'react', 'to', 'dime', '##thy', '##lam', '##ino', '##pro', '##py', '##lam', '##ine', '(', 'a', 'surf', '##act', '##ant', ')', 'or', 'para', '##ph', '##en', '##yle', '##ned', '##iam', '##ine', '(', 'a', 'constituent', 'of', 'hair', '/', 'mustache', '/', 'beard', '/', 'eyebrows', 'dye', ')', 'and', '[MASK]', 'likely', 'to', 'have', '[MASK]', '##ly', '[MASK]', 'reactions', 'to', 'traditional', 'all', '##er', '##genic', 'pre', '[MASK]', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '[MASK]', '[MASK]', 'included', 'personal', 'care', 'products', '[MASK]', 'topical', 'medications', ',', 'while', 'top', 'sources', 'of', 'ir', '##ritan', '##ts', 'included', 'personal', '@', '-', '@', '[MASK]', '[MASK]', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{86: 'and', 72: '##ser', 80: '##er', 7: '##mat', 62: 'clinical', 102: 'care', 58: 'less', 103: 'products', 64: 'relevant', 81: '##gens'}
loss:  18.869510650634766
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 30.00%
Average score: 14.86
{'and': 'and', '##ser': '##ser', '##er': '##ergy', '##mat': '##mat', 'clinical': 'adverse', 'care': '-', 'less': 'more', 'products': ',', 'relevant': 'similar', '##gens': '##ergy'}
{'and': tensor(14.8831), '##ser': tensor(21.9811), '##er': tensor(13.4747), '##mat': tensor(25.4426), 'clinical': tensor(13.1364), 'care': tensor(8.2806), 'less': tensor(14.2968), 'products': tensor(10.2515), 'relevant': tensor(10.8918), '##gens': tensor(15.9700)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'with', 'men', 'without', 'facial', 'der', '##mat', '##itis', ',', '[MASK]', 'with', 'facial', 'der', '##mat', '##itis', 'were', 'more', 'likely', 'to', 'react', 'to', 'dime', '##thy', '##lam', '##ino', '##pro', '##py', '##lam', '##ine', '(', '[MASK]', 'surf', '##act', '##ant', ')', '[MASK]', '[MASK]', '##ph', '##en', '##yle', '##ned', '##iam', '##ine', '(', 'a', 'constituent', 'of', 'hair', '/', 'mustache', '/', 'beard', '/', '[MASK]', 'dye', ')', 'and', 'less', 'likely', '[MASK]', 'have', '[MASK]', '##ly', 'relevant', 'reactions', 'to', 'traditional', 'all', '##er', '##genic', '[MASK]', '##ser', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '##er', '##gens', 'included', 'personal', 'care', 'products', 'and', 'topical', 'medications', ',', 'while', 'top', 'sources', 'of', 'ir', '##ritan', '[MASK]', 'included', 'personal', '@', '-', '@', 'care', 'products', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{71: 'pre', 36: 'or', 1: 'compared', 31: 'a', 60: 'to', 37: 'para', 62: 'clinical', 96: '##ts', 54: 'eyebrows', 10: 'men'}
loss:  21.24243927001953
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 80.00%
Average score: 15.53
{'pre': 'pre', 'or': 'or', 'compared': 'compared', 'a': 'a', 'to': 'to', 'para': 'bi', 'clinical': 'clinical', '##ts': '##ts', 'eyebrows': 'hair', 'men': 'men'}
{'pre': tensor(16.6741), 'or': tensor(13.7348), 'compared': tensor(13.7269), 'a': tensor(14.1388), 'to': tensor(18.6903), 'para': tensor(13.0521), 'clinical': tensor(15.2339), '##ts': tensor(21.9633), 'eyebrows': tensor(13.2483), 'men': tensor(14.8247)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', 'without', 'facial', '[MASK]', '##mat', '##itis', ',', 'men', '[MASK]', 'facial', 'der', '##mat', '##itis', '[MASK]', 'more', 'likely', 'to', 'react', 'to', 'dime', '[MASK]', '##lam', '##ino', '##pro', '##py', '##lam', '##ine', '(', 'a', '[MASK]', '##act', '##ant', ')', 'or', 'para', '##ph', '##en', '##yle', '##ned', '##iam', '##ine', '[MASK]', 'a', 'constituent', 'of', 'hair', '/', 'mustache', '/', 'beard', '/', 'eyebrows', 'dye', ')', 'and', 'less', 'likely', 'to', 'have', 'clinical', '[MASK]', 'relevant', 'reactions', 'to', 'traditional', 'all', '##er', '##genic', 'pre', '##ser', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '##er', '##gens', 'included', '[MASK]', 'care', 'products', '[MASK]', 'topical', 'medications', ',', 'while', 'top', 'sources', 'of', 'ir', '##ritan', '##ts', 'included', 'personal', '@', '-', '@', 'care', '[MASK]', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{63: '##ly', 23: '##thy', 103: 'products', 6: 'der', 11: 'with', 44: '(', 83: 'personal', 86: 'and', 16: 'were', 32: 'surf'}
loss:  23.476289749145508
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 100.00%
Average score: 17.97
{'##ly': '##ly', '##thy': '##thy', 'products': 'products', 'der': 'der', 'with': 'with', '(': '(', 'personal': 'personal', 'and': 'and', 'were': 'were', 'surf': 'surf'}
{'##ly': tensor(19.7640), '##thy': tensor(26.6182), 'products': tensor(14.1573), 'der': tensor(22.3511), 'with': tensor(18.9667), '(': tensor(19.2364), 'personal': tensor(9.0222), 'and': tensor(15.4104), 'were': tensor(17.0379), 'surf': tensor(17.0989)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'with', 'men', 'without', 'facial', 'der', '##mat', '##itis', ',', 'men', 'with', '[MASK]', 'der', '##mat', '##itis', 'were', 'more', 'likely', 'to', 'react', 'to', 'dime', '##thy', '##lam', '##ino', '##pro', '##py', '##lam', '##ine', '(', 'a', 'surf', '##act', '##ant', ')', 'or', 'para', '##ph', '##en', '##yle', '##ned', '##iam', '##ine', '(', 'a', 'constituent', 'of', 'hair', '/', 'mustache', '/', 'beard', '/', '[MASK]', '[MASK]', ')', 'and', 'less', 'likely', 'to', '[MASK]', 'clinical', '[MASK]', '[MASK]', 'reactions', 'to', 'traditional', 'all', '##er', '##genic', 'pre', '##ser', '[MASK]', '##ves', '.', 'top', 'sources', 'of', '[MASK]', '##er', '##gens', 'included', 'personal', 'care', 'products', 'and', 'topical', 'medications', ',', 'while', 'top', 'sources', 'of', 'ir', '##ritan', '##ts', 'included', 'personal', '@', '-', '@', 'care', '[MASK]', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{1: 'compared', 79: 'all', 103: 'products', 73: '##vati', 64: 'relevant', 55: 'dye', 61: 'have', 63: '##ly', 54: 'eyebrows', 12: 'facial'}
loss:  19.022724151611328
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 70.00%
Average score: 14.21
{'compared': 'compared', 'all': 'all', 'products': 'products', '##vati': '##vati', 'relevant': 'allergic', 'dye': 'beard', 'have': 'have', '##ly': '##ly', 'eyebrows': 'beard', 'facial': 'facial'}
{'compared': tensor(14.4780), 'all': tensor(18.7718), 'products': tensor(13.9207), '##vati': tensor(24.6315), 'relevant': tensor(10.0563), 'dye': tensor(12.1165), 'have': tensor(12.2828), '##ly': tensor(12.4143), 'eyebrows': tensor(11.9564), 'facial': tensor(11.4685)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'in', '[MASK]', 'with', 'inflammatory', 'bow', '##el', 'disease', '(', 'ib', '##d', ')', ',', 'a', 'long', 'course', 'of', '[MASK]', 'van', '[MASK]', '##y', '##cin', 'is', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '##rid', '##io', '[MASK]', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', 'course', ',', 'a', 'retrospective', 'chart', 'review', 'reveals', '.', '[MASK]', 'in', 'ib', '##d', ',', 'having', '[MASK]', '[MASK]', '##ff', 'is', 'associated', 'with', 'worse', 'outcomes', '-', 'e', '.', 'g', '.', ',', 'greater', 'likelihood', 'for', 'hospital', '##ization', 'or', '[MASK]', ',', 'lower', 'likelihood', 'to', 'respond', 'to', 'medical', 'therapy', '[MASK]', ',', 'as', '[MASK]', 'showed', 'previously', '(', 'http', ':', '/', '/', 'bit', '.', 'l', '##y', '/', '2', '[MASK]', '##k', '##c', '##3', '##k', ')', ',', 'increased', 'risk', 'for', 'j', '[MASK]', 'complications', 'if', 'a', 'patient', 'had', 'c', 'di', '##ff', 'before', '[MASK]', 'cole', '##ct', '##omy', ',', '"', 'dr', '.', 'david', 'rubin', '[MASK]', 'university', 'of', 'chicago', 'medicine', 'told', '[MASK]', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', 'that', '[MASK]', 'one', 'c', 'di', '##ff', 'infection', 'increases', 'the', 'likelihood', 'of', 'having', 'another', '[MASK]', 'and', 'having', 'two', 'increases', 'the', 'likelihood', 'of', 'a', 'third', 'substantially', '.', '"', '[SEP]']
{151: 'having', 2: 'patients', 141: 'reuters', 115: 'pouch', 104: '##lp', 87: 'and', 125: 'their', 32: '##ides', 19: '##com', 52: '"', 163: ',', 17: 'oral', 78: 'surgery', 58: 'c', 135: 'of', 90: 'we', 59: 'di'}
loss:  18.54401969909668
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 47.06%
Average score: 12.90
{'having': 'having', 'patients': 'patients', 'reuters': 'public', 'pouch': '##v', '##lp': '##p', 'and': 'or', 'their': 'a', '##ides': '##id', '##com': '##com', '"': '"', ',': ',', 'oral': 'topical', 'surgery': 'death', 'c': 'c', 'of': 'of', 'we': 'they', 'di': 'di'}
{'having': tensor(13.9840), 'patients': tensor(15.1964), 'reuters': tensor(9.6192), 'pouch': tensor(10.3220), '##lp': tensor(11.2993), 'and': tensor(10.8115), 'their': tensor(10.8553), '##ides': tensor(12.4849), '##com': tensor(18.7939), '"': tensor(12.7635), ',': tensor(12.2555), 'oral': tensor(10.7250), 'surgery': tensor(12.9099), 'c': tensor(14.0877), 'of': tensor(13.5795), 'we': tensor(8.9170), 'di': tensor(20.6926)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'in', 'patients', 'with', 'inflammatory', '[MASK]', '##el', 'disease', '(', '[MASK]', '##d', ')', ',', 'a', 'long', 'course', 'of', 'oral', 'van', '##com', '##y', '##cin', 'is', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '##rid', '[MASK]', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', 'course', ',', 'a', '[MASK]', '[MASK]', 'review', 'reveals', '.', '"', 'in', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', 'is', 'associated', 'with', 'worse', 'outcomes', '-', 'e', '.', 'g', '.', ',', '[MASK]', 'likelihood', 'for', 'hospital', '[MASK]', 'or', 'surgery', ',', 'lower', 'likelihood', 'to', 'respond', 'to', 'medical', '[MASK]', 'and', ',', 'as', 'we', 'showed', 'previously', '(', 'http', ':', '/', '[MASK]', '[MASK]', '.', 'l', '##y', '/', '2', '##lp', '##k', '##c', '##3', '##k', ')', '[MASK]', 'increased', 'risk', 'for', 'j', 'pouch', '[MASK]', '[MASK]', 'a', 'patient', 'had', 'c', '[MASK]', '##ff', 'before', 'their', 'cole', '##ct', '##omy', ',', '"', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', 'reuters', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', '[MASK]', 'having', 'one', 'c', 'di', '[MASK]', 'infection', 'increases', 'the', 'likelihood', 'of', 'having', 'another', ',', 'and', '[MASK]', 'two', 'increases', 'the', 'likelihood', 'of', 'a', 'third', 'substantially', '.', '"', '[SEP]']
{9: 'ib', 48: 'chart', 47: 'retrospective', 72: 'greater', 97: '/', 110: ',', 76: '##ization', 117: 'if', 122: 'di', 98: 'bit', 155: '##ff', 31: '##io', 165: 'having', 150: 'that', 86: 'therapy', 5: 'bow', 116: 'complications'}
loss:  20.55680274963379
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 64.71%
Average score: 15.06
{'ib': 'ib', 'chart': 'cochrane', 'retrospective': 'recent', 'greater': 'lower', '/': '/', ',': ',', '##ization': '##ization', 'if': 'if', 'di': 'di', 'bit': '/', '##ff': '##ff', '##io': '##io', 'having': 'having', 'that': 'that', 'therapy': 'emergencies', 'bow': 'bow', 'complications': 'infection'}
{'ib': tensor(19.7256), 'chart': tensor(8.6664), 'retrospective': tensor(10.7089), 'greater': tensor(14.4101), '/': tensor(18.0099), ',': tensor(14.2604), '##ization': tensor(17.6398), 'if': tensor(15.0108), 'di': tensor(20.7021), 'bit': tensor(11.9428), '##ff': tensor(20.5193), '##io': tensor(18.0683), 'having': tensor(13.3437), 'that': tensor(14.5636), 'therapy': tensor(12.3961), 'bow': tensor(14.0896), 'complications': tensor(12.0384)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'in', 'patients', 'with', 'inflammatory', 'bow', '##el', 'disease', '[MASK]', '[MASK]', '##d', ')', ',', 'a', 'long', 'course', 'of', 'oral', 'van', '##com', '##y', '##cin', 'is', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '##rid', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', 'course', ',', 'a', 'retrospective', 'chart', 'review', 'reveals', '.', '[MASK]', '[MASK]', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', 'is', 'associated', 'with', 'worse', 'outcomes', '-', 'e', '[MASK]', 'g', '.', ',', 'greater', 'likelihood', 'for', '[MASK]', '##ization', '[MASK]', 'surgery', ',', 'lower', 'likelihood', 'to', 'respond', 'to', 'medical', 'therapy', 'and', ',', 'as', '[MASK]', 'showed', 'previously', '(', 'http', ':', '/', '/', '[MASK]', '.', 'l', '##y', '/', '2', '##lp', '##k', '##c', '##3', '##k', ')', ',', 'increased', 'risk', 'for', 'j', 'pouch', 'complications', '[MASK]', 'a', 'patient', 'had', 'c', 'di', '##ff', 'before', 'their', 'cole', '##ct', '##omy', ',', '[MASK]', 'dr', '.', '[MASK]', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', 'reuters', 'health', 'by', 'email', '.', '"', 'we', '[MASK]', 'know', 'that', 'having', 'one', 'c', 'di', '##ff', '[MASK]', '[MASK]', 'the', 'likelihood', 'of', 'having', 'another', ',', 'and', 'having', 'two', 'increases', '[MASK]', 'likelihood', 'of', 'a', 'third', '[MASK]', '.', '"', '[SEP]']
{156: 'infection', 9: 'ib', 168: 'the', 148: 'also', 68: '.', 130: '"', 90: 'we', 52: '"', 133: 'david', 98: 'bit', 173: 'substantially', 8: '(', 157: 'increases', 117: 'if', 75: 'hospital', 53: 'in', 77: 'or'}
loss:  20.397136688232422
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 52.94%
Average score: 14.06
{'infection': 'increases', 'ib': 'ib', 'the': 'the', 'also': 'all', '.': '.', '"': 'in', 'we': 'they', 'david': 'david', 'bit': 'www', 'substantially': 'pregnancy', '(': '(', 'increases': 'increases', 'if': 'if', 'hospital': 'hospital', 'in': 'in', 'or': 'after'}
{'infection': tensor(17.1535), 'ib': tensor(20.0771), 'the': tensor(16.4300), 'also': tensor(12.6961), '.': tensor(21.6665), '"': tensor(11.8336), 'we': tensor(8.3847), 'david': tensor(7.8374), 'bit': tensor(8.3963), 'substantially': tensor(9.6396), '(': tensor(22.4781), 'increases': tensor(16.8193), 'if': tensor(13.8301), 'hospital': tensor(16.6447), 'in': tensor(10.2025), 'or': tensor(10.8469)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'in', 'patients', '[MASK]', 'inflammatory', 'bow', '##el', 'disease', '(', 'ib', '##d', ')', ',', 'a', 'long', 'course', 'of', 'oral', 'van', '[MASK]', '##y', '##cin', 'is', 'associated', 'with', 'lower', 'odds', 'of', '[MASK]', '##ost', '##rid', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '[MASK]', 'than', 'a', 'short', 'course', ',', 'a', 'retrospective', 'chart', 'review', 'reveals', '.', '"', 'in', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', 'is', 'associated', 'with', 'worse', 'outcomes', '-', 'e', '.', 'g', '.', ',', 'greater', 'likelihood', 'for', '[MASK]', '##ization', 'or', 'surgery', ',', 'lower', '[MASK]', 'to', 'respond', 'to', 'medical', 'therapy', 'and', '[MASK]', 'as', 'we', 'showed', 'previously', '(', '[MASK]', ':', '/', '/', 'bit', '.', 'l', '##y', '/', '2', '##lp', '##k', '##c', '##3', '##k', ')', ',', 'increased', '[MASK]', 'for', 'j', '[MASK]', 'complications', 'if', 'a', 'patient', 'had', 'c', 'di', '##ff', 'before', '[MASK]', 'cole', '[MASK]', '##omy', '[MASK]', '"', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', 'reuters', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', 'that', 'having', 'one', 'c', 'di', '##ff', 'infection', 'increases', 'the', 'likelihood', 'of', '[MASK]', 'another', ',', '[MASK]', 'having', '[MASK]', 'increases', 'the', 'likelihood', 'of', 'a', '[MASK]', 'substantially', '.', '"', '[SEP]']
{81: 'likelihood', 129: ',', 112: 'risk', 125: 'their', 75: 'hospital', 172: 'third', 40: '##rence', 3: 'with', 88: ',', 166: 'two', 164: 'and', 28: 'cl', 19: '##com', 94: 'http', 127: '##ct', 161: 'having', 115: 'pouch'}
loss:  19.756649017333984
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 76.47%
Average score: 14.65
{'likelihood': 'likelihood', ',': ',', 'risk': 'risk', 'their': 'a', 'hospital': 'hospital', 'third': 'death', '##rence': '##rence', 'with': 'with', 'two': 'one', 'and': 'and', 'cl': 'cl', '##com': '##com', 'http': 'http', '##ct': '##ct', 'having': 'having', 'pouch': '##v'}
{'likelihood': tensor(13.8986), ',': tensor(13.0339), 'risk': tensor(15.2443), 'their': tensor(11.2066), 'hospital': tensor(17.1852), 'third': tensor(10.5867), '##rence': tensor(16.1768), 'with': tensor(17.6430), 'two': tensor(10.1241), 'and': tensor(13.0380), 'cl': tensor(18.2670), '##com': tensor(18.9857), 'http': tensor(15.5827), '##ct': tensor(19.8906), 'having': tensor(14.1561), 'pouch': tensor(9.3224)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'in', 'patients', 'with', 'inflammatory', 'bow', '##el', 'disease', '(', 'ib', '##d', ')', ',', 'a', 'long', 'course', 'of', 'oral', '[MASK]', '##com', '##y', '##cin', '[MASK]', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '##rid', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', '[MASK]', ',', 'a', 'retrospective', 'chart', 'review', 'reveals', '.', '"', 'in', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', 'is', '[MASK]', 'with', 'worse', 'outcomes', '-', 'e', '[MASK]', '[MASK]', '.', ',', 'greater', 'likelihood', 'for', 'hospital', '##ization', 'or', 'surgery', ',', 'lower', '[MASK]', 'to', 'respond', 'to', 'medical', 'therapy', 'and', ',', 'as', '[MASK]', 'showed', 'previously', '(', 'http', ':', '/', '[MASK]', '[MASK]', '.', 'l', '##y', '/', '[MASK]', '##lp', '##k', '##c', '##3', '##k', ')', ',', 'increased', 'risk', 'for', 'j', 'pouch', 'complications', 'if', '[MASK]', 'patient', 'had', 'c', 'di', '##ff', 'before', 'their', 'cole', '##ct', '##omy', ',', '[MASK]', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', '[MASK]', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', 'that', 'having', 'one', 'c', 'di', '[MASK]', 'infection', '[MASK]', 'the', 'likelihood', 'of', '[MASK]', 'another', ',', 'and', 'having', 'two', 'increases', 'the', 'likelihood', 'of', 'a', 'third', 'substantially', '.', '"', '[SEP]']
{90: 'we', 118: 'a', 141: 'reuters', 103: '2', 62: 'associated', 22: 'is', 44: 'course', 155: '##ff', 161: 'having', 68: '.', 97: '/', 81: 'likelihood', 98: 'bit', 18: 'van', 130: '"', 69: 'g', 157: 'increases'}
loss:  19.795791625976562
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 64.71%
Average score: 14.27
{'we': 'we', 'a': 'the', 'reuters': 'public', '2': 'b', 'associated': 'associated', 'is': 'is', 'course': 'course', '##ff': '##ff', 'having': 'having', '.': '##q', '/': '/', 'likelihood': 'likelihood', 'bit': '/', 'van': 'van', '"': '"', 'g': '##q', 'increases': 'increases'}
{'we': tensor(8.9922), 'a': tensor(13.5497), 'reuters': tensor(9.6611), '2': tensor(9.0622), 'associated': tensor(19.0498), 'is': tensor(15.3555), 'course': tensor(14.1290), '##ff': tensor(21.7061), 'having': tensor(13.7998), '.': tensor(14.6831), '/': tensor(17.8605), 'likelihood': tensor(13.1651), 'bit': tensor(12.2067), 'van': tensor(11.7819), '"': tensor(13.6797), 'g': tensor(14.6552), 'increases': tensor(19.3192)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', 'was', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', 'by', 'michael', 'j', '.', 'wilkinson', ',', 'md', ',', 'of', 'the', '[MASK]', 'of', 'california', '[MASK]', '[MASK]', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', 'the', 'women', 'were', 'taking', 'a', 'stat', '##in', '[MASK]', 'anti', '##hy', '##per', '##tens', '##ive', 'medications', ',', 'or', 'both', 'at', 'study', 'entry', ',', '"', 'the', 'observed', 'benefits', 'of', 'time', '@', '-', '@', 'restricted', '[MASK]', 'were', 'additive', 'to', 'the', 'effects', 'of', 'these', 'medications', '.', '.', '.', 'and', '[MASK]', 'this', 'population', 'at', 'high', 'risk', 'for', 'cardiovascular', '[MASK]', ',', 'a', '[MASK]', 'reduction', 'in', 'at', '##her', '[MASK]', 'lip', '##ids', ',', 'blood', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', 'therapy', 'has', 'important', 'clinical', '[MASK]', ',', '[MASK]', 'say', 'the', 'investigators', '[MASK]', '[SEP]']
{118: '.', 25: 'san', 41: ',', 78: 'in', 114: '"', 24: ',', 89: 'significant', 21: 'university', 86: 'disease', 112: 'implications', 94: '##ogenic', 65: 'eating'}
loss:  21.19679069519043
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 58.33%
Average score: 15.67
{'.': '.', 'san': 'san', ',': 'san', 'in': 'with', '"': '"', 'significant': 'significant', 'university': 'university', 'disease': 'disease', 'implications': 'implications', '##ogenic': '##ine', 'eating': 'treatment'}
{'.': tensor(19.7588), 'san': tensor(18.9715), ',': tensor(15.7594), 'in': tensor(11.8029), '"': tensor(15.8099), 'significant': tensor(10.1407), 'university': tensor(22.6806), 'disease': tensor(16.3074), 'implications': tensor(15.7802), '##ogenic': tensor(15.5745), 'eating': tensor(9.7518)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', 'was', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', 'by', 'michael', 'j', '.', 'wilkinson', ',', 'md', ',', 'of', 'the', 'university', 'of', 'california', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', 'the', 'women', 'were', 'taking', 'a', 'stat', '##in', ',', 'anti', '##hy', '##per', '##tens', '##ive', 'medications', ',', '[MASK]', 'both', 'at', '[MASK]', 'entry', ',', '[MASK]', 'the', 'observed', 'benefits', 'of', 'time', '@', '-', '@', '[MASK]', 'eating', 'were', 'additive', 'to', 'the', 'effects', 'of', 'these', '[MASK]', '[MASK]', '.', '.', 'and', 'in', 'this', 'population', '[MASK]', 'high', 'risk', 'for', 'cardiovascular', 'disease', ',', 'a', 'significant', 'reduction', 'in', 'at', '[MASK]', '[MASK]', 'lip', '##ids', ',', 'blood', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', '[MASK]', 'has', 'important', '[MASK]', '[MASK]', ',', '"', 'say', 'the', 'investigators', '.', '[SEP]']
{49: 'or', 55: '"', 111: 'clinical', 108: 'therapy', 64: 'restricted', 94: '##ogenic', 52: 'study', 112: 'implications', 81: 'at', 93: '##her', 73: 'medications', 74: '.'}
loss:  16.928882598876953
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 33.33%
Average score: 11.26
{'or': 'and', '"': '"', 'clinical': 'implications', 'therapy': 'activity', 'restricted': 'and', '##ogenic': '##rial', 'study': 'medical', 'implications': 'implications', 'at': 'at', '##her': 'least', 'medications': 'medications', '.': 'medications'}
{'or': tensor(10.3162), '"': tensor(11.1912), 'clinical': tensor(10.5778), 'therapy': tensor(9.7260), 'restricted': tensor(8.0458), '##ogenic': tensor(13.9381), 'study': tensor(7.7195), 'implications': tensor(15.1697), 'at': tensor(14.5176), '##her': tensor(11.4780), 'medications': tensor(11.1734), '.': tensor(11.2673)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', '[MASK]', 'was', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', 'by', 'michael', 'j', '.', 'wilkinson', ',', 'md', ',', 'of', 'the', 'university', 'of', 'california', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', '[MASK]', 'women', 'were', 'taking', 'a', 'stat', '##in', ',', 'anti', '##hy', '##per', '##tens', '##ive', 'medications', ',', 'or', 'both', '[MASK]', 'study', '[MASK]', ',', '"', 'the', 'observed', 'benefits', 'of', '[MASK]', '@', '-', '@', 'restricted', 'eating', 'were', 'additive', 'to', '[MASK]', 'effects', 'of', 'these', 'medications', '.', '.', '[MASK]', 'and', '[MASK]', 'this', '[MASK]', 'at', 'high', 'risk', 'for', 'cardiovascular', 'disease', '[MASK]', 'a', 'significant', 'reduction', 'in', '[MASK]', '##her', '##ogenic', 'lip', '##ids', ',', 'blood', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', 'therapy', 'has', 'important', 'clinical', 'implications', ',', '"', 'say', 'the', 'investigators', '[MASK]', '[SEP]']
{60: 'time', 51: 'at', 69: 'the', 2: 'study', 78: 'in', 34: 'the', 80: 'population', 92: 'at', 118: '.', 53: 'entry', 87: ',', 76: '.'}
loss:  20.005956649780273
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 50.00%
Average score: 12.34
{'time': 'the', 'at': 'at', 'the': 'the', 'study': 'study', 'in': 'because', 'population': 'is', '.': '.', 'entry': 'concluded', ',': '.'}
{'time': tensor(8.6095), 'at': tensor(16.6170), 'the': tensor(13.8946), 'study': tensor(12.9705), 'in': tensor(10.7653), 'population': tensor(10.3952), '.': tensor(13.7217), 'entry': tensor(12.2814), ',': tensor(11.8288)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', 'was', '[MASK]', 'online', 'december', '5', 'in', 'cell', 'metabolism', 'by', '[MASK]', 'j', '.', 'wilkinson', ',', 'md', ',', 'of', 'the', 'university', '[MASK]', 'california', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', '[MASK]', 'the', 'women', '[MASK]', 'taking', 'a', 'stat', '##in', ',', 'anti', '##hy', '##per', '[MASK]', '##ive', 'medications', ',', 'or', 'both', 'at', 'study', 'entry', ',', '"', 'the', 'observed', 'benefits', 'of', 'time', '@', '-', '@', 'restricted', 'eating', 'were', 'additive', 'to', 'the', 'effects', 'of', 'these', 'medications', '.', '.', '.', 'and', '[MASK]', 'this', 'population', '[MASK]', 'high', 'risk', 'for', 'cardiovascular', 'disease', ',', 'a', 'significant', 'reduction', 'in', 'at', '[MASK]', '##ogenic', 'lip', '##ids', ',', 'blood', 'pressure', ',', '[MASK]', 'blood', 'glucose', '[MASK]', 'top', 'of', 'medical', 'therapy', 'has', 'important', 'clinical', 'implications', '[MASK]', '"', 'say', 'the', 'investigators', '.', '[SEP]']
{33: 'of', 113: ',', 81: 'at', 78: 'in', 101: 'and', 12: 'michael', 22: 'of', 93: '##her', 4: 'published', 45: '##tens', 104: 'on', 36: 'were'}
loss:  20.78175163269043
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 83.33%
Average score: 15.34
{'of': 'of', ',': ',', 'at': 'at', 'in': 'because', 'and': 'and', 'michael': 'robert', '##her': '##her', 'published': 'published', '##tens': '##tens', 'on': 'on', 'were': 'were'}
{'of': tensor(20.3995), ',': tensor(16.1923), 'at': tensor(13.8354), 'in': tensor(13.6609), 'and': tensor(16.1092), 'michael': tensor(7.6158), '##her': tensor(15.3253), 'published': tensor(13.6259), '##tens': tensor(20.6824), 'on': tensor(16.1970), 'were': tensor(15.0851)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', '[MASK]', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', '[MASK]', 'michael', 'j', '[MASK]', 'wilkinson', ',', 'md', '[MASK]', 'of', 'the', 'university', 'of', '[MASK]', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', 'the', 'women', 'were', 'taking', 'a', 'stat', '##in', ',', 'anti', '[MASK]', '##per', '##tens', '##ive', 'medications', ',', 'or', 'both', 'at', 'study', 'entry', ',', '"', '[MASK]', 'observed', 'benefits', 'of', 'time', '@', '-', '@', 'restricted', 'eating', 'were', 'additive', 'to', 'the', 'effects', 'of', 'these', 'medications', '.', '.', '.', 'and', 'in', 'this', 'population', '[MASK]', 'high', 'risk', 'for', 'cardiovascular', '[MASK]', ',', 'a', 'significant', 'reduction', 'in', 'at', '[MASK]', '##ogenic', 'lip', '##ids', ',', 'blood', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', '[MASK]', 'therapy', 'has', 'important', 'clinical', 'implications', ',', '"', '[MASK]', 'the', 'investigators', '.', '[SEP]']
{23: 'california', 115: 'say', 86: 'disease', 81: 'at', 11: 'by', 43: '##hy', 56: 'the', 107: 'medical', 93: '##her', 14: '.', 18: ',', 3: 'was'}
loss:  20.595678329467773
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 83.33%
Average score: 15.25
{'california': 'california', 'say': 'said', 'disease': 'disease', 'at': 'at', 'by': 'by', '##hy': '##hy', 'the': 'the', 'medical': 'hormone', '##her': '##her', '.': '.', ',': ',', 'was': 'was'}
{'california': tensor(18.5956), 'say': tensor(12.8649), 'disease': tensor(16.8641), 'at': tensor(15.0004), 'by': tensor(15.1194), '##hy': tensor(20.1499), 'the': tensor(13.1916), 'medical': tensor(9.9083), '##her': tensor(15.4542), '.': tensor(17.1040), ',': tensor(13.1639), 'was': tensor(15.5666)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', 'begun', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '##cino', '##gen', 'n', '@', '-', '@', 'ni', '##tro', '##so', '##dim', '##eth', '[MASK]', '##mine', '(', 'n', '##dm', '##a', ')', ',', 'the', 'agency', 'announced', 'wednesday', '.', 'contamination', 'with', '[MASK]', 'same', 'substance', 'led', 'to', 'recalls', 'of', 'blood', 'pressure', '[MASK]', 'heart', '##burn', 'medications', 'within', 'the', 'last', '2', 'years', '.', '[MASK]', '##form', '##in', '[MASK]', 'generally', 'the', 'first', 'medication', 'prescribed', 'for', 'type', '2', 'diabetes', ',', 'according', 'to', '[MASK]', 'clinic', '.', 'it', 'lowers', 'glucose', 'production', '[MASK]', 'the', '[MASK]', 'and', 'boost', '##s', 'your', 'body', "'", 's', '[MASK]', 'to', 'insulin', '[MASK]', '[MASK]', 'your', 'body', 'uses', 'insulin', 'more', 'effectively', '.', 'more', 'than', '30', 'million', 'people', 'in', 'the', '[MASK]', '.', 's', '.', 'have', 'diabetes', ',', 'and', '90', 'to', '95', '%', 'are', 'type', '2', ',', '[MASK]', '[MASK]', 'says', ',', '[MASK]', 'met', '##form', '##in', 'is', 'the', 'fourth', '@', '-', '@', 'most', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{99: 'that', 98: 'so', 134: 'and', 114: 'u', 131: 'cdc', 95: 'sensitivity', 78: 'mayo', 28: '##yla', 43: 'this', 62: 'met', 87: 'liver', 85: 'in', 65: 'is', 52: 'and', 130: 'the'}
loss:  20.789995193481445
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 46.67%
Average score: 14.73
{'that': 'making', 'so': ',', 'and': 'and', 'u': 'u', 'cdc': 'it', 'sensitivity': 'response', 'mayo': 'the', '##yla': '##yla', 'this': 'the', 'met': 'met', 'liver': 'body', 'in': 'in', 'is': 'is', 'the': 'it'}
{'that': tensor(9.8733), 'so': tensor(11.2930), 'and': tensor(12.9970), 'u': tensor(21.7603), 'cdc': tensor(8.9513), 'sensitivity': tensor(17.4765), 'mayo': tensor(11.4752), '##yla': tensor(21.8706), 'this': tensor(15.8474), 'met': tensor(20.1898), 'liver': tensor(15.0432), 'in': tensor(13.9200), 'is': tensor(17.4420), 'the': tensor(8.0679)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', '[MASK]', 'testing', 'samples', 'of', '[MASK]', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '[MASK]', '##gen', 'n', '@', '-', '@', 'ni', '##tro', '##so', '##dim', '##eth', '##yla', '##mine', '(', 'n', '##dm', '##a', ')', ',', 'the', 'agency', 'announced', '[MASK]', '.', 'contamination', 'with', 'this', 'same', 'substance', 'led', 'to', 'recalls', '[MASK]', '[MASK]', 'pressure', 'and', 'heart', '##burn', 'medications', 'within', 'the', '[MASK]', '2', 'years', '.', 'met', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', 'prescribed', 'for', 'type', '2', 'diabetes', ',', 'according', 'to', 'mayo', '[MASK]', '.', 'it', '[MASK]', 'glucose', 'production', 'in', 'the', 'liver', 'and', 'boost', '##s', 'your', 'body', '[MASK]', 's', 'sensitivity', 'to', 'insulin', 'so', 'that', 'your', 'body', 'uses', 'insulin', 'more', 'effectively', '.', 'more', 'than', '30', 'million', 'people', 'in', '[MASK]', 'u', '.', 's', '[MASK]', 'have', 'diabetes', ',', 'and', '[MASK]', 'to', '95', '%', 'are', 'type', '2', ',', 'the', 'cdc', 'says', ',', 'and', 'met', '##form', '##in', 'is', 'the', 'fourth', '@', '[MASK]', '@', 'most', '[MASK]', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{113: 'the', 50: 'blood', 79: 'clinic', 93: "'", 117: '.', 58: 'last', 142: '-', 82: 'lowers', 8: 'the', 145: 'prescribed', 49: 'of', 4: 'begun', 122: '90', 17: '##cino', 39: 'wednesday'}
loss:  20.174694061279297
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 53.33%
Average score: 14.26
{'the': 'the', 'blood': 'of', 'clinic': 'clinic', "'": "'", '.': '.', 'last': 'next', '-': '-', 'lowers': 'increases', 'prescribed': 'common', 'of': 'of', 'begun': 'been', '90': 'up', '##cino': '##cino', 'wednesday': 'recently'}
{'the': tensor(12.6752), 'blood': tensor(11.5525), 'clinic': tensor(14.3457), "'": tensor(21.8416), '.': tensor(16.1920), 'last': tensor(13.2943), '-': tensor(11.6093), 'lowers': tensor(17.0328), 'prescribed': tensor(11.6547), 'of': tensor(12.8544), 'begun': tensor(13.9922), '90': tensor(13.1077), '##cino': tensor(20.8614), 'wednesday': tensor(8.6387)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', 'begun', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '##cino', '##gen', 'n', '@', '-', '@', 'ni', '[MASK]', '##so', '##dim', '##eth', '##yla', '##mine', '(', 'n', '##dm', '##a', ')', ',', 'the', 'agency', 'announced', 'wednesday', '.', 'contamination', 'with', 'this', 'same', 'substance', 'led', 'to', 'recalls', 'of', 'blood', 'pressure', 'and', '[MASK]', '##burn', 'medications', 'within', 'the', 'last', '[MASK]', 'years', '[MASK]', 'met', '##form', '##in', '[MASK]', 'generally', 'the', '[MASK]', 'medication', 'prescribed', 'for', 'type', '2', 'diabetes', ',', 'according', '[MASK]', 'mayo', 'clinic', '.', 'it', 'lowers', '[MASK]', '[MASK]', 'in', 'the', 'liver', 'and', 'boost', '##s', 'your', 'body', "'", 's', 'sensitivity', 'to', '[MASK]', 'so', 'that', 'your', 'body', 'uses', 'insulin', 'more', 'effectively', '.', 'more', 'than', '30', '[MASK]', '[MASK]', 'in', 'the', 'u', '[MASK]', 's', '.', 'have', 'diabetes', ',', 'and', '90', 'to', '95', '%', 'are', 'type', '2', ',', 'the', 'cdc', 'says', '[MASK]', 'and', 'met', '##form', '##in', 'is', 'the', 'fourth', '@', '[MASK]', '@', 'most', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{53: 'heart', 84: 'production', 65: 'is', 77: 'to', 111: 'people', 115: '.', 133: ',', 59: '2', 97: 'insulin', 110: 'million', 61: '.', 68: 'first', 83: 'glucose', 142: '-', 24: '##tro'}
loss:  21.787534713745117
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 60.00%
Average score: 15.35
{'heart': 'heart', 'production': 'pressure', 'is': 'is', 'to': 'to', 'people': '%', '.': '.', ',': ',', '2': 'few', 'insulin': 'insulin', 'million': '%', 'first': 'only', 'glucose': 'blood', '-': '-', '##tro': '##tro'}
{'heart': tensor(13.8603), 'production': tensor(14.5964), 'is': tensor(18.9709), 'to': tensor(18.9711), 'people': tensor(17.0025), '.': tensor(17.1616), ',': tensor(14.9617), '2': tensor(11.6029), 'insulin': tensor(17.8370), 'million': tensor(18.7519), 'first': tensor(12.0414), 'glucose': tensor(10.6904), '-': tensor(11.8117), '##tro': tensor(16.6028)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', 'begun', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '##cino', '##gen', 'n', '@', '-', '@', 'ni', '##tro', '##so', '##dim', '##eth', '##yla', '##mine', '(', 'n', '[MASK]', '##a', ')', ',', 'the', 'agency', 'announced', 'wednesday', '.', '[MASK]', 'with', 'this', 'same', 'substance', 'led', 'to', 'recalls', 'of', 'blood', 'pressure', 'and', 'heart', '##burn', '[MASK]', 'within', 'the', '[MASK]', '2', 'years', '.', 'met', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', '[MASK]', 'for', 'type', '2', '[MASK]', ',', 'according', 'to', 'mayo', 'clinic', '.', 'it', 'lowers', 'glucose', 'production', 'in', 'the', 'liver', '[MASK]', 'boost', '##s', '[MASK]', 'body', "'", 's', 'sensitivity', 'to', 'insulin', 'so', 'that', 'your', 'body', 'uses', 'insulin', 'more', 'effectively', '.', 'more', 'than', '30', 'million', 'people', 'in', 'the', 'u', '.', 's', '.', '[MASK]', 'diabetes', ',', 'and', '[MASK]', 'to', '95', '%', 'are', '[MASK]', '2', ',', 'the', 'cdc', 'says', ',', '[MASK]', 'met', '##form', '[MASK]', 'is', '[MASK]', 'fourth', '@', '-', '@', 'most', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '[MASK]', '[SEP]']
{58: 'last', 55: 'medications', 118: 'have', 122: '90', 41: 'contamination', 91: 'your', 127: 'type', 70: 'prescribed', 74: 'diabetes', 139: 'the', 134: 'and', 32: '##dm', 151: '.', 137: '##in', 88: 'and'}
loss:  20.613494873046875
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 60.00%
Average score: 15.26
{'last': 'next', 'medications': ',', 'have': 'have', '90': 'up', 'contamination': 'tests', 'your': 'your', 'type': 'type', 'prescribed': 'approved', 'diabetes': 'diabetes', 'the': 'the', 'and': 'and', '##dm': '##dc', '.': '.', '##in': '##in'}
{'last': tensor(12.3174), 'medications': tensor(9.3971), 'have': tensor(16.6665), '90': tensor(12.9272), 'contamination': tensor(11.8578), 'your': tensor(14.5585), 'type': tensor(16.1219), 'prescribed': tensor(15.0013), 'diabetes': tensor(22.6778), 'the': tensor(14.9216), 'and': tensor(14.8945), '##dm': tensor(11.4875), '.': tensor(19.3987), '##in': tensor(21.4551)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', 'begun', 'testing', 'samples', 'of', '[MASK]', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '[MASK]', '##gen', 'n', '@', '-', '@', 'ni', '##tro', '##so', '##dim', '##eth', '##yla', '##mine', '(', 'n', '##dm', '##a', ')', ',', 'the', 'agency', '[MASK]', 'wednesday', '.', 'contamination', 'with', 'this', '[MASK]', 'substance', 'led', '[MASK]', 'recalls', '[MASK]', 'blood', 'pressure', 'and', 'heart', '##burn', 'medications', 'within', 'the', 'last', '2', 'years', '[MASK]', 'met', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', 'prescribed', 'for', 'type', '2', 'diabetes', ',', 'according', 'to', 'mayo', 'clinic', '.', 'it', 'lowers', 'glucose', 'production', 'in', 'the', 'liver', 'and', 'boost', '[MASK]', '[MASK]', 'body', "'", 's', 'sensitivity', '[MASK]', 'insulin', 'so', '[MASK]', 'your', 'body', 'uses', 'insulin', 'more', 'effectively', '.', 'more', 'than', '30', 'million', '[MASK]', 'in', 'the', 'u', '.', '[MASK]', '.', 'have', 'diabetes', '[MASK]', 'and', '90', 'to', '95', '%', 'are', 'type', '2', ',', 'the', 'cdc', 'says', ',', 'and', 'met', '##form', '##in', 'is', 'the', 'fourth', '@', '-', '[MASK]', 'most', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{91: 'your', 120: ',', 38: 'announced', 49: 'of', 8: 'the', 143: '@', 17: '##cino', 111: 'people', 44: 'same', 90: '##s', 96: 'to', 47: 'to', 61: '.', 99: 'that', 116: 's'}
loss:  21.529415130615234
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 86.67%
Average score: 15.28
{'your': 'your', ',': ',', 'announced': 'on', 'of': 'of', 'the': 'the', '@': '@', '##cino': '##cino', 'people': 'people', 'same': 'new', '##s': '##s', 'to': 'to', '.': '.', 'that': 'that', 's': 's'}
{'your': tensor(13.8892), ',': tensor(14.8209), 'announced': tensor(9.3374), 'of': tensor(13.9556), 'the': tensor(12.6460), '@': tensor(14.5223), '##cino': tensor(20.8633), 'people': tensor(18.2028), 'same': tensor(9.8337), '##s': tensor(15.4894), 'to': tensor(14.6907), '.': tensor(16.5065), 'that': tensor(15.4610), 's': tensor(23.7370)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', 'be', '.', 'just', 'listen', 'to', 'what', '[MASK]', 'leaders', 'said', 'following', 'the', 'election', 'of', 'the', 'speaker', 'of', 'the', 'house', '[MASK]', 'commons', '.', 'their', 'speeches', 'were', 'rep', '##lete', 'with', '[MASK]', '[MASK]', 'the', '[MASK]', '@', '-', '@', 'word', ':', 'collaboration', '.', 'over', 'and', 'over', '[MASK]', 'canadians', 'heard', 'their', 'political', 'leaders', 'promise', 'to', '[MASK]', 'received', 'the', 'message', 'they', 'were', 'sent', 'in', 'the', 'election', ':', 'voters', 'want', 'them', 'to', '[MASK]', 'together', 'for', 'the', 'better', '##ment', 'of', 'our', 'country', '.', '[SEP]']
{34: 'references', 71: 'work', 13: 'party', 56: 'have', 35: 'to', 37: 'c', 48: ',', 25: 'of'}
loss:  18.38928985595703
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 50.00%
Average score: 11.35
{'references': 'words', 'work': 'work', 'party': 'the', 'have': 'have', 'to': 'of', 'c': 'same', ',': ',', 'of': 'of'}
{'references': tensor(7.4359), 'work': tensor(13.8819), 'party': tensor(9.7659), 'have': tensor(10.5118), 'to': tensor(10.9163), 'c': tensor(8.5269), ',': tensor(10.7571), 'of': tensor(18.9688)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', '[MASK]', '.', 'just', 'listen', 'to', 'what', 'party', 'leaders', 'said', 'following', 'the', 'election', 'of', 'the', 'speaker', '[MASK]', 'the', 'house', 'of', 'commons', '.', 'their', 'speeches', '[MASK]', 'rep', '[MASK]', 'with', 'references', 'to', 'the', '[MASK]', '@', '-', '[MASK]', 'word', ':', 'collaboration', '.', 'over', 'and', 'over', ',', 'canadians', 'heard', 'their', 'political', 'leaders', 'promise', '[MASK]', 'have', 'received', 'the', 'message', 'they', 'were', 'sent', 'in', 'the', 'election', ':', 'voters', 'want', 'them', 'to', 'work', 'together', 'for', 'the', 'better', '##ment', 'of', '[MASK]', 'country', '.', '[SEP]']
{37: 'c', 22: 'of', 55: 'to', 7: 'be', 78: 'our', 30: 'were', 40: '@', 32: '##lete'}
loss:  19.840436935424805
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 75.00%
Average score: 13.54
{'c': 'same', 'of': 'of', 'to': 'to', 'be': 'be', 'our': 'their', 'were': 'were', '@': '@', '##lete': '##lete'}
{'c': tensor(8.0897), 'of': tensor(15.5160), 'to': tensor(14.4283), 'be': tensor(11.2765), 'our': tensor(13.3427), 'were': tensor(12.4614), '@': tensor(11.8094), '##lete': tensor(21.3602)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', '[MASK]', 'could', 'be', '.', '[MASK]', 'listen', '[MASK]', 'what', 'party', 'leaders', 'said', 'following', 'the', 'election', 'of', 'the', 'speaker', 'of', 'the', 'house', 'of', 'commons', '.', 'their', 'speeches', 'were', 'rep', '##lete', 'with', 'references', 'to', 'the', 'c', '@', '-', '[MASK]', 'word', '[MASK]', 'collaboration', '.', 'over', 'and', 'over', ',', 'canadians', 'heard', 'their', 'political', '[MASK]', 'promise', 'to', 'have', 'received', '[MASK]', 'message', 'they', 'were', 'sent', 'in', '[MASK]', 'election', ':', 'voters', 'want', 'them', 'to', 'work', 'together', 'for', 'the', 'better', '##ment', 'of', 'our', 'country', '.', '[SEP]']
{9: 'just', 58: 'the', 64: 'the', 40: '@', 42: ':', 11: 'to', 5: 'it', 53: 'leaders'}
loss:  18.273632049560547
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 62.50%
Average score: 11.05
{'just': 'we', 'the': 'the', '@': '@', ':': 'for', 'to': 'to', 'it': 'it', 'leaders': 'parties'}
{'just': tensor(10.9707), 'the': tensor(12.0181), '@': tensor(10.8368), ':': tensor(9.4290), 'to': tensor(12.5086), 'it': tensor(9.9707), 'leaders': tensor(11.5964)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', 'be', '.', 'just', 'listen', 'to', 'what', 'party', 'leaders', 'said', 'following', '[MASK]', 'election', 'of', 'the', 'speaker', 'of', '[MASK]', 'house', 'of', 'commons', '.', 'their', 'speeches', 'were', 'rep', '##lete', 'with', 'references', '[MASK]', 'the', 'c', '@', '-', '[MASK]', 'word', ':', 'collaboration', '.', 'over', 'and', 'over', ',', 'canadians', 'heard', 'their', '[MASK]', 'leaders', 'promise', '[MASK]', 'have', '[MASK]', 'the', '[MASK]', 'they', 'were', 'sent', 'in', 'the', 'election', ':', 'voters', 'want', 'them', 'to', 'work', 'together', 'for', 'the', 'better', '##ment', 'of', 'our', 'country', '.', '[SEP]']
{57: 'received', 52: 'political', 17: 'the', 59: 'message', 40: '@', 35: 'to', 23: 'the', 55: 'to'}
loss:  19.330448150634766
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 75.00%
Average score: 12.26
{'received': 'all', 'political': 'party', 'the': 'the', 'message': 'message', '@': '@', 'to': 'to'}
{'received': tensor(10.5014), 'political': tensor(12.0317), 'the': tensor(15.0484), 'message': tensor(10.9087), '@': tensor(11.4579), 'to': tensor(13.6063)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'rhetoric', 'certainly', 'indicates', 'it', 'could', 'be', '.', 'just', 'listen', 'to', 'what', 'party', 'leaders', 'said', 'following', 'the', 'election', 'of', 'the', 'speaker', 'of', 'the', '[MASK]', 'of', 'commons', '.', '[MASK]', '[MASK]', 'were', 'rep', '##lete', 'with', 'references', 'to', 'the', 'c', '@', '-', '@', 'word', '[MASK]', 'collaboration', '.', 'over', 'and', 'over', ',', 'canadians', 'heard', 'their', 'political', 'leaders', 'promise', 'to', 'have', 'received', 'the', 'message', 'they', '[MASK]', 'sent', '[MASK]', 'the', 'election', ':', 'voters', 'want', '[MASK]', 'to', 'work', 'together', 'for', 'the', 'better', '##ment', 'of', '[MASK]', 'country', '.', '[SEP]']
{29: 'speeches', 63: 'in', 42: ':', 28: 'their', 61: 'were', 69: 'them', 24: 'house', 78: 'our'}
loss:  19.227121353149414
prediction_scores:  torch.Size([1, 82, 30522])
Accuracy: 37.50%
Average score: 12.93
{'speeches': 'interviews', 'in': 'before', ':': 'for', 'their': 'the', 'were': 'had', 'them': 'them', 'house': 'house', 'our': 'our'}
{'speeches': tensor(12.1827), 'in': tensor(12.5507), ':': tensor(9.4677), 'their': tensor(8.4003), 'were': tensor(13.8692), 'them': tensor(10.0672), 'house': tensor(23.6187), 'our': tensor(13.2681)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', '[MASK]', 'two', 'canadians', 'is', 'widely', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', 'executive', 'meng', 'wan', '##zhou', 'on', 'dec', '.', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', '[MASK]', '##wei', 'technologies', '[MASK]', 'arrested', 'in', 'vancouver', '[MASK]', 'the', 'request', '[MASK]', 'the', 'united', '[MASK]', ',', 'which', 'wants', 'her', 'extra', '##dit', '##ed', 'to', 'face', 'fraud', 'charges', 'for', '[MASK]', 'violating', 'sanctions', 'against', 'iran', '.', '[SEP]']
{51: 'of', 41: 'hua', 67: 'allegedly', 44: 'was', 54: 'states', 4: 'the', 48: 'at'}
loss:  19.83169174194336
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 100.00%
Average score: 13.96
{'of': 'of', 'hua': 'hua', 'allegedly': 'allegedly', 'was': 'was', 'states': 'states', 'the': 'the', 'at': 'at'}
{'of': tensor(15.6395), 'hua': tensor(13.9382), 'allegedly': tensor(11.3439), 'was': tensor(14.5263), 'states': tensor(13.0857), 'the': tensor(14.4962), 'at': tensor(14.7141)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', 'the', '[MASK]', 'canadians', 'is', '[MASK]', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', 'executive', 'meng', 'wan', '##zhou', 'on', 'dec', '[MASK]', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '##wei', 'technologies', '[MASK]', 'arrested', '[MASK]', 'vancouver', 'at', 'the', 'request', '[MASK]', 'the', 'united', 'states', ',', 'which', 'wants', '[MASK]', 'extra', '##dit', '##ed', 'to', 'face', 'fraud', 'charges', 'for', 'allegedly', 'violating', 'sanctions', 'against', 'iran', '.', '[SEP]']
{8: 'widely', 46: 'in', 30: '.', 51: 'of', 5: 'two', 58: 'her', 44: 'was'}
loss:  19.916519165039062
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 85.71%
Average score: 13.95
{'widely': 'widely', 'in': 'in', '.': '.', 'of': 'of', 'two': 'two', 'her': 'him', 'was': 'was'}
{'widely': tensor(13.3983), 'in': tensor(15.9497), '.': tensor(13.8157), 'of': tensor(16.7392), 'two': tensor(12.1793), 'her': tensor(11.8919), 'was': tensor(13.7012)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', 'the', 'two', 'canadians', 'is', 'widely', 'viewed', 'as', '[MASK]', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', 'executive', '[MASK]', 'wan', '##zhou', '[MASK]', 'dec', '.', '1', 'of', '[MASK]', 'year', '[MASK]', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '##wei', 'technologies', '[MASK]', 'arrested', 'in', 'vancouver', 'at', 'the', 'request', 'of', 'the', 'united', 'states', ',', 'which', 'wants', 'her', 'extra', '##dit', '##ed', 'to', 'face', 'fraud', 'charges', 'for', 'allegedly', 'violating', 'sanctions', '[MASK]', 'iran', '.', '[SEP]']
{11: 'retaliation', 25: 'meng', 35: '.', 28: 'on', 70: 'against', 33: 'last', 44: 'was'}
loss:  18.55790138244629
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 71.43%
Average score: 11.35
{'retaliation': 'retaliation', 'meng': 'liu', '.': '.', 'on': 'on', 'against': 'against', 'last': 'that', 'was': 'was'}
{'retaliation': tensor(12.5332), 'meng': tensor(7.6319), '.': tensor(10.6461), 'on': tensor(11.4829), 'against': tensor(13.7032), 'last': tensor(11.5605), 'was': tensor(11.9147)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', 'of', 'the', 'two', 'canadians', 'is', 'widely', 'viewed', 'as', 'retaliation', 'for', 'canada', "'", 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '[MASK]', 'tech', 'executive', 'meng', 'wan', '##zhou', 'on', '[MASK]', '.', '[MASK]', '[MASK]', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '##wei', 'technologies', 'was', 'arrested', 'in', 'vancouver', 'at', 'the', 'request', 'of', 'the', 'united', 'states', ',', 'which', 'wants', 'her', 'extra', '##dit', '##ed', '[MASK]', 'face', 'fraud', 'charges', 'for', 'allegedly', '[MASK]', 'sanctions', '[MASK]', 'iran', '.', '[SEP]']
{62: 'to', 29: 'dec', 22: '@', 32: 'of', 70: 'against', 31: '1', 68: 'violating'}
loss:  18.67481803894043
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 42.86%
Average score: 10.84
{'to': 'to', 'dec': 'inc', '@': 'year', 'of': 'the', 'against': 'against', '1': 'com', 'violating': 'violating'}
{'to': tensor(14.6527), 'dec': tensor(8.9662), '@': tensor(7.4790), 'of': tensor(7.8693), 'against': tensor(13.7587), '1': tensor(10.8426), 'violating': tensor(12.2832)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'detention', '[MASK]', 'the', 'two', 'canadians', 'is', 'widely', '[MASK]', 'as', 'retaliation', 'for', 'canada', '[MASK]', 's', 'arrest', 'of', 'chinese', 'high', '@', '-', '@', 'tech', 'executive', 'meng', 'wan', '##zhou', '[MASK]', 'dec', '.', '1', 'of', 'last', 'year', '.', 'the', 'chief', 'financial', 'officer', 'of', 'hua', '##wei', 'technologies', 'was', 'arrested', 'in', 'vancouver', 'at', 'the', 'request', 'of', '[MASK]', 'united', 'states', ',', 'which', 'wants', 'her', 'extra', '##dit', '##ed', 'to', 'face', 'fraud', 'charges', 'for', 'allegedly', 'violating', 'sanctions', '[MASK]', 'iran', '[MASK]', '[SEP]']
{3: 'of', 9: 'viewed', 14: "'", 52: 'the', 72: '.', 28: 'on', 70: 'against'}
loss:  23.802305221557617
prediction_scores:  torch.Size([1, 74, 30522])
Accuracy: 85.71%
Average score: 17.49
{'of': 'of', 'viewed': 'seen', "'": "'", 'the': 'the', '.': '.', 'on': 'on', 'against': 'against'}
{'of': tensor(17.1114), 'viewed': tensor(14.9119), "'": tensor(27.3539), 'the': tensor(16.2534), '.': tensor(20.3688), 'on': tensor(12.6426), 'against': tensor(13.7775)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'spin', '##ney', 'voiced', 'and', 'operated', 'the', 'two', 'popular', 'mu', '##ppet', '##s', 'for', '[MASK]', '50', '[MASK]', 'and', 'performed', 'them', 'almost', 'exclusively', 'into', 'his', '80s', 'on', 'the', 'pbs', '[MASK]', "'", 'television', '[MASK]', 'that', 'later', 'moved', 'to', 'hbo', '.', 'he', 'retired', 'from', '[MASK]', '##icing', 'big', 'bird', 'last', 'year', 'and', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '##rmi', '##t', 'the', 'frog', ',', 'took', 'over', '.', '"', 'i', "'", '[MASK]', 'always', '[MASK]', 'part', '[MASK]', 'him', ',', '"', 'spin', '##ney', 'said', 'in', '2014', '.', 'the', 'longtime', 'puppet', '##eer', 'received', '[MASK]', 'star', 'on', 'the', 'hollywood', 'walk', 'of', 'fame', 'in', '1994', '.', 'in', '[MASK]', ',', 'he', 'received', 'the', 'u', '.', 's', '.', 'library', '[MASK]', 'congress', "'", '[MASK]', 'living', 'legend', 'award', ',', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{30: 'show', 70: 'be', 27: 'kids', 68: 'll', 112: 's', 13: 'nearly', 87: 'a', 72: 'of', 15: 'years', 99: '2000', 109: 'of', 40: 'vo'}
loss:  21.055784225463867
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 50.00%
Average score: 13.58
{'show': 'program', 'be': 'a', 'kids': 'stations', 'll': 've', 's': 's', 'nearly': 'over', 'a': 'a', 'of': 'of', 'years': 'years', '2000': '2006', 'vo': 'vo'}
{'show': tensor(11.5220), 'be': tensor(11.4587), 'kids': tensor(12.3561), 'll': tensor(15.9759), 's': tensor(8.9423), 'nearly': tensor(11.2158), 'a': tensor(14.5918), 'of': tensor(17.5582), 'years': tensor(16.6101), '2000': tensor(11.3650), 'vo': tensor(17.7462)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'spin', '##ney', 'voiced', 'and', 'operated', '[MASK]', 'two', 'popular', '[MASK]', '##ppet', '##s', 'for', 'nearly', '50', 'years', 'and', 'performed', 'them', '[MASK]', '[MASK]', 'into', 'his', '80s', 'on', 'the', 'pbs', 'kids', "'", 'television', 'show', 'that', 'later', 'moved', 'to', 'hbo', '.', 'he', 'retired', 'from', 'vo', '##icing', 'big', 'bird', '[MASK]', 'year', 'and', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '##rmi', '##t', 'the', 'frog', ',', 'took', 'over', '[MASK]', '"', 'i', "'", 'll', 'always', 'be', 'part', 'of', '[MASK]', ',', '"', 'spin', '##ney', 'said', 'in', '2014', '.', 'the', '[MASK]', 'puppet', '##eer', 'received', 'a', 'star', '[MASK]', 'the', 'hollywood', 'walk', 'of', 'fame', 'in', '1994', '.', 'in', '[MASK]', '[MASK]', 'he', 'received', 'the', 'u', '.', 's', '.', 'library', 'of', 'congress', "'", 's', 'living', 'legend', 'award', ',', 'in', 'recognition', 'of', 'his', 'creative', '[MASK]', '.', '[SEP]']
{9: 'mu', 99: '2000', 64: '.', 19: 'almost', 122: 'contributions', 73: 'him', 89: 'on', 20: 'exclusively', 83: 'longtime', 6: 'the', 100: ',', 44: 'last'}
loss:  19.288246154785156
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 41.67%
Average score: 11.62
{'mu': 'mu', '2000': '2006', '.': '.', 'almost': 'from', 'contributions': 'work', 'him': 'it', 'on': 'on', 'exclusively': 'well', 'longtime': 'master', 'the': 'the', ',': ',', 'last': 'that'}
{'mu': tensor(14.4824), '2000': tensor(9.7882), '.': tensor(16.5177), 'almost': tensor(8.3108), 'contributions': tensor(11.0726), 'him': tensor(9.0000), 'on': tensor(16.9571), 'exclusively': tensor(10.9434), 'longtime': tensor(8.3148), 'the': tensor(11.3143), ',': tensor(10.5316), 'last': tensor(12.2511)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'spin', '[MASK]', 'voiced', 'and', 'operated', '[MASK]', 'two', 'popular', 'mu', '##ppet', '##s', 'for', 'nearly', '50', 'years', 'and', 'performed', 'them', 'almost', 'exclusively', '[MASK]', '[MASK]', '80s', 'on', 'the', 'pbs', 'kids', "'", 'television', 'show', 'that', 'later', 'moved', '[MASK]', 'hbo', '.', 'he', '[MASK]', 'from', 'vo', '##icing', 'big', 'bird', 'last', '[MASK]', 'and', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '##rmi', '##t', 'the', '[MASK]', ',', 'took', 'over', '.', '"', 'i', "'", 'll', '[MASK]', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', 'said', 'in', '[MASK]', '.', 'the', 'longtime', 'puppet', '##eer', '[MASK]', 'a', 'star', 'on', 'the', 'hollywood', 'walk', 'of', 'fame', 'in', '1994', '.', 'in', '2000', ',', '[MASK]', 'received', 'the', 'u', '.', 's', '.', 'library', 'of', 'congress', "'", 's', 'living', 'legend', 'award', ',', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{2: '##ney', 80: '2014', 45: 'year', 21: 'into', 69: 'always', 34: 'to', 60: 'frog', 6: 'the', 22: 'his', 101: 'he', 38: 'retired', 86: 'received'}
loss:  20.016603469848633
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 75.00%
Average score: 14.42
{'##ney': '##ney', '2014': '2006', 'year': 'year', 'into': 'in', 'always': 'always', 'to': 'to', 'frog': 'frog', 'the': 'the', 'his': 'the', 'he': 'he', 'retired': 'retired', 'received': 'received'}
{'##ney': tensor(19.5045), '2014': tensor(11.0714), 'year': tensor(11.3799), 'into': tensor(12.7916), 'always': tensor(16.8970), 'to': tensor(16.7568), 'frog': tensor(13.7677), 'the': tensor(11.3981), 'his': tensor(13.7475), 'he': tensor(13.3076), 'retired': tensor(16.6902), 'received': tensor(15.7237)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', '[MASK]', 'voiced', 'and', 'operated', 'the', 'two', 'popular', 'mu', '##ppet', '##s', 'for', 'nearly', '50', 'years', 'and', 'performed', 'them', 'almost', 'exclusively', 'into', 'his', '80s', 'on', 'the', 'pbs', 'kids', "'", 'television', 'show', 'that', '[MASK]', 'moved', 'to', 'hbo', '.', 'he', 'retired', 'from', 'vo', '##icing', 'big', '[MASK]', '[MASK]', 'year', 'and', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '[MASK]', '##t', 'the', 'frog', ',', 'took', '[MASK]', '.', '"', 'i', '[MASK]', 'll', 'always', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', 'said', 'in', '[MASK]', '.', 'the', 'longtime', 'puppet', '##eer', 'received', 'a', 'star', 'on', 'the', 'hollywood', 'walk', '[MASK]', 'fame', 'in', '1994', '.', 'in', '2000', '[MASK]', 'he', 'received', 'the', 'u', '.', 's', '.', 'library', 'of', 'congress', "'", 's', 'living', '[MASK]', 'award', ',', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{67: "'", 43: 'bird', 32: 'later', 44: 'last', 63: 'over', 57: '##rmi', 114: 'legend', 93: 'of', 80: '2014', 1: 'spin', 2: '##ney', 100: ','}
loss:  21.002077102661133
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 66.67%
Average score: 14.29
{"'": "'", 'bird': '##foot', 'later': 'later', 'last': 'that', 'over': 'over', '##rmi': '##rmi', 'legend': 'legend', 'of': 'of', '2014': '2006', 'spin': 'he', '##ney': '##ney', ',': ','}
{"'": tensor(22.3801), 'bird': tensor(7.1926), 'later': tensor(11.2117), 'last': tensor(12.2796), 'over': tensor(16.4439), '##rmi': tensor(21.3857), 'legend': tensor(12.3809), 'of': tensor(20.3794), '2014': tensor(11.5510), 'spin': tensor(6.7073), '##ney': tensor(13.5960), ',': tensor(15.9470)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'spin', '[MASK]', 'voiced', '[MASK]', 'operated', 'the', 'two', 'popular', 'mu', '[MASK]', '##s', 'for', 'nearly', '50', 'years', 'and', '[MASK]', 'them', 'almost', 'exclusively', 'into', 'his', '80s', 'on', 'the', 'pbs', 'kids', "'", 'television', 'show', 'that', 'later', 'moved', 'to', '[MASK]', '[MASK]', 'he', 'retired', 'from', 'vo', '##icing', 'big', 'bird', 'last', 'year', 'and', 'his', 'apprentice', ',', 'matt', 'vogel', ',', 'who', 'also', 'plays', 'ke', '##rmi', '[MASK]', 'the', 'frog', ',', 'took', 'over', '.', '"', 'i', "'", 'll', 'always', 'be', 'part', 'of', 'him', ',', '"', 'spin', '##ney', 'said', '[MASK]', '2014', '.', 'the', 'longtime', 'puppet', '##eer', 'received', 'a', 'star', 'on', 'the', '[MASK]', 'walk', 'of', 'fame', 'in', '1994', '.', 'in', '2000', ',', 'he', 'received', 'the', 'u', '[MASK]', 's', '.', 'library', 'of', 'congress', "'", '[MASK]', 'living', '[MASK]', 'award', ',', 'in', 'recognition', 'of', 'his', 'creative', 'contributions', '.', '[SEP]']
{2: '##ney', 114: 'legend', 10: '##ppet', 105: '.', 36: '.', 91: 'hollywood', 58: '##t', 35: 'hbo', 79: 'in', 4: 'and', 17: 'performed', 112: 's'}
loss:  20.539060592651367
prediction_scores:  torch.Size([1, 125, 30522])
Accuracy: 91.67%
Average score: 14.99
{'##ney': '##ney', 'legend': 'legend', '##ppet': '##ppet', '.': '.', 'hollywood': 'hollywood', '##t': '##t', 'hbo': 'pbs', 'in': 'in', 'and': 'and', 'performed': 'performed', 's': 's'}
{'##ney': tensor(19.9375), 'legend': tensor(12.0400), '##ppet': tensor(21.0892), '.': tensor(15.8608), 'hollywood': tensor(13.9491), '##t': tensor(20.8502), 'hbo': tensor(9.6230), 'in': tensor(14.6743), 'and': tensor(15.4324), 'performed': tensor(12.0584), 's': tensor(9.3957)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', 'have', 'been', '[MASK]', 'rampant', '[MASK]', '[MASK]', 'a', 'year', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", 's', '"', 'ann', '[MASK]', 'ho', '##rri', '##bilis', '"', 'of', '1992', ',', 'there', 'has', 'been', 'speculation', 'about', 'who', "'", 's', 'been', 'making', '[MASK]', 'decisions', 'at', 'buckingham', 'palace', ',', 'and', 'whether', 'the', '93', '@', '[MASK]', '@', 'year', '@', '-', '@', 'old', 'monarch', 'might', 'ultimately', 'step', 'further', 'back', 'from', 'her', 'role', 'in', 'the', 'not', '@', '-', '@', 'too', '@', '-', '@', 'distant', 'future', '.', 'headlines', 'in', 'the', '[MASK]', '.', 'k', '.', '[MASK]', '[MASK]', 'days', 'suggested', 'she', 'might', 'give', 'up', 'the', 'throne', 'in', 'two', 'years', '—', '[MASK]', 'age', '95', '[MASK]', '[SEP]']
{13: 'running', 89: 'u', 46: 'the', 15: '.', 94: 'recent', 107: 'at', 28: '##us', 93: 'in', 16: 'in', 57: '-', 110: '.'}
loss:  19.480104446411133
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 72.73%
Average score: 12.28
{'running': 'running', 'u': 'u', 'the': 'the', '.': ';', 'recent': 'these', 'at': 'at', '##us': '##us', 'in': 'in', '-': '-'}
{'running': tensor(12.2158), 'u': tensor(18.6598), 'the': tensor(9.3868), '.': tensor(18.9323), 'recent': tensor(7.4258), 'at': tensor(11.2681), '##us': tensor(13.1103), 'in': tensor(9.5318), '-': tensor(10.0124)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'amid', '[MASK]', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', 'have', 'been', 'running', 'rampant', '.', 'in', 'a', 'year', 'that', 'may', 'rival', 'queen', 'elizabeth', '[MASK]', 's', '"', 'ann', '##us', 'ho', '[MASK]', '##bilis', '"', 'of', '1992', ',', 'there', 'has', 'been', 'speculation', 'about', 'who', "'", 's', 'been', 'making', 'the', 'decisions', 'at', '[MASK]', 'palace', ',', 'and', 'whether', 'the', '93', '@', '-', '@', 'year', '@', '-', '@', 'old', 'monarch', 'might', 'ultimately', 'step', 'further', 'back', 'from', 'her', '[MASK]', 'in', 'the', '[MASK]', '@', '-', '[MASK]', 'too', '@', '-', '@', '[MASK]', 'future', '.', 'headlines', 'in', 'the', 'u', '[MASK]', 'k', '.', 'in', '[MASK]', 'days', 'suggested', 'she', 'might', 'give', 'up', 'the', 'throne', 'in', '[MASK]', 'years', '—', 'at', 'age', '95', '.', '[SEP]']
{30: '##rri', 49: 'buckingham', 90: '.', 94: 'recent', 75: 'not', 24: "'", 2: 'the', 104: 'two', 78: '@', 72: 'role', 83: 'distant'}
loss:  19.889915466308594
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 72.73%
Average score: 12.70
{'##rri': '##rri', 'buckingham': 'buckingham', '.': '.', 'recent': 'recent', 'not': '[', "'": "'", 'the': 'the', 'two': '@', '@': '@', 'role': 'role', 'distant': 'year'}
{'##rri': tensor(17.9081), 'buckingham': tensor(12.7849), '.': tensor(18.0551), 'recent': tensor(11.8476), 'not': tensor(7.1397), "'": tensor(21.3622), 'the': tensor(11.3800), 'two': tensor(9.8960), '@': tensor(10.6001), 'role': tensor(10.0284), 'distant': tensor(8.6755)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', 'scandal', 'swirling', '[MASK]', '[MASK]', 'andrew', ',', '[MASK]', 'rumours', 'have', 'been', 'running', 'rampant', '.', 'in', '[MASK]', 'year', 'that', '[MASK]', 'rival', 'queen', 'elizabeth', "'", 's', '"', 'ann', '##us', 'ho', '##rri', '##bilis', '"', 'of', '1992', ',', 'there', 'has', 'been', 'speculation', 'about', 'who', "'", 's', 'been', 'making', 'the', 'decisions', 'at', 'buckingham', 'palace', ',', 'and', 'whether', 'the', '93', '@', '-', '@', 'year', '@', '-', '@', 'old', 'monarch', 'might', 'ultimately', 'step', 'further', 'back', 'from', 'her', 'role', 'in', 'the', 'not', '@', '-', '@', 'too', '@', '[MASK]', '@', 'distant', 'future', '.', 'headlines', 'in', '[MASK]', 'u', '.', '[MASK]', '.', 'in', 'recent', 'days', 'suggested', '[MASK]', 'might', 'give', '[MASK]', 'the', 'throne', '[MASK]', 'two', 'years', '—', 'at', 'age', '95', '.', '[SEP]']
{6: 'prince', 91: 'k', 20: 'may', 100: 'up', 81: '-', 97: 'she', 5: 'around', 9: 'other', 88: 'the', 103: 'in', 17: 'a'}
loss:  18.88079261779785
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 54.55%
Average score: 11.86
{'prince': 'prince', 'k': 's', 'may': 'would', 'up': 'up', '-': '-', 'she': 'she', 'around': 'around', 'other': 'false', 'the': 'the', 'in': 'at', 'a': 'the'}
{'prince': tensor(8.8854), 'k': tensor(16.2952), 'may': tensor(10.1831), 'up': tensor(13.9032), '-': tensor(10.1921), 'she': tensor(10.2061), 'around': tensor(12.3296), 'other': tensor(8.0247), 'the': tensor(15.7628), 'in': tensor(10.3772), 'a': tensor(14.3137)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', 'scandal', 'swirling', 'around', 'prince', 'andrew', ',', 'other', 'rumours', 'have', 'been', 'running', 'rampant', '.', 'in', 'a', '[MASK]', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", 's', '"', '[MASK]', '##us', 'ho', '[MASK]', '[MASK]', '"', 'of', '1992', ',', '[MASK]', 'has', 'been', 'speculation', 'about', 'who', "'", 's', 'been', 'making', 'the', 'decisions', 'at', 'buckingham', 'palace', ',', 'and', 'whether', 'the', '[MASK]', '@', '-', '@', 'year', '@', '-', '@', 'old', 'monarch', 'might', 'ultimately', 'step', 'further', 'back', 'from', 'her', 'role', 'in', 'the', 'not', '@', '-', '@', 'too', '@', '-', '@', 'distant', 'future', '.', 'headlines', '[MASK]', 'the', 'u', '.', '[MASK]', '.', 'in', '[MASK]', 'days', 'suggested', 'she', 'might', 'give', '[MASK]', 'the', 'throne', 'in', 'two', 'years', '—', 'at', 'age', '95', '[MASK]', '[SEP]']
{31: '##bilis', 87: 'in', 36: 'there', 27: 'ann', 55: '93', 18: 'year', 100: 'up', 110: '.', 91: 'k', 94: 'recent', 30: '##rri'}
loss:  19.429929733276367
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 36.36%
Average score: 12.98
{'##bilis': '##us', 'in': 'in', 'there': 'there', 'ann': 'hoc', '93': 'not', 'year': 'case', 'up': 'up', '.': ';', 'k': 's', 'recent': 'recent', '##rri': '##mine'}
{'##bilis': tensor(8.7304), 'in': tensor(13.8957), 'there': tensor(16.6712), 'ann': tensor(10.1031), '93': tensor(9.5445), 'year': tensor(9.9181), 'up': tensor(15.9100), '.': tensor(20.3587), 'k': tensor(16.7484), 'recent': tensor(11.5209), '##rri': tensor(9.3843)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'amid', 'the', '[MASK]', 'swirling', 'around', 'prince', 'andrew', ',', 'other', '[MASK]', 'have', 'been', 'running', 'rampant', '.', 'in', 'a', 'year', 'that', 'may', 'rival', 'queen', 'elizabeth', "'", 's', '"', 'ann', '##us', 'ho', '##rri', '[MASK]', '"', 'of', '1992', ',', 'there', 'has', 'been', 'speculation', 'about', 'who', "'", 's', 'been', '[MASK]', 'the', 'decisions', 'at', 'buckingham', '[MASK]', ',', 'and', 'whether', 'the', '93', '@', '-', '@', 'year', '[MASK]', '[MASK]', '@', 'old', 'monarch', 'might', 'ultimately', 'step', 'further', 'back', 'from', 'her', 'role', 'in', 'the', 'not', '@', '-', '@', 'too', '[MASK]', '-', '@', 'distant', '[MASK]', '.', 'headlines', 'in', 'the', 'u', '.', 'k', '[MASK]', 'in', 'recent', '[MASK]', 'suggested', 'she', 'might', 'give', 'up', 'the', 'throne', 'in', 'two', 'years', '—', 'at', 'age', '95', '.', '[SEP]']
{10: 'rumours', 95: 'days', 80: '@', 31: '##bilis', 60: '@', 50: 'palace', 3: 'scandal', 84: 'future', 92: '.', 61: '-', 45: 'making'}
loss:  18.03189468383789
prediction_scores:  torch.Size([1, 112, 30522])
Accuracy: 54.55%
Average score: 12.54
{'rumours': 'rumours', 'days': 'years', '@': '-', '##bilis': '##s', 'palace': 'palace', 'scandal': 'rumours', 'future': 'future', '.': '.', '-': '-', 'making': 'making'}
{'rumours': tensor(13.4263), 'days': tensor(13.4251), '@': tensor(8.8701), '##bilis': tensor(12.8398), 'palace': tensor(18.2874), 'scandal': tensor(11.4013), 'future': tensor(8.7408), '.': tensor(13.9656), '-': tensor(10.3144), 'making': tensor(14.0939)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '##is', 'was', 'diagnosed', 'with', 'ho', '##d', '##g', '##kin', "'", 's', 'disease', 'last', 'april', 'and', 'has', 'had', 'to', 'undergo', 'some', '[MASK]', 'uncomfortable', 'medical', 'procedures', 'at', 'the', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '[MASK]', '-', '@', 'year', '@', '-', '@', 'old', 'has', 'had', 'a', 'cat', '[MASK]', '##er', 'inserted', 'into', 'a', 'peripheral', '[MASK]', 'and', 'threaded', 'through', 'to', 'her', 'heart', ',', 'in', 'order', 'for', '[MASK]', '[MASK]', '##ving', '[MASK]', 'to', 'be', '[MASK]', '.', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', 'growth', 'was', 'discovered', 'on', 'her', '[MASK]', 'thigh', '.', '[SEP]']
{42: '@', 71: 'life', 77: 'injected', 26: 'pretty', 74: 'treatments', 72: '##sa', 60: 'vein', 91: 'inner', 54: '##het'}
loss:  17.793420791625977
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 11.11%
Average score: 11.99
{'@': 'years', 'life': 'cat', 'injected': 'performed', 'pretty': 'very', 'treatments': 'surgery', '##sa': '##lie', 'vein': 'artery', 'inner': 'left', '##het': '##het'}
{'@': tensor(8.5826), 'life': tensor(7.4559), 'injected': tensor(10.7611), 'pretty': tensor(11.4032), 'treatments': tensor(7.4765), '##sa': tensor(14.4338), 'vein': tensor(15.6227), 'inner': tensor(13.6746), '##het': tensor(18.5326)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '[MASK]', 'le', '##fra', '##nco', '##is', '[MASK]', 'diagnosed', 'with', 'ho', '[MASK]', '##g', '##kin', "'", 's', 'disease', 'last', 'april', 'and', 'has', 'had', 'to', 'undergo', 'some', 'pretty', 'uncomfortable', 'medical', 'procedures', 'at', '[MASK]', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '@', '-', '@', '[MASK]', '[MASK]', '-', '@', 'old', 'has', 'had', '[MASK]', '[MASK]', '##het', '##er', 'inserted', 'into', 'a', 'peripheral', 'vein', 'and', 'threaded', 'through', 'to', '[MASK]', 'heart', ',', 'in', 'order', 'for', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '.', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', 'growth', 'was', 'discovered', 'on', 'her', 'inner', 'thigh', '.', '[SEP]']
{3: '##y', 45: 'year', 52: 'a', 8: 'was', 12: '##d', 31: 'the', 46: '@', 65: 'her', 53: 'cat'}
loss:  20.63978385925293
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 77.78%
Average score: 13.44
{'##y': '-', 'year': '-', 'a': 'a', 'was': 'was', '##d': '##d', 'the': 'the', '@': '@', 'her': 'her', 'cat': 'cat'}
{'##y': tensor(9.3502), 'year': tensor(11.6410), 'a': tensor(12.6899), 'was': tensor(14.7551), '##d': tensor(16.9375), 'the': tensor(13.3447), '@': tensor(10.8075), 'her': tensor(13.5041), 'cat': tensor(17.9211)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '##is', 'was', 'diagnosed', 'with', 'ho', '[MASK]', '##g', '##kin', '[MASK]', 's', '[MASK]', 'last', 'april', 'and', 'has', '[MASK]', 'to', 'undergo', 'some', 'pretty', 'uncomfortable', 'medical', 'procedures', 'at', '[MASK]', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '@', '-', '@', 'year', '@', '-', '@', 'old', 'has', 'had', 'a', 'cat', '##het', '##er', 'inserted', 'into', 'a', '[MASK]', 'vein', 'and', 'threaded', 'through', 'to', 'her', 'heart', ',', 'in', 'order', 'for', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '.', 'she', 'underwent', 'a', 'bio', '[MASK]', 'when', '[MASK]', 'growth', 'was', 'discovered', '[MASK]', 'her', 'inner', 'thigh', '.', '[SEP]']
{17: 'disease', 12: '##d', 15: "'", 89: 'on', 85: 'a', 83: '##psy', 59: 'peripheral', 31: 'the', 22: 'had'}
loss:  20.531957626342773
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 66.67%
Average score: 14.40
{'disease': 'disease', '##d': '##d', "'": "'", 'on': 'in', 'a': 'abnormal', '##psy': '##psy', 'peripheral': 'portal', 'the': 'the', 'had': 'had'}
{'disease': tensor(14.9814), '##d': tensor(17.0158), "'": tensor(17.5497), 'on': tensor(13.1768), 'a': tensor(9.0117), '##psy': tensor(19.1582), 'peripheral': tensor(9.9385), 'the': tensor(13.3771), 'had': tensor(15.3688)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '##is', 'was', 'diagnosed', 'with', 'ho', '##d', '##g', '##kin', "'", '[MASK]', 'disease', 'last', '[MASK]', 'and', 'has', 'had', 'to', '[MASK]', 'some', 'pretty', 'uncomfortable', 'medical', 'procedures', 'at', '[MASK]', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '@', '-', '@', 'year', '@', '-', '[MASK]', 'old', 'has', 'had', '[MASK]', 'cat', '##het', '[MASK]', '[MASK]', 'into', 'a', 'peripheral', 'vein', 'and', 'threaded', 'through', 'to', 'her', 'heart', ',', 'in', 'order', 'for', 'life', '##sa', '##ving', 'treatments', 'to', 'be', 'injected', '.', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', 'growth', 'was', 'discovered', 'on', 'her', 'inner', '[MASK]', '.', '[SEP]']
{24: 'undergo', 52: 'a', 16: 's', 56: 'inserted', 19: 'april', 31: 'the', 55: '##er', 92: 'thigh', 48: '@'}
loss:  20.564149856567383
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 77.78%
Average score: 14.11
{'undergo': 'undergo', 'a': 'a', 's': 's', 'inserted': 'inserted', 'april': 'year', 'the': 'the', '##er': '##er', 'thigh': 'thigh', '@': 'year'}
{'undergo': tensor(14.8246), 'a': tensor(10.6385), 's': tensor(17.1894), 'inserted': tensor(11.7201), 'april': tensor(13.2591), 'the': tensor(13.2481), '##er': tensor(18.9211), 'thigh': tensor(11.4156), '@': tensor(15.7634)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/CBC05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'ko', '##ral', '##y', 'le', '##fra', '##nco', '##is', 'was', 'diagnosed', 'with', 'ho', '##d', '##g', '##kin', "'", 's', '[MASK]', '[MASK]', 'april', 'and', 'has', 'had', 'to', 'undergo', '[MASK]', 'pretty', 'uncomfortable', 'medical', 'procedures', 'at', 'the', 'montreal', 'children', "'", 's', 'hospital', 'since', 'then', '.', 'the', 'nine', '@', '-', '@', 'year', '@', '-', '@', 'old', '[MASK]', 'had', 'a', 'cat', '##het', '##er', 'inserted', 'into', '[MASK]', 'peripheral', 'vein', 'and', 'threaded', 'through', '[MASK]', 'her', 'heart', ',', 'in', 'order', '[MASK]', 'life', '##sa', '##ving', 'treatments', 'to', 'be', '[MASK]', '.', 'she', 'underwent', 'a', 'bio', '##psy', 'when', 'a', 'growth', 'was', '[MASK]', 'on', 'her', 'inner', 'thigh', '.', '[SEP]']
{77: 'injected', 64: 'to', 70: 'for', 18: 'last', 88: 'discovered', 17: 'disease', 25: 'some', 58: 'a', 50: 'has'}
loss:  19.27471160888672
prediction_scores:  torch.Size([1, 95, 30522])
Accuracy: 55.56%
Average score: 12.93
{'injected': 'performed', 'to': 'to', 'for': 'for', 'last': 'in', 'discovered': 'detected', 'disease': 'disease', 'some': 'some', 'a': 'a', 'has': 'woman'}
{'injected': tensor(12.1535), 'to': tensor(13.0187), 'for': tensor(14.6022), 'last': tensor(11.2711), 'discovered': tensor(12.2663), 'disease': tensor(15.4381), 'some': tensor(13.7277), 'a': tensor(13.1084), 'has': tensor(10.7964)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '@', '-', '@', 'scale', 'study', 'looking', 'at', 'transplant', 'outcomes', 'across', 'age', 'groups', 'in', 'multiple', '[MASK]', '##elo', '##ma', 'patients', 'found', 'similar', 'rates', 'of', '[MASK]', '##rel', '##ap', '##se', 'mortality', ',', 're', '##la', '[MASK]', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', '[MASK]', ',', '[MASK]', 'overall', 'survival', 'between', 'patients', 'who', 'were', 'aged', '70', 'years', 'and', 'older', 'and', 'those', 'who', 'were', 'aged', '60', '@', '[MASK]', '@', '69', 'years', '.', '[SEP]']
{33: '##pse', 25: 'non', 17: 'my', 42: 'survival', 63: '-', 44: 'and'}
loss:  22.276018142700195
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 100.00%
Average score: 15.59
{'##pse': '##pse', 'non': 'non', 'my': 'my', 'survival': 'survival', '-': '-', 'and': 'and'}
{'##pse': tensor(24.4987), 'non': tensor(13.6062), 'my': tensor(16.6004), 'survival': tensor(11.9045), '-': tensor(12.5700), 'and': tensor(14.3763)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '@', '-', '@', 'scale', 'study', 'looking', 'at', 'transplant', 'outcomes', 'across', 'age', 'groups', 'in', 'multiple', 'my', '##elo', '##ma', 'patients', '[MASK]', 'similar', 'rates', 'of', 'non', '[MASK]', '##ap', '##se', '[MASK]', ',', 're', '##la', '##pse', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', 'survival', ',', '[MASK]', 'overall', 'survival', 'between', 'patients', 'who', 'were', 'aged', '70', 'years', '[MASK]', 'older', 'and', 'those', 'who', 'were', 'aged', '60', '@', '-', '[MASK]', '69', 'years', '.', '[SEP]']
{29: 'mortality', 54: 'and', 26: '##rel', 44: 'and', 21: 'found', 64: '@'}
loss:  19.896276473999023
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 33.33%
Average score: 13.91
{'mortality': 'survival', 'and': 'and', '##rel': '##coll', 'found': 'showed', '@': '@'}
{'mortality': tensor(12.2685), 'and': tensor(14.7403), '##rel': tensor(15.0298), 'found': tensor(12.8634), '@': tensor(14.6452)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '@', '-', '@', 'scale', 'study', 'looking', 'at', 'transplant', 'outcomes', 'across', '[MASK]', 'groups', 'in', 'multiple', '[MASK]', '##elo', '##ma', 'patients', 'found', 'similar', 'rates', 'of', 'non', '##rel', '##ap', '[MASK]', 'mortality', ',', 're', '##la', '##pse', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', 'survival', ',', 'and', 'overall', 'survival', 'between', '[MASK]', 'who', 'were', 'aged', '[MASK]', 'years', 'and', 'older', 'and', 'those', 'who', 'were', 'aged', '[MASK]', '@', '-', '@', '69', 'years', '.', '[SEP]']
{48: 'patients', 52: '70', 13: 'age', 17: 'my', 61: '60', 28: '##se'}
loss:  20.851560592651367
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 16.67%
Average score: 13.91
{'patients': 'those', '70': '@', 'age': 'two', 'my': 'my', '60': 'from', '##se': '##ious'}
{'patients': tensor(15.7010), '70': tensor(15.5637), 'age': tensor(11.1405), 'my': tensor(16.4809), '60': tensor(10.2425), '##se': tensor(14.3198)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'a', 'large', '@', '-', '@', 'scale', '[MASK]', 'looking', 'at', 'transplant', 'outcomes', '[MASK]', 'age', 'groups', 'in', 'multiple', 'my', '##elo', '##ma', 'patients', 'found', 'similar', 'rates', 'of', 'non', '[MASK]', '##ap', '##se', 'mortality', ',', 're', '[MASK]', '##pse', '/', 'progression', ',', 'progression', '@', '-', '@', 'free', 'survival', ',', 'and', 'overall', 'survival', 'between', 'patients', 'who', 'were', 'aged', '70', 'years', 'and', '[MASK]', 'and', 'those', 'who', 'were', 'aged', '60', '[MASK]', '-', '@', '69', 'years', '.', '[SEP]']
{12: 'across', 26: '##rel', 55: 'older', 62: '@', 7: 'study', 32: '##la'}
loss:  20.406211853027344
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 50.00%
Average score: 14.30
{'across': 'between', '##rel': '##coll', 'older': 'above', '@': '@', 'study': 'study', '##la': '##la'}
{'across': tensor(11.9618), '##rel': tensor(15.4710), 'older': tensor(11.7699), '@': tensor(11.2622), 'study': tensor(12.8345), '##la': tensor(22.4775)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'large', '@', '-', '@', 'scale', 'study', 'looking', 'at', '[MASK]', 'outcomes', 'across', 'age', 'groups', 'in', 'multiple', 'my', '##elo', '##ma', 'patients', 'found', 'similar', 'rates', 'of', 'non', '##rel', '##ap', '##se', 'mortality', ',', 're', '##la', '##pse', '/', 'progression', ',', 'progression', '[MASK]', '-', '@', 'free', 'survival', ',', '[MASK]', 'overall', 'survival', 'between', 'patients', 'who', 'were', '[MASK]', '70', 'years', '[MASK]', 'older', 'and', 'those', 'who', 'were', 'aged', '60', '@', '-', '@', '69', 'years', '.', '[SEP]']
{10: 'transplant', 38: '@', 1: 'a', 44: 'and', 54: 'and', 51: 'aged'}
loss:  21.852540969848633
prediction_scores:  torch.Size([1, 69, 30522])
Accuracy: 66.67%
Average score: 14.24
{'transplant': 'health', '@': '@', 'a': 'a', 'and': 'or', 'aged': 'aged'}
{'transplant': tensor(9.3829), '@': tensor(16.0230), 'a': tensor(13.8269), 'and': tensor(16.4936), 'aged': tensor(15.4826)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', 'without', 'facial', 'der', '##mat', '##itis', ',', 'men', 'with', 'facial', 'der', '##mat', '##itis', 'were', '[MASK]', '[MASK]', 'to', '[MASK]', 'to', '[MASK]', '##thy', '##lam', '##ino', '##pro', '##py', '##lam', '[MASK]', '(', 'a', 'surf', '##act', '##ant', ')', 'or', 'para', '##ph', '##en', '##yle', '##ned', '[MASK]', '##ine', '(', '[MASK]', 'constituent', 'of', 'hair', '/', 'mustache', '/', 'beard', '/', 'eyebrows', 'dye', ')', 'and', 'less', 'likely', 'to', 'have', 'clinical', '##ly', 'relevant', 'reactions', 'to', 'traditional', 'all', '##er', '[MASK]', 'pre', '##ser', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '[MASK]', '##gens', 'included', 'personal', 'care', 'products', 'and', 'topical', 'medications', ',', 'while', 'top', '[MASK]', 'of', 'ir', '##ritan', '##ts', 'included', 'personal', '@', '-', '@', 'care', 'products', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{17: 'more', 22: 'dime', 18: 'likely', 29: '##ine', 42: '##iam', 92: 'sources', 45: 'a', 70: '##genic', 80: '##er', 20: 'react'}
loss:  21.57309913635254
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 70.00%
Average score: 16.46
{'more': 'less', 'dime': 'dime', 'likely': 'likely', '##ine': '##ine', '##iam': '##iam', 'sources': 'sources', 'a': 'a', '##genic': '##gen', '##er': '##er', 'react': 'respond'}
{'more': tensor(14.0374), 'dime': tensor(15.9626), 'likely': tensor(13.4116), '##ine': tensor(20.0917), '##iam': tensor(14.6008), 'sources': tensor(17.3098), 'a': tensor(13.2596), '##genic': tensor(19.4532), '##er': tensor(22.3694), 'react': tensor(14.0539)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', '[MASK]', 'facial', 'der', '##mat', '##itis', ',', 'men', 'with', 'facial', 'der', '##mat', '##itis', '[MASK]', 'more', 'likely', 'to', '[MASK]', 'to', 'dime', '##thy', '##lam', '##ino', '##pro', '##py', '##lam', '##ine', '(', 'a', 'surf', '##act', '##ant', ')', 'or', 'para', '##ph', '##en', '##yle', '##ned', '##iam', '[MASK]', '(', 'a', 'constituent', 'of', 'hair', '/', '[MASK]', '[MASK]', 'beard', '/', 'eyebrows', 'dye', ')', 'and', 'less', 'likely', 'to', 'have', 'clinical', '##ly', 'relevant', 'reactions', 'to', 'traditional', 'all', '##er', '##genic', 'pre', '##ser', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '##er', '##gens', '[MASK]', 'personal', 'care', 'products', 'and', '[MASK]', 'medications', ',', 'while', 'top', 'sources', 'of', 'ir', '##ritan', '##ts', 'included', 'personal', '@', '[MASK]', '@', 'care', 'products', '[MASK]', 'industrial', 'chemicals', '.', '[SEP]']
{104: 'and', 43: '##ine', 82: 'included', 4: 'without', 50: 'mustache', 20: 'react', 100: '-', 51: '/', 87: 'topical', 16: 'were'}
loss:  20.71628189086914
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 50.00%
Average score: 14.63
{'and': 'and', '##ine': '##ine', 'included': 'included', 'without': 'with', 'mustache': 'beard', 'react': 'respond', '-': 'and', '/': '/', 'topical': 'prescription', 'were': 'were'}
{'and': tensor(15.5278), '##ine': tensor(20.1760), 'included': tensor(17.3016), 'without': tensor(17.3669), 'mustache': tensor(12.3980), 'react': tensor(14.5438), '-': tensor(10.0748), '/': tensor(10.3323), 'topical': tensor(10.5908), 'were': tensor(18.0180)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', 'without', 'facial', 'der', '##mat', '##itis', ',', 'men', 'with', 'facial', 'der', '##mat', '##itis', 'were', 'more', 'likely', 'to', '[MASK]', '[MASK]', 'dime', '##thy', '##lam', '##ino', '##pro', '##py', '##lam', '[MASK]', '(', 'a', 'surf', '##act', '##ant', ')', '[MASK]', 'para', '##ph', '##en', '##yle', '##ned', '##iam', '[MASK]', '(', 'a', '[MASK]', 'of', 'hair', '/', 'mustache', '/', 'beard', '/', 'eyebrows', 'dye', ')', 'and', 'less', 'likely', 'to', 'have', 'clinical', '##ly', 'relevant', 'reactions', 'to', 'traditional', '[MASK]', '##er', '##genic', 'pre', '[MASK]', '##vati', '[MASK]', '.', 'top', 'sources', 'of', 'all', '[MASK]', '##gens', 'included', 'personal', 'care', 'products', 'and', 'topical', 'medications', ',', 'while', 'top', 'sources', 'of', 'ir', '##ritan', '##ts', 'included', 'personal', '@', '-', '@', 'care', 'products', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{21: 'to', 36: 'or', 80: '##er', 29: '##ine', 74: '##ves', 20: 'react', 68: 'all', 72: '##ser', 43: '##ine', 46: 'constituent'}
loss:  21.086360931396484
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 70.00%
Average score: 14.75
{'to': 'either', 'or': 'or', '##er': '##er', '##ine': '##ine', '##ves': '##ves', 'react': 'receive', 'all': 'all', '##ser': '##ser', 'constituent': 'component'}
{'to': tensor(10.2612), 'or': tensor(13.2113), '##er': tensor(15.8114), '##ine': tensor(17.9702), '##ves': tensor(17.7305), 'react': tensor(8.6663), 'all': tensor(17.8094), '##ser': tensor(19.8038), 'constituent': tensor(11.5221)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', '[MASK]', 'facial', 'der', '##mat', '##itis', ',', 'men', 'with', 'facial', 'der', '##mat', '##itis', '[MASK]', 'more', 'likely', 'to', 'react', 'to', 'dime', '##thy', '[MASK]', '##ino', '##pro', '##py', '##lam', '##ine', '(', 'a', 'surf', '##act', '##ant', ')', 'or', 'para', '##ph', '##en', '[MASK]', '##ned', '##iam', '##ine', '(', 'a', 'constituent', 'of', 'hair', '[MASK]', 'mustache', '/', 'beard', '[MASK]', 'eyebrows', 'dye', ')', 'and', '[MASK]', 'likely', 'to', '[MASK]', 'clinical', '##ly', 'relevant', 'reactions', 'to', 'traditional', 'all', '##er', '##genic', 'pre', '##ser', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '##er', '##gens', 'included', 'personal', 'care', 'products', 'and', 'topical', 'medications', ',', 'while', 'top', 'sources', 'of', 'ir', '[MASK]', '##ts', 'included', '[MASK]', '@', '-', '@', 'care', 'products', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{49: '/', 53: '/', 40: '##yle', 58: 'less', 95: '##ritan', 61: 'have', 4: 'without', 98: 'personal', 16: 'were', 24: '##lam'}
loss:  20.794189453125
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 70.00%
Average score: 15.82
{'/': '/', '##yle': '##yle', 'less': 'more', '##ritan': '##ritan', 'have': 'have', 'without': 'with', 'personal': 'standard', 'were': 'were', '##lam': '##lam'}
{'/': tensor(12.6597), '##yle': tensor(16.8221), 'less': tensor(14.7936), '##ritan': tensor(22.8117), 'have': tensor(12.5955), 'without': tensor(17.5466), 'personal': tensor(7.1719), 'were': tensor(17.3727), '##lam': tensor(20.5745)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'compared', 'with', 'men', 'without', 'facial', 'der', '##mat', '[MASK]', '[MASK]', 'men', 'with', 'facial', 'der', '##mat', '##itis', 'were', 'more', 'likely', 'to', 'react', 'to', 'dime', '##thy', '##lam', '[MASK]', '##pro', '##py', '##lam', '[MASK]', '(', 'a', 'surf', '##act', '##ant', ')', 'or', 'para', '##ph', '##en', '##yle', '[MASK]', '##iam', '##ine', '(', 'a', 'constituent', 'of', 'hair', '[MASK]', 'mustache', '/', 'beard', '/', '[MASK]', 'dye', ')', 'and', 'less', 'likely', '[MASK]', 'have', 'clinical', '##ly', 'relevant', 'reactions', 'to', 'traditional', 'all', '##er', '##genic', '[MASK]', '##ser', '##vati', '##ves', '.', 'top', 'sources', 'of', 'all', '##er', '##gens', 'included', 'personal', 'care', 'products', 'and', 'topical', 'medications', ',', 'while', 'top', 'sources', 'of', '[MASK]', '##ritan', '##ts', 'included', 'personal', '@', '-', '@', 'care', 'products', 'and', 'industrial', 'chemicals', '.', '[SEP]']
{49: '/', 54: 'eyebrows', 9: ',', 8: '##itis', 71: 'pre', 94: 'ir', 25: '##ino', 60: 'to', 29: '##ine', 41: '##ned'}
loss:  23.55708122253418
prediction_scores:  torch.Size([1, 109, 30522])
Accuracy: 90.00%
Average score: 17.15
{'/': '/', 'eyebrows': 'hair', ',': ',', '##itis': '##itis', 'pre': 'pre', 'ir': 'ir', '##ino': '##ino', 'to': 'to', '##ine': '##ine', '##ned': '##ned'}
{'/': tensor(11.7081), 'eyebrows': tensor(12.0934), ',': tensor(14.4348), '##itis': tensor(24.1847), 'pre': tensor(15.2789), 'ir': tensor(18.3761), '##ino': tensor(18.9771), 'to': tensor(18.9609), '##ine': tensor(21.0491), '##ned': tensor(16.4563)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'in', '[MASK]', '[MASK]', 'inflammatory', 'bow', '##el', 'disease', '(', 'ib', '##d', ')', ',', 'a', 'long', 'course', 'of', 'oral', '[MASK]', '[MASK]', '##y', '##cin', 'is', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '[MASK]', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', '[MASK]', ',', 'a', 'retrospective', 'chart', 'review', 'reveals', '[MASK]', '"', 'in', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', 'is', 'associated', 'with', 'worse', '[MASK]', '-', 'e', '.', 'g', '.', ',', '[MASK]', 'likelihood', 'for', 'hospital', '##ization', 'or', '[MASK]', '[MASK]', 'lower', 'likelihood', 'to', 'respond', 'to', 'medical', 'therapy', 'and', ',', 'as', 'we', 'showed', 'previously', '(', 'http', ':', '/', '/', 'bit', '.', '[MASK]', '##y', '/', '2', '##lp', '##k', '##c', '[MASK]', '##k', ')', ',', 'increased', 'risk', 'for', 'j', 'pouch', 'complications', 'if', 'a', 'patient', 'had', '[MASK]', 'di', '##ff', 'before', 'their', 'cole', '##ct', '##omy', ',', '"', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', 'reuters', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', 'that', 'having', 'one', 'c', 'di', '##ff', '[MASK]', 'increases', 'the', 'likelihood', '[MASK]', 'having', 'another', ',', 'and', 'having', 'two', '[MASK]', 'the', 'likelihood', 'of', 'a', 'third', 'substantially', '.', '"', '[SEP]']
{18: 'van', 30: '##rid', 72: 'greater', 167: 'increases', 100: 'l', 44: 'course', 79: ',', 107: '##3', 121: 'c', 3: 'with', 78: 'surgery', 2: 'patients', 51: '.', 19: '##com', 65: 'outcomes', 156: 'infection', 160: 'of'}
loss:  18.98099708557129
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 58.82%
Average score: 12.43
{'van': 'am', '##rid': '##rid', 'greater': 'lower', 'increases': 'increases', 'l': 'jp', 'course': 'course', ',': ',', '##3': '##2', 'c': 'c', 'with': 'with', 'surgery': ',', 'patients': 'patients', '.': 'that', '##com': '##com', 'outcomes': 'outcomes', 'infection': 'significantly', 'of': 'of'}
{'van': tensor(6.3350), '##rid': tensor(16.5614), 'greater': tensor(12.9344), 'increases': tensor(16.0234), 'l': tensor(9.6643), 'course': tensor(14.4665), ',': tensor(11.2848), '##3': tensor(11.0067), 'c': tensor(10.4493), 'with': tensor(11.8841), 'surgery': tensor(7.5470), 'patients': tensor(11.9906), '.': tensor(12.7023), '##com': tensor(17.6543), 'outcomes': tensor(14.4636), 'infection': tensor(8.9321), 'of': tensor(17.3819)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'in', 'patients', '[MASK]', 'inflammatory', 'bow', '##el', 'disease', '(', 'ib', '##d', '[MASK]', ',', 'a', 'long', 'course', 'of', 'oral', 'van', '##com', '##y', '##cin', 'is', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '##rid', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', '[MASK]', 'short', 'course', ',', 'a', 'retrospective', 'chart', 'review', 'reveals', '.', '"', 'in', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', '[MASK]', 'associated', 'with', '[MASK]', 'outcomes', '-', 'e', '.', 'g', '[MASK]', ',', '[MASK]', 'likelihood', '[MASK]', 'hospital', '[MASK]', 'or', 'surgery', ',', '[MASK]', 'likelihood', 'to', 'respond', 'to', 'medical', 'therapy', 'and', ',', '[MASK]', 'we', '[MASK]', 'previously', '(', 'http', ':', '[MASK]', '/', 'bit', '.', '[MASK]', '##y', '/', '2', '##lp', '##k', '##c', '##3', '##k', '[MASK]', ',', 'increased', 'risk', 'for', 'j', 'pouch', 'complications', 'if', 'a', 'patient', 'had', 'c', 'di', '##ff', 'before', 'their', 'cole', '##ct', '##omy', ',', '"', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', 'reuters', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', 'that', 'having', 'one', 'c', 'di', '##ff', 'infection', 'increases', 'the', 'likelihood', 'of', 'having', 'another', ',', 'and', '[MASK]', 'two', 'increases', 'the', 'likelihood', 'of', 'a', 'third', 'substantially', '.', '[MASK]', '[SEP]']
{70: '.', 74: 'for', 175: '"', 72: 'greater', 91: 'showed', 3: 'with', 100: 'l', 61: 'is', 64: 'worse', 76: '##ization', 11: ')', 80: 'lower', 96: '/', 165: 'having', 109: ')', 89: 'as', 42: 'a'}
loss:  21.387359619140625
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 64.71%
Average score: 14.27
{'.': '.', 'for': 'of', '"': '"', 'greater': 'reduced', 'showed': 'noted', 'with': 'with', 'l': 'jp', 'is': 'is', 'worse': 'improved', '##ization': '##ization', ')': ')', 'lower': 'reduced', '/': '/', 'having': 'having', 'as': 'as', 'a': 'a'}
{'.': tensor(17.5828), 'for': tensor(15.3819), '"': tensor(10.6779), 'greater': tensor(12.4374), 'showed': tensor(12.5038), 'with': tensor(17.5037), 'l': tensor(9.4914), 'is': tensor(15.1185), 'worse': tensor(11.1515), '##ization': tensor(15.8829), ')': tensor(15.1240), 'lower': tensor(12.3926), '/': tensor(22.3074), 'having': tensor(12.4735), 'as': tensor(14.2343), 'a': tensor(14.0586)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'patients', '[MASK]', 'inflammatory', 'bow', '##el', 'disease', '(', 'ib', '##d', ')', ',', 'a', 'long', 'course', 'of', 'oral', 'van', '[MASK]', '##y', '##cin', '[MASK]', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '##rid', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', 'course', ',', 'a', 'retrospective', 'chart', '[MASK]', 'reveals', '.', '"', 'in', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', 'is', 'associated', '[MASK]', 'worse', 'outcomes', '-', 'e', '.', 'g', '.', ',', 'greater', 'likelihood', 'for', '[MASK]', '##ization', 'or', '[MASK]', ',', 'lower', 'likelihood', 'to', 'respond', 'to', 'medical', 'therapy', '[MASK]', ',', 'as', 'we', 'showed', 'previously', '(', 'http', ':', '/', '/', 'bit', '.', 'l', '##y', '/', '2', '##lp', '##k', '##c', '##3', '##k', ')', '[MASK]', 'increased', 'risk', 'for', 'j', 'pouch', '[MASK]', 'if', 'a', '[MASK]', 'had', 'c', 'di', '[MASK]', 'before', 'their', 'cole', '##ct', '##omy', '[MASK]', '"', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', 'reuters', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', 'that', 'having', 'one', 'c', 'di', '##ff', 'infection', 'increases', 'the', 'likelihood', '[MASK]', 'having', 'another', '[MASK]', 'and', 'having', 'two', 'increases', 'the', 'likelihood', 'of', 'a', '[MASK]', 'substantially', '.', '"', '[SEP]']
{1: 'in', 129: ',', 87: 'and', 123: '##ff', 63: 'with', 19: '##com', 172: 'third', 78: 'surgery', 3: 'with', 163: ',', 75: 'hospital', 116: 'complications', 49: 'review', 119: 'patient', 160: 'of', 22: 'is', 110: ','}
loss:  20.74529266357422
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 76.47%
Average score: 14.28
{'in': 'in', ',': ',', 'and': 'and', '##ff': '##ff', 'with': 'with', '##com': '##com', 'third': 'third', 'surgery': 'death', 'hospital': 'hospital', 'complications': 'infection', 'review': 'also', 'patient': 'patient', 'of': 'of', 'is': 'is'}
{'in': tensor(13.7172), ',': tensor(12.7255), 'and': tensor(11.8896), '##ff': tensor(22.7978), 'with': tensor(16.1436), '##com': tensor(20.3902), 'third': tensor(10.5234), 'surgery': tensor(13.2330), 'hospital': tensor(16.7821), 'complications': tensor(10.1615), 'review': tensor(7.2008), 'patient': tensor(14.4351), 'of': tensor(16.1956), 'is': tensor(13.6945)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'in', 'patients', 'with', 'inflammatory', 'bow', '##el', 'disease', '(', 'ib', '##d', ')', '[MASK]', 'a', 'long', 'course', 'of', 'oral', 'van', '##com', '##y', '##cin', 'is', 'associated', 'with', 'lower', 'odds', 'of', 'cl', '##ost', '##rid', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', 'course', ',', '[MASK]', 'retrospective', 'chart', 'review', '[MASK]', '.', '"', 'in', 'ib', '##d', ',', 'having', '[MASK]', 'di', '##ff', 'is', 'associated', 'with', 'worse', '[MASK]', '-', 'e', '[MASK]', '[MASK]', '.', ',', 'greater', 'likelihood', 'for', 'hospital', '##ization', 'or', 'surgery', ',', 'lower', 'likelihood', '[MASK]', 'respond', 'to', '[MASK]', 'therapy', 'and', ',', 'as', 'we', 'showed', 'previously', '(', 'http', ':', '/', '/', 'bit', '.', 'l', '##y', '/', '2', '##lp', '[MASK]', '##c', '[MASK]', '##k', ')', ',', 'increased', 'risk', 'for', 'j', 'pouch', 'complications', 'if', 'a', 'patient', '[MASK]', 'c', 'di', '##ff', 'before', 'their', 'cole', '##ct', '##omy', ',', '[MASK]', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', 'chicago', 'medicine', 'told', 'reuters', 'health', 'by', 'email', '.', '"', 'we', 'also', 'know', 'that', 'having', 'one', 'c', 'di', '##ff', 'infection', 'increases', 'the', 'likelihood', 'of', 'having', 'another', ',', '[MASK]', '[MASK]', '[MASK]', 'increases', 'the', 'likelihood', 'of', 'a', 'third', 'substantially', '.', '[MASK]', '[SEP]']
{50: 'reveals', 175: '"', 85: 'medical', 166: 'two', 46: 'a', 58: 'c', 68: '.', 69: 'g', 165: 'having', 82: 'to', 107: '##3', 164: 'and', 65: 'outcomes', 120: 'had', 12: ',', 105: '##k', 130: '"'}
loss:  18.00758934020996
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 47.06%
Average score: 10.78
{'reveals': 'concluded', '"': '"', 'medical': 'radiation', 'two': 'also', 'a': 'a', 'c': 'c', '.': '.', 'g': 'e', 'having': 'having', 'to': 'to', '##3': '##2', 'and': 'but', 'outcomes': 'non', 'had': 'has', ',': ',', '##k': '##2'}
{'reveals': tensor(8.7530), '"': tensor(11.6665), 'medical': tensor(9.5130), 'two': tensor(9.2958), 'a': tensor(8.1085), 'c': tensor(13.4164), '.': tensor(8.6988), 'g': tensor(12.2911), 'having': tensor(7.0263), 'to': tensor(16.2975), '##3': tensor(11.0672), 'and': tensor(10.0698), 'outcomes': tensor(8.1400), 'had': tensor(12.4497), ',': tensor(14.9084), '##k': tensor(10.7101)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'in', 'patients', 'with', 'inflammatory', 'bow', '[MASK]', 'disease', '(', 'ib', '##d', ')', ',', '[MASK]', 'long', 'course', 'of', 'oral', 'van', '##com', '[MASK]', '[MASK]', 'is', 'associated', 'with', '[MASK]', 'odds', 'of', 'cl', '##ost', '##rid', '##io', '##ides', 'di', '##ffi', '##ci', '##le', 'infection', 'rec', '##ur', '##rence', 'than', 'a', 'short', 'course', ',', 'a', 'retrospective', 'chart', 'review', 'reveals', '.', '"', 'in', 'ib', '##d', ',', 'having', 'c', 'di', '##ff', 'is', 'associated', 'with', 'worse', 'outcomes', '-', 'e', '.', 'g', '.', ',', 'greater', 'likelihood', 'for', 'hospital', '##ization', 'or', 'surgery', ',', '[MASK]', 'likelihood', 'to', 'respond', 'to', 'medical', 'therapy', '[MASK]', ',', 'as', 'we', 'showed', 'previously', '(', 'http', ':', '/', '/', 'bit', '.', 'l', '[MASK]', '/', '2', '[MASK]', '##k', '##c', '##3', '##k', ')', ',', 'increased', 'risk', 'for', 'j', 'pouch', 'complications', 'if', 'a', '[MASK]', 'had', 'c', 'di', '##ff', 'before', 'their', 'cole', '[MASK]', '##omy', '[MASK]', '[MASK]', 'dr', '.', 'david', 'rubin', 'of', 'university', 'of', '[MASK]', 'medicine', 'told', 'reuters', '[MASK]', 'by', '[MASK]', '.', '"', 'we', 'also', 'know', 'that', 'having', 'one', 'c', 'di', '[MASK]', 'infection', 'increases', 'the', 'likelihood', 'of', 'having', 'another', ',', 'and', 'having', 'two', 'increases', 'the', 'likelihood', 'of', 'a', 'third', 'substantially', '.', '"', '[SEP]']
{13: 'a', 101: '##y', 80: 'lower', 20: '##y', 6: '##el', 21: '##cin', 142: 'health', 25: 'lower', 155: '##ff', 129: ',', 119: 'patient', 144: 'email', 127: '##ct', 104: '##lp', 138: 'chicago', 87: 'and', 130: '"'}
loss:  19.52142906188965
prediction_scores:  torch.Size([1, 177, 30522])
Accuracy: 41.18%
Average score: 13.26
{'a': 'a', '##y': '##et', 'lower': 'higher', '##el': '##el', '##cin': '##tion', 'health': ',', '##ff': '##ff', ',': '.', 'patient': 'patient', 'email': 'contrast', '##ct': '##ct', '##lp': '##g', 'chicago': 'internal', 'and': 'and', '"': 'as'}
{'a': tensor(15.5616), '##y': tensor(11.4075), 'lower': tensor(14.5416), '##el': tensor(21.0502), '##cin': tensor(10.7878), 'health': tensor(8.2533), '##ff': tensor(20.4177), ',': tensor(11.1089), 'patient': tensor(14.8359), 'email': tensor(8.5161), '##ct': tensor(21.8774), '##lp': tensor(10.0526), 'chicago': tensor(9.1618), 'and': tensor(12.0832), '"': tensor(9.1731)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', '[MASK]', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', 'by', 'michael', 'j', '.', 'wilkinson', ',', 'md', ',', 'of', 'the', 'university', 'of', 'california', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', '[MASK]', 'the', 'women', 'were', 'taking', 'a', 'stat', '##in', ',', 'anti', '##hy', '##per', '[MASK]', '##ive', 'medications', ',', 'or', 'both', 'at', 'study', 'entry', ',', '"', 'the', 'observed', 'benefits', 'of', 'time', '@', '-', '@', 'restricted', '[MASK]', '[MASK]', 'additive', 'to', 'the', 'effects', 'of', 'these', 'medications', '.', '.', '[MASK]', 'and', 'in', 'this', 'population', 'at', 'high', 'risk', '[MASK]', 'cardiovascular', 'disease', ',', 'a', 'significant', 'reduction', 'in', '[MASK]', '##her', '[MASK]', 'lip', '##ids', ',', '[MASK]', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', 'therapy', 'has', 'important', '[MASK]', 'implications', ',', '"', 'say', '[MASK]', 'investigators', '.', '[SEP]']
{3: 'was', 116: 'the', 98: 'blood', 92: 'at', 94: '##ogenic', 45: '##tens', 33: 'of', 84: 'for', 65: 'eating', 111: 'clinical', 66: 'were', 76: '.'}
loss:  21.06761360168457
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 58.33%
Average score: 13.93
{'was': 'was', 'the': 'the', 'blood': 'blood', 'at': 'anti', '##ogenic': '##ine', '##tens': '##tens', 'of': 'of', 'for': 'for', 'eating': 'and', 'clinical': 'therapeutic', 'were': 'not', '.': '.'}
{'was': tensor(15.3827), 'the': tensor(11.3328), 'blood': tensor(16.7102), 'at': tensor(9.9089), '##ogenic': tensor(13.8486), '##tens': tensor(23.5205), 'of': tensor(17.3531), 'for': tensor(15.3542), 'eating': tensor(7.4048), 'clinical': tensor(12.1062), 'were': tensor(9.8297), '.': tensor(14.4477)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', '[MASK]', 'was', 'published', 'online', 'december', '5', 'in', '[MASK]', 'metabolism', 'by', 'michael', 'j', '[MASK]', 'wilkinson', ',', 'md', ',', 'of', 'the', 'university', '[MASK]', 'california', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', 'the', '[MASK]', 'were', 'taking', '[MASK]', 'stat', '##in', ',', 'anti', '##hy', '##per', '##tens', '##ive', 'medications', ',', 'or', 'both', 'at', 'study', 'entry', ',', '"', 'the', 'observed', '[MASK]', 'of', 'time', '@', '-', '[MASK]', 'restricted', 'eating', 'were', 'additive', 'to', 'the', 'effects', '[MASK]', 'these', 'medications', '.', '.', '.', 'and', 'in', '[MASK]', 'population', 'at', 'high', 'risk', 'for', 'cardiovascular', 'disease', ',', 'a', 'significant', 'reduction', 'in', 'at', '##her', '[MASK]', 'lip', '##ids', ',', 'blood', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', 'therapy', 'has', 'important', 'clinical', 'implications', ',', '"', '[MASK]', 'the', 'investigators', '.', '[SEP]']
{38: 'a', 2: 'study', 35: 'women', 94: '##ogenic', 22: 'of', 79: 'this', 14: '.', 63: '@', 58: 'benefits', 9: 'cell', 71: 'of', 115: 'say'}
loss:  20.4480037689209
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 41.67%
Average score: 13.73
{'a': 'either', 'study': 'study', 'women': 'participants', '##ogenic': '##ogenic', 'of': 'of', 'this': 'a', '.': '.', '@': 'day', 'benefits': 'effects', 'cell': 'dietary', 'say': 'explained'}
{'a': tensor(11.1729), 'study': tensor(13.5297), 'women': tensor(15.2148), '##ogenic': tensor(17.3250), 'of': tensor(16.6856), 'this': tensor(14.6551), '.': tensor(17.1596), '@': tensor(9.7900), 'benefits': tensor(15.1801), 'cell': tensor(8.9270), 'say': tensor(11.4424)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', 'was', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', 'by', 'michael', 'j', '.', '[MASK]', ',', 'md', ',', 'of', 'the', 'university', 'of', 'california', '[MASK]', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', 'the', '[MASK]', 'were', 'taking', '[MASK]', 'stat', '##in', ',', '[MASK]', '##hy', '##per', '##tens', '##ive', 'medications', ',', 'or', 'both', '[MASK]', 'study', 'entry', ',', '"', 'the', 'observed', 'benefits', 'of', 'time', '@', '-', '@', 'restricted', 'eating', 'were', 'additive', 'to', '[MASK]', 'effects', 'of', 'these', 'medications', '.', '.', '.', '[MASK]', 'in', 'this', 'population', 'at', 'high', 'risk', 'for', 'cardiovascular', 'disease', '[MASK]', '[MASK]', 'significant', 'reduction', 'in', '[MASK]', '##her', '##ogenic', 'lip', '[MASK]', ',', 'blood', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', 'therapy', 'has', 'important', 'clinical', 'implications', ',', '"', 'say', 'the', 'investigators', '.', '[SEP]']
{42: 'anti', 87: ',', 51: 'at', 24: ',', 92: 'at', 35: 'women', 38: 'a', 77: 'and', 96: '##ids', 88: 'a', 69: 'the', 15: 'wilkinson'}
loss:  20.667739868164062
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 58.33%
Average score: 13.91
{'anti': 'anti', ',': ',', 'at': 'at', 'women': 'participants', 'a': 'a', 'and': '.', '##ids': '##ids', 'the': 'the', 'wilkinson': 'smith'}
{'anti': tensor(18.5781), ',': tensor(14.5667), 'at': tensor(16.9258), 'women': tensor(15.5135), 'a': tensor(11.9520), 'and': tensor(9.9000), '##ids': tensor(18.7922), 'the': tensor(13.2503), 'wilkinson': tensor(5.7162)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', 'was', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', '[MASK]', 'michael', '[MASK]', '.', 'wilkinson', ',', 'md', ',', 'of', 'the', 'university', 'of', 'california', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', 'the', 'women', 'were', 'taking', 'a', 'stat', '[MASK]', ',', '[MASK]', '##hy', '[MASK]', '##tens', '[MASK]', 'medications', ',', 'or', 'both', 'at', 'study', 'entry', ',', '"', 'the', 'observed', 'benefits', 'of', 'time', '@', '[MASK]', '@', 'restricted', 'eating', 'were', 'additive', 'to', 'the', 'effects', 'of', 'these', 'medications', '.', '.', '.', 'and', 'in', 'this', 'population', 'at', 'high', 'risk', '[MASK]', 'cardiovascular', 'disease', ',', 'a', 'significant', 'reduction', 'in', 'at', '##her', '##ogenic', 'lip', '##ids', ',', '[MASK]', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', 'therapy', 'has', 'important', 'clinical', '[MASK]', ',', '"', 'say', 'the', '[MASK]', '[MASK]', '[SEP]']
{44: '##per', 13: 'j', 112: 'implications', 46: '##ive', 98: 'blood', 40: '##in', 62: '-', 118: '.', 11: 'by', 117: 'investigators', 42: 'anti', 84: 'for'}
loss:  22.065673828125
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 66.67%
Average score: 15.07
{'##per': '##dra', 'j': 'h', 'implications': 'implications', '##ive': '##ive', 'blood': 'blood', '##in': '##in', '-': 'and', '.': '.', 'by': 'by', 'investigators': 'authors', 'anti': 'anti', 'for': 'for'}
{'##per': tensor(17.0491), 'j': tensor(10.6946), 'implications': tensor(15.4871), '##ive': tensor(18.6336), 'blood': tensor(16.4518), '##in': tensor(16.0188), '-': tensor(9.4492), '.': tensor(17.8068), 'by': tensor(14.6331), 'investigators': tensor(13.8964), 'anti': tensor(15.4880), 'for': tensor(15.2734)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'study', 'was', 'published', 'online', 'december', '5', 'in', 'cell', 'metabolism', 'by', 'michael', 'j', '.', '[MASK]', ',', 'md', ',', 'of', 'the', 'university', 'of', 'california', ',', 'san', 'diego', ',', 'and', 'colleagues', '.', 'because', 'most', 'of', 'the', 'women', 'were', 'taking', 'a', 'stat', '##in', ',', 'anti', '##hy', '##per', '##tens', '##ive', 'medications', ',', '[MASK]', 'both', '[MASK]', 'study', 'entry', '[MASK]', '"', 'the', '[MASK]', 'benefits', 'of', '[MASK]', '@', '[MASK]', '@', 'restricted', 'eating', '[MASK]', '[MASK]', 'to', 'the', 'effects', 'of', 'these', 'medications', '.', '.', '.', 'and', 'in', 'this', 'population', 'at', 'high', 'risk', 'for', 'cardiovascular', 'disease', ',', 'a', 'significant', 'reduction', 'in', 'at', '##her', '##ogenic', 'lip', '##ids', ',', 'blood', 'pressure', ',', 'and', 'blood', 'glucose', 'on', 'top', 'of', 'medical', 'therapy', 'has', '[MASK]', 'clinical', 'implications', ',', '"', 'say', 'the', '[MASK]', '[MASK]', '[SEP]']
{67: 'additive', 51: 'at', 62: '-', 54: ',', 49: 'or', 118: '.', 66: 'were', 110: 'important', 117: 'investigators', 15: 'wilkinson', 57: 'observed', 60: 'time'}
loss:  17.64799690246582
prediction_scores:  torch.Size([1, 120, 30522])
Accuracy: 25.00%
Average score: 9.95
{'additive': 'related', 'at': 'the', '-': ':', ',': ',', 'or': 'in', '.': '.', 'were': 'are', 'important': 'important', 'investigators': 'authors', 'wilkinson': 'white', 'observed': 'clinical', 'time': 'a'}
{'additive': tensor(9.9143), 'at': tensor(9.5834), '-': tensor(9.5696), ',': tensor(10.8003), 'or': tensor(6.9938), '.': tensor(17.3869), 'were': tensor(7.8678), 'important': tensor(9.7490), 'investigators': tensor(13.6900), 'wilkinson': tensor(5.5364), 'observed': tensor(10.1845), 'time': tensor(8.1706)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', '[MASK]', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '##cino', '##gen', 'n', '@', '[MASK]', '@', 'ni', '##tro', '##so', '##dim', '##eth', '[MASK]', '##mine', '(', 'n', '##dm', '##a', ')', ',', 'the', 'agency', 'announced', 'wednesday', '.', 'contamination', 'with', 'this', 'same', 'substance', 'led', 'to', 'recalls', 'of', 'blood', 'pressure', 'and', 'heart', '##burn', 'medications', 'within', '[MASK]', 'last', '2', 'years', '.', 'met', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', 'prescribed', 'for', 'type', '[MASK]', 'diabetes', ',', 'according', 'to', '[MASK]', 'clinic', '.', 'it', 'lowers', 'glucose', 'production', 'in', 'the', 'liver', 'and', 'boost', '##s', '[MASK]', 'body', "'", 's', 'sensitivity', 'to', '[MASK]', 'so', 'that', '[MASK]', 'body', 'uses', 'insulin', '[MASK]', 'effectively', '.', 'more', 'than', '30', 'million', 'people', 'in', '[MASK]', 'u', '.', 's', '.', 'have', 'diabetes', ',', 'and', '90', 'to', '[MASK]', '%', '[MASK]', 'type', '2', '[MASK]', '[MASK]', 'cdc', 'says', ',', 'and', 'met', '##form', '##in', 'is', 'the', 'fourth', '@', '-', '@', 'most', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{104: 'more', 73: '2', 129: ',', 91: 'your', 21: '-', 28: '##yla', 113: 'the', 57: 'the', 126: 'are', 100: 'your', 124: '95', 78: 'mayo', 4: 'begun', 97: 'insulin', 130: 'the'}
loss:  21.052825927734375
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 46.67%
Average score: 13.65
{'more': 'more', '2': '1', ',': 'diabetes', 'your': 'the', '-': '-', '##yla': '##yla', 'the': ',', 'are': 'have', '95': '95', 'mayo': 'the', 'begun': 'been', 'insulin': 'insulin'}
{'more': tensor(14.3706), '2': tensor(10.0908), ',': tensor(14.5750), 'your': tensor(14.0435), '-': tensor(11.6442), '##yla': tensor(20.3260), 'the': tensor(10.6383), 'are': tensor(11.9386), '95': tensor(14.6199), 'mayo': tensor(10.9188), 'begun': tensor(12.5463), 'insulin': tensor(18.0649)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', 'begun', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', '[MASK]', 'the', 'car', '[MASK]', '##gen', 'n', '[MASK]', '[MASK]', '[MASK]', 'ni', '##tro', '[MASK]', '##dim', '##eth', '##yla', '##mine', '(', 'n', '##dm', '##a', ')', ',', 'the', 'agency', 'announced', 'wednesday', '.', 'contamination', 'with', '[MASK]', 'same', 'substance', 'led', 'to', 'recalls', 'of', 'blood', 'pressure', 'and', 'heart', '[MASK]', 'medications', 'within', 'the', 'last', '2', 'years', '.', 'met', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', 'prescribed', 'for', 'type', '2', '[MASK]', ',', 'according', 'to', 'mayo', 'clinic', '.', 'it', 'lowers', 'glucose', 'production', 'in', 'the', 'liver', 'and', 'boost', '[MASK]', 'your', 'body', "'", 's', 'sensitivity', 'to', 'insulin', '[MASK]', 'that', 'your', 'body', 'uses', 'insulin', 'more', '[MASK]', '.', 'more', 'than', '30', 'million', 'people', 'in', 'the', 'u', '.', 's', '.', 'have', 'diabetes', ',', 'and', '90', 'to', '95', '%', 'are', 'type', '2', ',', 'the', '[MASK]', 'says', ',', 'and', 'met', '##form', '##in', 'is', 'the', 'fourth', '@', '[MASK]', '@', '[MASK]', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{25: '##so', 21: '-', 54: '##burn', 74: 'diabetes', 90: '##s', 20: '@', 22: '@', 105: 'effectively', 14: 'for', 98: 'so', 142: '-', 131: 'cdc', 17: '##cino', 43: 'this', 144: 'most'}
loss:  20.48550033569336
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 33.33%
Average score: 14.17
{'##so': '##xy', '-': ',', '##burn': 'rate', 'diabetes': 'diabetes', '##s': '##s', '@': 'and', 'effectively': 'often', 'for': 'with', 'so': 'so', 'cdc': 'agency', '##cino': '##cino', 'this': 'the', 'most': '-'}
{'##so': tensor(16.6920), '-': tensor(9.6129), '##burn': tensor(10.6488), 'diabetes': tensor(21.5655), '##s': tensor(20.3197), '@': tensor(10.1068), 'effectively': tensor(14.0460), 'for': tensor(11.9539), 'so': tensor(11.8730), 'cdc': tensor(10.9728), '##cino': tensor(20.9717), 'this': tensor(15.3908), 'most': tensor(10.0527)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'fda', 'has', 'begun', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', 'for', '[MASK]', '[MASK]', '##cino', '##gen', 'n', '@', '-', '[MASK]', 'ni', '##tro', '##so', '##dim', '##eth', '##yla', '##mine', '(', 'n', '##dm', '##a', ')', ',', '[MASK]', 'agency', 'announced', 'wednesday', '.', 'contamination', 'with', 'this', 'same', 'substance', 'led', 'to', 'recalls', 'of', 'blood', 'pressure', 'and', 'heart', '[MASK]', 'medications', 'within', 'the', '[MASK]', '2', 'years', '.', '[MASK]', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', 'prescribed', 'for', 'type', '2', 'diabetes', ',', 'according', 'to', '[MASK]', 'clinic', '.', '[MASK]', 'lowers', '[MASK]', 'production', 'in', 'the', '[MASK]', 'and', 'boost', '##s', 'your', 'body', "'", 's', 'sensitivity', 'to', 'insulin', 'so', '[MASK]', 'your', 'body', 'uses', 'insulin', 'more', 'effectively', '.', 'more', 'than', '30', 'million', 'people', 'in', 'the', 'u', '.', 's', '.', 'have', 'diabetes', ',', 'and', '90', 'to', '95', '%', 'are', 'type', '2', '[MASK]', 'the', 'cdc', 'says', ',', 'and', 'met', '##form', '##in', 'is', '[MASK]', 'fourth', '@', '-', '@', 'most', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{129: ',', 139: 'the', 36: 'the', 99: 'that', 78: 'mayo', 15: 'the', 22: '@', 81: 'it', 83: 'glucose', 54: '##burn', 16: 'car', 62: 'met', 58: 'last', 1: 'the', 87: 'liver'}
loss:  20.959495544433594
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 60.00%
Average score: 14.02
{',': ',', 'the': 'the', 'that': 'that', 'mayo': 'the', '@': '@', 'it': 'it', 'glucose': 'insulin', '##burn': 'rate', 'car': 'car', 'met': 'met', 'last': 'next', 'liver': 'body'}
{',': tensor(14.3332), 'the': tensor(13.5481), 'that': tensor(15.2050), 'mayo': tensor(11.2779), '@': tensor(9.6498), 'it': tensor(13.5628), 'glucose': tensor(15.1024), '##burn': tensor(11.0408), 'car': tensor(20.5652), 'met': tensor(18.2270), 'last': tensor(13.5006), 'liver': tensor(12.2169)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', 'begun', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '##cino', '##gen', 'n', '[MASK]', '-', '[MASK]', 'ni', '##tro', '##so', '##dim', '##eth', '##yla', '##mine', '(', 'n', '##dm', '##a', ')', ',', 'the', 'agency', 'announced', 'wednesday', '.', 'contamination', 'with', 'this', 'same', 'substance', 'led', 'to', 'recalls', '[MASK]', 'blood', 'pressure', 'and', 'heart', '##burn', 'medications', 'within', 'the', '[MASK]', '2', '[MASK]', '[MASK]', 'met', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', 'prescribed', '[MASK]', '[MASK]', '2', 'diabetes', '[MASK]', 'according', 'to', 'mayo', 'clinic', '.', 'it', 'lowers', 'glucose', 'production', 'in', 'the', 'liver', 'and', 'boost', '[MASK]', 'your', 'body', "'", 's', 'sensitivity', '[MASK]', 'insulin', 'so', 'that', 'your', 'body', 'uses', 'insulin', 'more', 'effectively', '.', 'more', 'than', '30', 'million', 'people', 'in', '[MASK]', 'u', '.', 's', '.', 'have', 'diabetes', ',', 'and', '90', 'to', '95', '%', 'are', 'type', '2', ',', 'the', 'cdc', 'says', ',', 'and', 'met', '##form', '##in', 'is', 'the', 'fourth', '[MASK]', '-', '@', 'most', 'prescribed', '[MASK]', 'in', 'the', 'united', 'states', '[MASK]', '[SEP]']
{96: 'to', 72: 'type', 20: '@', 146: 'drug', 58: 'last', 22: '@', 90: '##s', 75: ',', 71: 'for', 141: '@', 113: 'the', 60: 'years', 151: '.', 49: 'of', 61: '.'}
loss:  21.732133865356445
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 73.33%
Average score: 14.12
{'to': 'to', 'type': 'type', '@': '@', 'drug': 'medication', 'last': 'type', '##s': '##s', ',': ',', 'for': 'for', 'the': 'the', 'years': 'months', '.': '.', 'of': 'of'}
{'to': tensor(15.9955), 'type': tensor(20.7949), '@': tensor(9.3984), 'drug': tensor(13.1368), 'last': tensor(11.0683), '##s': tensor(20.4584), ',': tensor(12.5809), 'for': tensor(11.9954), 'the': tensor(16.7329), 'years': tensor(10.7956), '.': tensor(13.3863), 'of': tensor(13.1441)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/Medscape05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'the', 'fda', 'has', 'begun', 'testing', 'samples', 'of', 'the', 'diabetes', 'drug', 'met', '##form', '##in', 'for', 'the', 'car', '##cino', '##gen', '[MASK]', '@', '-', '@', 'ni', '##tro', '##so', '##dim', '##eth', '##yla', '##mine', '[MASK]', 'n', '[MASK]', '##a', ')', ',', 'the', 'agency', 'announced', 'wednesday', '.', 'contamination', '[MASK]', 'this', 'same', 'substance', 'led', 'to', '[MASK]', 'of', 'blood', 'pressure', 'and', 'heart', '##burn', 'medications', 'within', 'the', '[MASK]', '[MASK]', 'years', '.', 'met', '##form', '##in', 'is', 'generally', 'the', 'first', 'medication', 'prescribed', 'for', 'type', '2', 'diabetes', ',', 'according', 'to', 'mayo', '[MASK]', '.', 'it', 'lowers', 'glucose', 'production', 'in', 'the', 'liver', 'and', 'boost', '[MASK]', 'your', 'body', "'", '[MASK]', 'sensitivity', 'to', 'insulin', '[MASK]', 'that', 'your', 'body', '[MASK]', '[MASK]', 'more', 'effectively', '.', 'more', 'than', '30', 'million', 'people', '[MASK]', 'the', 'u', '.', 's', '.', 'have', 'diabetes', '[MASK]', 'and', '90', 'to', '95', '%', 'are', 'type', '2', ',', 'the', 'cdc', 'says', ',', 'and', 'met', '##form', '##in', 'is', 'the', 'fourth', '@', '-', '@', 'most', 'prescribed', 'drug', 'in', 'the', 'united', 'states', '.', '[SEP]']
{32: '##dm', 98: 'so', 59: '2', 120: ',', 103: 'insulin', 94: 's', 58: 'last', 48: 'recalls', 19: 'n', 90: '##s', 30: '(', 102: 'uses', 42: 'with', 79: 'clinic', 112: 'in'}
loss:  20.465099334716797
prediction_scores:  torch.Size([1, 153, 30522])
Accuracy: 60.00%
Average score: 13.97
{'##dm': '##dal', 'so': 'so', '2': '@', ',': ',', 'insulin': 'insulin', 's': 's', 'last': 'first', 'recalls': 'withdrawal', 'n': ',', '##s': '##s', '(': '(', 'uses': 'is', 'with': 'with', 'clinic': 'clinic', 'in': 'in'}
{'##dm': tensor(11.9000), 'so': tensor(15.0456), '2': tensor(9.9122), ',': tensor(13.7200), 'insulin': tensor(12.5614), 's': tensor(22.8202), 'last': tensor(13.2050), 'recalls': tensor(10.1204), 'n': tensor(8.7969), '##s': tensor(20.4968), '(': tensor(16.7064), 'uses': tensor(12.0740), 'with': tensor(14.2614), 'clinic': tensor(11.5229), 'in': tensor(16.4705)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'ad', '##ren', '##er', '##gic', 'activation', 'is', 'thought', 'to', 'be', 'an', 'important', 'deter', '##mina', '##nt', 'of', 'outcome', 'in', 'subjects', 'with', 'chronic', '[MASK]', 'failure', '(', 'ch', '##f', ')', ',', 'but', 'baseline', 'or', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '##gic', 'activity', 'have', 'not', 'been', 'previously', 'investigated', 'in', '[MASK]', 'large', 'patient', 'sample', 'treated', 'with', 'a', 'powerful', 'anti', '[MASK]', '##ren', '##er', '##gic', 'agent', '.', 'results', 'systemic', '[MASK]', '##nous', 'nor', '##ep', '##ine', '##ph', '[MASK]', '[MASK]', 'measured', '[MASK]', 'baseline', ',', '@', 'months', ',', '[MASK]', '@', 'months', 'in', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', '[MASK]', 'place', '##bo', 'treatment', 'with', 'the', 'beta', '-', 'block', '##er', '/', 'sy', '##mp', '##ath', '##ol', '##ytic', 'agent', 'bu', '##cin', '##do', '##lo', '[MASK]', '.', 'results', 'baseline', 'nor', '[MASK]', '##ine', '##ph', '##rine', '[MASK]', 'was', 'associated', 'with', 'a', 'progressive', 'increase', 'in', 'rates', 'of', 'death', 'or', 'death', '[MASK]', 'ch', '##f', 'hospital', '##ization', 'that', 'was', 'independent', 'of', 'treatment', 'group', '.', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'was', 'also', '[MASK]', 'highly', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '##or', 'of', 'death', '.', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', '[MASK]', '[MASK]', '[MASK]', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'at', '@', '[MASK]', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', 'and', '[MASK]', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '##bo', '-', 'treated', '[MASK]', 'but', 'not', 'in', '[MASK]', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', ',', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'increase', 'at', '@', 'months', '[MASK]', 'associated', 'with', 'increased', 'subsequent', 'risks', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', '.', 'results', 'in', '[MASK]', 'bu', '##cin', '##do', '##lo', '##l', '[MASK]', 'treated', 'group', 'but', 'not', '[MASK]', 'the', 'place', '##bo', '-', 'treated', '[MASK]', ',', 'the', '[MASK]', 'st', 'qu', '##art', '##ile', 'of', 'marked', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'reduction', 'was', 'associated', 'with', 'an', 'increased', 'mortality', 'risk', '.', 'results', 'a', 'likelihood', '-', 'based', 'method', 'indicated', 'that', '@', '%', 'of', 'the', 'bu', '##cin', '[MASK]', '##lo', '[MASK]', 'group', 'but', 'only', '@', '[MASK]', 'of', 'the', 'place', '##bo', '[MASK]', 'were', 'at', 'an', '[MASK]', 'risk', 'for', '[MASK]', 'related', 'to', 'marked', 'reduction', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', '.', 'conclusions', 'in', 'best', ',', 'a', 'subset', 'of', 'patients', 'treated', 'with', 'bu', '##cin', '##do', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', 'the', 'result', 'of', 'sy', '[MASK]', '##ath', '##ol', '##ysis', ',', 'which', 'compromised', 'the', 'efficacy', 'of', 'this', 'third', '-', 'generation', '[MASK]', '-', 'block', '[MASK]', '.', '[SEP]']
{276: 'group', 259: 'the', 391: '##er', 191: '##ep', 55: '##ad', 122: '##ep', 72: 'at', 279: '@', 187: 'the', 388: 'beta', 321: '%', 287: '##ep', 374: '##mp', 139: 'plus', 330: 'increased', 314: '##do', 22: 'heart', 117: '##l', 189: 'in', 316: '##l', 166: 'a', 188: 'change', 78: 'and', 63: 've', 205: 'treatment', 265: '-', 270: 'in', 160: '##ep', 217: 'group', 197: 'months', 46: 'a', 221: 'the', 69: '##rine', 241: 'was', 96: 'compared', 333: 'death', 126: 'level', 70: 'was', 326: 'group'}
loss:  21.66940689086914
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 82.05%
Average score: 16.88
{'group': 'group', 'the': 'the', '##er': '##er', '##ep': '##ep', '##ad': '##ad', 'at': 'at', '@': 'average', 'beta': 'beta', '%': '%', '##mp': '##mp', 'plus': 'plus', 'increased': 'increased', '##do': '##do', 'heart': 'heart', '##l': '##l', 'in': 'in', 'a': 'a', 'change': 'levels', 'and': 'and', 've': 've', 'treatment': 'highly', '-': '-', 'months': 'months', '##rine': '##rine', 'was': '##rine', 'compared': 'compared', 'death': 'death', 'level': 'reduction'}
{'group': tensor(15.6792), 'the': tensor(15.2602), '##er': tensor(19.2087), '##ep': tensor(28.7330), '##ad': tensor(20.5621), 'at': tensor(14.6113), '@': tensor(7.3595), 'beta': tensor(16.1518), '%': tensor(17.2765), '##mp': tensor(25.4793), 'plus': tensor(10.9866), 'increased': tensor(18.8855), '##do': tensor(28.3845), 'heart': tensor(14.3636), '##l': tensor(20.4331), 'in': tensor(15.9354), 'a': tensor(16.1834), 'change': tensor(10.0389), 'and': tensor(13.6778), 've': tensor(16.0694), 'treatment': tensor(10.0437), '-': tensor(16.5189), 'months': tensor(14.4676), '##rine': tensor(26.8375), 'was': tensor(22.4223), 'compared': tensor(12.6884), 'death': tensor(13.5135), 'level': tensor(11.0031)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'ad', '[MASK]', '##er', '##gic', 'activation', 'is', 'thought', 'to', 'be', 'an', 'important', '[MASK]', '##mina', '##nt', 'of', 'outcome', 'in', 'subjects', 'with', 'chronic', 'heart', 'failure', '(', 'ch', '##f', ')', ',', 'but', 'baseline', 'or', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '##gic', 'activity', '[MASK]', 'not', 'been', 'previously', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', 'with', 'a', 'powerful', 'anti', '##ad', '##ren', '##er', '##gic', 'agent', '.', 'results', 'systemic', 've', '##nous', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'measured', '[MASK]', 'baseline', ',', '@', 'months', ',', 'and', '@', 'months', '[MASK]', '[MASK]', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', 'place', '##bo', '[MASK]', 'with', 'the', '[MASK]', '-', 'block', '##er', '/', 'sy', '[MASK]', '##ath', '##ol', '##ytic', 'agent', 'bu', '##cin', '##do', '##lo', '##l', '[MASK]', 'results', 'baseline', 'nor', '##ep', '##ine', '##ph', '[MASK]', 'level', 'was', 'associated', '[MASK]', 'a', 'progressive', 'increase', 'in', 'rates', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', '[MASK]', '##ization', 'that', 'was', 'independent', 'of', '[MASK]', 'group', '.', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', '[MASK]', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'was', 'also', 'a', 'highly', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '##or', 'of', 'death', '[MASK]', 'results', '[MASK]', 'contrast', ',', 'the', '[MASK]', 'of', 'the', 'change', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', '[MASK]', 'outcomes', 'was', 'complex', 'and', 'treatment', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '[MASK]', '-', 'treated', '[MASK]', 'but', 'not', 'in', 'the', 'bu', '##cin', '##do', '##lo', '[MASK]', '-', 'treated', 'group', ',', '[MASK]', 'nor', '##ep', '##ine', '##ph', '##rine', 'increase', 'at', '@', 'months', 'was', 'associated', '[MASK]', '[MASK]', 'subsequent', 'risks', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', '[MASK]', 'results', '[MASK]', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'place', '##bo', '-', 'treated', 'group', ',', 'the', '@', 'st', '[MASK]', '##art', '##ile', 'of', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'reduction', 'was', 'associated', 'with', 'an', 'increased', '[MASK]', 'risk', '.', 'results', 'a', 'likelihood', '-', 'based', 'method', 'indicated', 'that', '@', '%', 'of', 'the', 'bu', '##cin', '[MASK]', '##lo', '##l', 'group', 'but', 'only', '@', '%', 'of', 'the', '[MASK]', '##bo', '[MASK]', 'were', 'at', 'an', 'increased', 'risk', 'for', 'death', 'related', 'to', 'marked', 'reduction', 'in', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'at', '@', 'months', '.', 'conclusions', 'in', 'best', ',', 'a', 'subset', 'of', 'patients', 'treated', 'with', 'bu', '##cin', '##do', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', '[MASK]', 'the', 'result', 'of', 'sy', '[MASK]', '##ath', '##ol', '##ysis', ',', 'which', 'compromised', 'the', 'efficacy', 'of', 'this', 'third', '-', 'generation', '[MASK]', '-', '[MASK]', '##er', '.', '[SEP]']
{118: '.', 281: 'qu', 243: 'with', 217: 'group', 13: 'deter', 185: 'relation', 158: 'baseline', 160: '##ep', 99: 'treatment', 179: '.', 214: '##bo', 297: 'mortality', 374: '##mp', 326: 'group', 244: 'increased', 72: 'at', 340: '##ep', 3: '##ren', 1: 'background', 82: 'the', 102: 'beta', 231: 'marked', 314: '##do', 390: 'block', 142: 'hospital', 226: '##l', 181: 'in', 200: 'clinical', 324: 'place', 369: 'as', 129: 'with', 81: 'in', 388: 'beta', 125: '##rine', 256: '.', 108: '##mp', 258: 'in', 40: 'have', 148: 'treatment'}
loss:  22.359830856323242
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 74.36%
Average score: 17.23
{'.': '.', 'qu': '##ip', 'with': 'with', 'group': 'group', 'deter': 'deter', 'relation': 'relationship', 'baseline': 'baseline', '##ep': '##ep', 'treatment': 'treatment', '##bo': '##bo', 'mortality': 'death', '##mp': '##mp', 'increased': 'with', 'at': 'at', '##ren': '##ren', 'background': 'chronic', 'the': '.', 'beta': 'beta', 'marked': 'marked', '##do': '##do', 'block': 'block', 'hospital': 'hospital', '##l': '##l', 'in': 'in', 'clinical': 'treatment', 'place': 'place', 'as': 'as', '##rine': '##rine', 'have': 'had'}
{'.': tensor(14.0376), 'qu': tensor(14.7616), 'with': tensor(18.0561), 'group': tensor(15.6642), 'deter': tensor(19.2695), 'relation': tensor(15.3612), 'baseline': tensor(10.6804), '##ep': tensor(28.5491), 'treatment': tensor(13.3903), '##bo': tensor(23.7789), 'mortality': tensor(12.9751), '##mp': tensor(19.4603), 'increased': tensor(14.2142), 'at': tensor(12.6021), '##ren': tensor(26.3629), 'background': tensor(8.4135), 'the': tensor(9.0211), 'beta': tensor(15.7210), 'marked': tensor(10.9785), '##do': tensor(28.2990), 'block': tensor(20.4343), 'hospital': tensor(20.8124), '##l': tensor(19.0435), 'in': tensor(16.1877), 'clinical': tensor(10.5022), 'place': tensor(22.9993), 'as': tensor(13.2271), '##rine': tensor(27.5939), 'have': tensor(17.2171)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', '[MASK]', '##ren', '##er', '##gic', 'activation', 'is', '[MASK]', 'to', 'be', 'an', 'important', 'deter', '##mina', '##nt', 'of', 'outcome', 'in', 'subjects', 'with', 'chronic', 'heart', '[MASK]', '(', 'ch', '[MASK]', ')', ',', 'but', 'baseline', 'or', 'serial', 'changes', '[MASK]', 'ad', '##ren', '##er', '##gic', 'activity', 'have', 'not', 'been', 'previously', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', 'with', 'a', 'powerful', '[MASK]', '##ad', '##ren', '##er', '[MASK]', 'agent', '.', 'results', 'systemic', 've', '##nous', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'was', 'measured', 'at', 'baseline', ',', '@', 'months', ',', 'and', '@', 'months', '[MASK]', 'the', '[MASK]', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', 'place', '##bo', 'treatment', 'with', 'the', 'beta', '-', 'block', '##er', '/', 'sy', '##mp', '##ath', '##ol', '##ytic', 'agent', 'bu', '##cin', '##do', '##lo', '[MASK]', '.', 'results', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', 'level', 'was', 'associated', 'with', 'a', 'progressive', 'increase', 'in', 'rates', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', 'that', 'was', 'independent', 'of', 'treatment', 'group', '.', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '[MASK]', '[MASK]', '##ph', '##rine', 'was', 'also', 'a', 'highly', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '##or', 'of', 'death', '.', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', 'the', 'change', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', 'and', 'treatment', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '##bo', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', '[MASK]', ',', 'marked', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'increase', 'at', '@', 'months', 'was', 'associated', '[MASK]', 'increased', 'subsequent', 'risks', '[MASK]', '[MASK]', 'or', 'death', 'plus', 'ch', '[MASK]', 'hospital', '##ization', '.', 'results', 'in', 'the', 'bu', '##cin', '[MASK]', '##lo', '##l', '-', '[MASK]', 'group', 'but', 'not', 'in', 'the', 'place', '##bo', '-', '[MASK]', 'group', ',', 'the', '@', 'st', 'qu', '##art', '##ile', 'of', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'reduction', '[MASK]', 'associated', 'with', 'an', 'increased', 'mortality', 'risk', '.', 'results', 'a', '[MASK]', '-', 'based', 'method', 'indicated', 'that', '@', '[MASK]', 'of', '[MASK]', 'bu', '##cin', '##do', '##lo', '##l', 'group', '[MASK]', 'only', '[MASK]', '%', 'of', '[MASK]', 'place', '##bo', 'group', '[MASK]', 'at', '[MASK]', 'increased', 'risk', 'for', 'death', 'related', 'to', 'marked', 'reduction', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', '[MASK]', '@', '[MASK]', '.', '[MASK]', '[MASK]', 'best', ',', 'a', 'subset', 'of', 'patients', '[MASK]', 'with', 'bu', '##cin', '[MASK]', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', '[MASK]', 'result', 'of', 'sy', '##mp', '##ath', '##ol', '##ysis', ',', 'which', 'compromised', 'the', 'efficacy', 'of', 'this', 'third', '[MASK]', 'generation', 'beta', '-', 'block', '##er', '.', '[SEP]']
{161: '##ine', 360: '##do', 2: 'ad', 262: '##do', 160: '##ep', 275: 'treated', 243: 'with', 309: '%', 81: 'in', 229: 'group', 327: 'were', 349: 'in', 348: 'conclusions', 23: 'failure', 302: 'likelihood', 26: '##f', 329: 'an', 253: '##f', 8: 'thought', 54: 'anti', 34: 'in', 386: '-', 66: '##ep', 320: '@', 346: 'months', 292: 'was', 318: 'but', 247: 'of', 356: 'treated', 266: 'treated', 83: 'beta', 323: 'the', 58: '##gic', 117: '##l', 344: 'at', 370: 'the', 233: '##ep', 248: 'death', 311: 'the'}
loss:  21.856182098388672
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 74.36%
Average score: 16.41
{'##ine': '##ine', '##do': '##do', 'ad': 'ad', '##ep': '##ep', 'treated': 'treated', 'with': 'with', '%': 'st', 'in': 'in', 'group': 'group', 'were': 'was', 'conclusions': 'at', 'failure': 'disease', 'likelihood': 'population', '##f': '##f', 'an': 'an', 'thought': 'thought', 'anti': 'pre', '-': '-', '@': '1', 'months': 'months', 'was': 'was', 'but': 'and', 'of': 'of', 'beta': 'beta', 'the': 'the', '##gic': '##gic', '##l': '##l', 'at': 'at', 'death': 'death'}
{'##ine': tensor(23.8335), '##do': tensor(28.0714), 'ad': tensor(20.8291), '##ep': tensor(28.1767), 'treated': tensor(17.2243), 'with': tensor(17.1187), '%': tensor(9.6466), 'in': tensor(16.4132), 'group': tensor(16.6318), 'were': tensor(12.1111), 'conclusions': tensor(11.0309), 'failure': tensor(17.6524), 'likelihood': tensor(7.8671), '##f': tensor(22.2895), 'an': tensor(15.9781), 'thought': tensor(14.0076), 'anti': tensor(9.9580), '-': tensor(17.9511), '@': tensor(12.0974), 'months': tensor(11.8838), 'was': tensor(16.3737), 'but': tensor(9.5854), 'of': tensor(15.7015), 'beta': tensor(16.7220), 'the': tensor(13.8755), '##gic': tensor(27.2246), '##l': tensor(18.9322), 'at': tensor(12.4527), 'death': tensor(14.1512)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'ad', '[MASK]', '##er', '##gic', '[MASK]', 'is', 'thought', 'to', 'be', 'an', 'important', '[MASK]', '##mina', '[MASK]', 'of', 'outcome', '[MASK]', 'subjects', 'with', 'chronic', 'heart', 'failure', '(', 'ch', '##f', '[MASK]', ',', 'but', 'baseline', 'or', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '[MASK]', 'activity', 'have', 'not', 'been', 'previously', 'investigated', 'in', 'a', 'large', 'patient', '[MASK]', 'treated', 'with', 'a', 'powerful', 'anti', '##ad', '[MASK]', '##er', '##gic', 'agent', '.', 'results', 'systemic', 've', '##nous', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'measured', 'at', 'baseline', ',', '@', 'months', ',', 'and', '@', 'months', 'in', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', '[MASK]', '##bo', 'treatment', 'with', 'the', '[MASK]', '[MASK]', 'block', '##er', '/', 'sy', '##mp', '[MASK]', '##ol', '##ytic', 'agent', 'bu', '##cin', '##do', '##lo', '##l', '.', 'results', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', 'level', '[MASK]', 'associated', 'with', 'a', 'progressive', 'increase', 'in', 'rates', '[MASK]', 'death', 'or', '[MASK]', 'plus', 'ch', '##f', 'hospital', '##ization', 'that', 'was', 'independent', 'of', 'treatment', 'group', '.', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'also', 'a', 'highly', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '##or', '[MASK]', 'death', '.', 'results', 'in', 'contrast', ',', '[MASK]', 'relation', 'of', 'the', 'change', '[MASK]', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', 'and', 'treatment', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '##bo', '[MASK]', 'treated', '[MASK]', 'but', '[MASK]', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', '[MASK]', ',', 'marked', 'nor', '##ep', '##ine', '[MASK]', '##rine', 'increase', 'at', '@', 'months', 'was', 'associated', 'with', '[MASK]', 'subsequent', 'risks', 'of', '[MASK]', '[MASK]', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', '.', 'results', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'place', '##bo', '-', 'treated', 'group', ',', 'the', '[MASK]', 'st', 'qu', '[MASK]', '##ile', 'of', 'marked', '[MASK]', '##ep', '##ine', '##ph', '##rine', 'reduction', 'was', 'associated', 'with', 'an', 'increased', 'mortality', 'risk', '.', 'results', 'a', 'likelihood', '-', 'based', 'method', 'indicated', 'that', '@', '%', 'of', 'the', 'bu', '##cin', '##do', '##lo', '##l', 'group', 'but', 'only', '@', '%', 'of', 'the', '[MASK]', '##bo', 'group', 'were', 'at', 'an', 'increased', 'risk', 'for', 'death', 'related', 'to', '[MASK]', 'reduction', 'in', '[MASK]', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', '.', 'conclusions', '[MASK]', 'best', ',', 'a', 'subset', 'of', 'patients', 'treated', 'with', '[MASK]', '##cin', '##do', '##lo', '[MASK]', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', 'the', 'result', 'of', 'sy', '##mp', '##ath', '##ol', '##ysis', ',', 'which', '[MASK]', 'the', 'efficacy', '[MASK]', 'this', 'third', '-', 'generation', '[MASK]', '-', 'block', '##er', '.', '[SEP]']
{336: 'marked', 109: '##ath', 248: 'death', 249: 'or', 97: 'place', 102: 'beta', 3: '##ren', 219: 'not', 388: 'beta', 189: 'in', 13: 'deter', 286: 'nor', 56: '##ren', 282: '##art', 279: '@', 177: 'of', 244: 'increased', 103: '-', 135: 'of', 324: 'place', 127: 'was', 358: 'bu', 215: '-', 380: 'compromised', 217: 'group', 349: 'in', 362: '##l', 235: '##ph', 15: '##nt', 27: ')', 49: 'sample', 38: '##gic', 6: 'activation', 383: 'of', 339: 'nor', 18: 'in', 138: 'death', 184: 'the', 229: 'group'}
loss:  22.5952091217041
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 79.49%
Average score: 17.41
{'marked': 'a', '##ath': '##ath', 'death': 'death', 'or': 'or', 'place': 'place', 'beta': 'beta', '##ren': '##ren', 'not': 'not', 'in': 'in', 'deter': 'deter', 'nor': 'nor', '##art': '##art', '@': 'average', 'of': 'of', 'increased': 'increased', '-': '-', 'was': 'was', 'bu': 'bu', 'compromised': 'confirmed', 'group': 'group', '##l': '##l', '##ph': '##ph', '##nt': '##nt', ')': ')', 'sample': 'being', '##gic': '##gic', 'activation': 'activity', 'the': 'the'}
{'marked': tensor(13.0632), '##ath': tensor(25.0862), 'death': tensor(13.5277), 'or': tensor(11.1727), 'place': tensor(23.7394), 'beta': tensor(18.1699), '##ren': tensor(21.7328), 'not': tensor(17.8192), 'in': tensor(14.4912), 'deter': tensor(16.9563), 'nor': tensor(21.7289), '##art': tensor(16.4369), '@': tensor(7.8274), 'of': tensor(16.3854), 'increased': tensor(11.3491), '-': tensor(15.7067), 'was': tensor(15.4227), 'bu': tensor(21.7355), 'compromised': tensor(12.2349), 'group': tensor(16.6809), '##l': tensor(19.2552), '##ph': tensor(27.4579), '##nt': tensor(18.8544), ')': tensor(21.4774), 'sample': tensor(11.3307), '##gic': tensor(28.0767), 'activation': tensor(14.6993), 'the': tensor(15.1421)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'ad', '##ren', '##er', '##gic', 'activation', 'is', 'thought', 'to', 'be', 'an', 'important', 'deter', '[MASK]', '##nt', 'of', 'outcome', 'in', '[MASK]', 'with', 'chronic', 'heart', '[MASK]', '(', 'ch', '##f', ')', '[MASK]', 'but', 'baseline', 'or', 'serial', '[MASK]', 'in', '[MASK]', '##ren', '[MASK]', '[MASK]', 'activity', '[MASK]', 'not', 'been', 'previously', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', 'with', '[MASK]', 'powerful', 'anti', '##ad', '##ren', '##er', '##gic', 'agent', '[MASK]', 'results', 'systemic', '[MASK]', '##nous', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'measured', 'at', '[MASK]', ',', '@', 'months', ',', 'and', '@', 'months', 'in', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', 'place', '##bo', 'treatment', '[MASK]', '[MASK]', 'beta', '-', 'block', '##er', '/', 'sy', '##mp', '##ath', '##ol', '##ytic', '[MASK]', 'bu', '##cin', '##do', '##lo', '##l', '.', 'results', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', 'level', 'was', 'associated', 'with', 'a', 'progressive', 'increase', 'in', 'rates', '[MASK]', 'death', '[MASK]', 'death', 'plus', '[MASK]', '##f', 'hospital', '##ization', '[MASK]', 'was', 'independent', 'of', 'treatment', 'group', '.', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'also', 'a', 'highly', 'significant', '[MASK]', 'p', '<', '@', ')', 'independent', 'predict', '[MASK]', 'of', 'death', '[MASK]', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', 'the', 'change', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '[MASK]', 'months', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', 'and', 'treatment', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '##bo', '-', 'treated', 'group', 'but', '[MASK]', 'in', 'the', 'bu', '##cin', '##do', '##lo', '[MASK]', '-', '[MASK]', '[MASK]', ',', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'increase', 'at', '@', 'months', 'was', 'associated', 'with', 'increased', 'subsequent', 'risks', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', '.', 'results', 'in', 'the', 'bu', '##cin', '[MASK]', '##lo', '##l', '-', 'treated', 'group', '[MASK]', 'not', 'in', 'the', 'place', '##bo', '-', '[MASK]', 'group', ',', 'the', '@', 'st', 'qu', '##art', '##ile', 'of', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'reduction', 'was', 'associated', '[MASK]', 'an', 'increased', 'mortality', '[MASK]', '.', 'results', 'a', 'likelihood', '-', 'based', '[MASK]', 'indicated', 'that', '@', '%', 'of', 'the', '[MASK]', '##cin', '##do', '##lo', '##l', 'group', 'but', 'only', '@', '%', 'of', 'the', 'place', '##bo', 'group', 'were', '[MASK]', 'an', 'increased', 'risk', 'for', 'death', 'related', 'to', 'marked', 'reduction', 'in', 'nor', '##ep', '##ine', '##ph', '[MASK]', 'at', '@', 'months', '.', 'conclusions', 'in', 'best', ',', 'a', 'subset', 'of', 'patients', 'treated', 'with', 'bu', '##cin', '##do', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', 'the', 'result', 'of', 'sy', '##mp', '##ath', '##ol', '##ysis', ',', 'which', 'compromised', 'the', '[MASK]', 'of', 'this', 'third', '-', 'generation', '[MASK]', '-', 'block', '##er', '.', '[SEP]']
{100: 'with', 140: 'ch', 294: 'with', 35: 'ad', 19: 'subjects', 144: 'that', 179: '.', 137: 'or', 38: '##gic', 226: '##l', 196: '@', 268: 'but', 112: 'agent', 305: 'method', 382: 'efficacy', 228: 'treated', 298: 'risk', 73: 'baseline', 388: 'beta', 328: 'at', 63: 've', 37: '##er', 101: 'the', 28: ',', 312: 'bu', 40: 'have', 219: 'not', 60: '.', 23: 'failure', 262: '##do', 135: 'of', 52: 'a', 14: '##mina', 169: '(', 176: '##or', 33: 'changes', 343: '##rine', 229: 'group', 275: 'treated'}
loss:  21.550411224365234
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 69.23%
Average score: 16.52
{'with': 'with', 'ch': 'ch', 'ad': 'ad', 'subjects': 'patients', 'that': 'and', '.': '.', 'or': 'or', '##gic': '##al', '##l': '##l', '@': '@', 'but': 'but', 'agent': 'drug', 'method': 'analysis', 'efficacy': 'effectiveness', 'treated': 'treated', 'risk': 'rate', 'baseline': '@', 'beta': 'beta', 'at': 'at', 've': 've', '##er': '##al', 'the': 'the', ',': ',', 'bu': 'bu', 'have': 'had', 'not': 'not', 'failure': 'disease', '##do': '##do', 'of': 'of', 'a': 'a', '##mina': '##mina', '(': '(', '##or': '##or', 'changes': 'increase', '##rine': '##rine', 'group': 'group'}
{'with': tensor(16.3941), 'ch': tensor(18.6753), 'ad': tensor(18.5793), 'subjects': tensor(15.2725), 'that': tensor(12.1242), '.': tensor(14.2738), 'or': tensor(13.1236), '##gic': tensor(15.9157), '##l': tensor(19.6288), '@': tensor(15.5546), 'but': tensor(16.8157), 'agent': tensor(9.1377), 'method': tensor(12.3860), 'efficacy': tensor(13.2034), 'treated': tensor(17.7912), 'risk': tensor(15.0361), 'baseline': tensor(13.4532), 'beta': tensor(17.6328), 'at': tensor(13.7099), 've': tensor(16.5920), '##er': tensor(16.7415), 'the': tensor(9.5247), ',': tensor(14.1726), 'bu': tensor(22.5973), 'have': tensor(15.6736), 'not': tensor(17.0561), 'failure': tensor(17.0580), '##do': tensor(27.8539), 'of': tensor(15.0234), 'a': tensor(14.1358), '##mina': tensor(23.3295), '(': tensor(16.6772), '##or': tensor(24.2168), 'changes': tensor(14.4476), '##rine': tensor(25.7562), 'group': tensor(15.1433)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'study', 'evaluated', 'the', 'effectiveness', 'of', 'a', 'three', '-', 'year', '[MASK]', '##patient', 'commitment', 'pilot', 'program', 'established', 'in', '@', 'at', 'bellevue', '[MASK]', 'in', 'new', 'york', 'city', '.', 'methods', 'a', 'total', 'of', '@', 'participants', 'were', 'randomly', 'assigned', ';', '@', 'received', 'court', '-', '[MASK]', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', 'the', 'enhanced', '-', 'service', 'package', 'only', '.', 'methods', 'between', '@', 'and', '@', 'percent', 'of', '[MASK]', 'subjects', 'completed', 'interviews', 'at', 'one', ',', 'five', ',', 'and', '@', 'months', 'after', 'hospital', 'discharge', '.', 'methods', 'outcome', 'measures', 'included', 're', '##hos', '##pit', '##ali', '##zation', '[MASK]', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '##mpt', '##oma', '##tology', ',', 'treatment', 'non', '[MASK]', '##pl', '[MASK]', ',', 'and', 'perceived', 'level', 'of', '[MASK]', '##rc', '##ion', '.', 'results', 'on', 'all', 'major', '[MASK]', 'measures', ',', 'no', 'statistical', '##ly', 'significant', 'differences', 'were', 'found', 'between', 'the', 'two', '[MASK]', '.', 'results', 'no', 'subject', 'was', 'arrested', 'for', 'a', '[MASK]', 'crime', '.', 'results', 'eighteen', '[MASK]', 'of', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', 'of', 'the', 'control', 'group', '[MASK]', 'arrested', 'at', 'least', 'once', '.', 'results', 'the', 'percentage', 're', '##hos', '##pit', '##ali', '##zed', 'during', 'follow', '-', 'up', '[MASK]', 'about', 'the', 'same', 'for', 'both', 'groups', '-', '@', 'percent', '[MASK]', '[MASK]', 'percent', ',', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', 'differ', 'significantly', 'in', 'the', 'total', 'number', 'of', 'days', 'hospitalized', '[MASK]', 'the', '[MASK]', '[MASK]', 'up', 'period', '.', 'results', '[MASK]', "'", 'perceptions', '[MASK]', 'their', 'quality', 'of', 'life', 'and', 'level', 'of', '[MASK]', '##rc', '##ion', 'were', 'about', 'the', 'same', '.', 'results', 'from', 'the', 'community', 'service', 'providers', '[MASK]', 'perspective', '[MASK]', 'patients', 'in', 'the', '[MASK]', 'groups', 'were', 'similarly', 'adhere', '##nt', 'to', 'their', 'required', 'treatments', '.', '[MASK]', 'all', 'results', 'must', '[MASK]', 'qualified', 'by', 'the', 'fact', 'that', '[MASK]', 'pick', '-', 'up', 'order', 'procedures', 'for', 'non', '##com', '##pl', '[MASK]', '##t', 'subjects', 'in', 'the', 'court', '-', 'ordered', 'group', 'were', 'implemented', 'during', 'the', 'study', ',', 'which', 'compromised', 'the', 'differences', 'between', 'the', 'conditions', 'for', 'the', 'two', 'groups', ',', 'and', 'that', '[MASK]', 'with', 'a', 'history', 'of', 'violence', 'were', '[MASK]', 'from', '[MASK]', 'program', '.', '[SEP]']
{191: 'and', 22: 'hospital', 211: 'during', 219: 'participants', 310: 'persons', 92: ',', 122: 'outcome', 281: '##ian', 317: 'excluded', 222: 'of', 230: 'coe', 265: 'be', 135: 'groups', 114: 'coe', 163: 'were', 106: '##com', 108: '##iance', 181: 'was', 250: 'two', 149: 'percent', 192: '@', 246: ',', 12: 'out', 213: 'follow', 261: 'conclusions', 42: 'ordered', 319: 'the', 271: 'no', 214: '-', 144: 'violent', 67: 'the', 244: "'"}
loss:  20.352508544921875
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 84.38%
Average score: 15.48
{'and': 'and', 'hospital': 'hospital', 'during': 'during', 'participants': 'patients', 'persons': 'subjects', ',': ',', 'outcome': 'outcome', '##ian': '##ian', 'excluded': 'excluded', 'of': 'of', 'coe': 'coe', 'be': 'be', 'groups': 'groups', 'were': 'were', '##com': '##com', '##iance': '##iance', 'was': 'was', 'two': 'two', 'percent': 'percent', '@': '@', 'out': 'out', 'follow': 'follow', 'conclusions': 'results', 'ordered': 'ordered', 'the': 'the', 'no': 'the', '-': 'follow', 'violent': 'violent', "'": "'"}
{'and': tensor(15.4718), 'hospital': tensor(18.5320), 'during': tensor(13.5112), 'participants': tensor(14.4957), 'persons': tensor(15.0723), ',': tensor(9.5324), 'outcome': tensor(11.2792), '##ian': tensor(20.3913), 'excluded': tensor(16.3441), 'of': tensor(14.3489), 'coe': tensor(21.2417), 'be': tensor(18.2196), 'groups': tensor(18.7766), 'were': tensor(17.1101), '##com': tensor(24.4189), '##iance': tensor(18.0997), 'was': tensor(14.8981), 'two': tensor(12.2685), 'percent': tensor(13.1461), '@': tensor(13.6906), 'out': tensor(13.1640), 'follow': tensor(17.7026), 'conclusions': tensor(12.6249), 'ordered': tensor(21.0033), 'the': tensor(10.0546), 'no': tensor(9.3905), '-': tensor(17.3839), 'violent': tensor(11.4119), "'": tensor(15.2830)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', '[MASK]', 'study', 'evaluated', 'the', 'effectiveness', 'of', 'a', 'three', '-', 'year', '[MASK]', '##patient', '[MASK]', 'pilot', 'program', 'established', 'in', '@', 'at', 'bellevue', 'hospital', 'in', 'new', 'york', 'city', '.', 'methods', 'a', 'total', '[MASK]', '@', 'participants', '[MASK]', 'randomly', 'assigned', '[MASK]', '@', 'received', 'court', '-', 'ordered', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', 'the', 'enhanced', '-', 'service', 'package', 'only', '.', 'methods', 'between', '[MASK]', 'and', '@', 'percent', 'of', 'the', 'subjects', 'completed', 'interviews', 'at', 'one', '[MASK]', 'five', '[MASK]', 'and', '@', 'months', 'after', 'hospital', 'discharge', '[MASK]', 'methods', '[MASK]', 'measures', 'included', 're', '##hos', '##pit', '##ali', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '##mpt', '[MASK]', '##tology', ',', 'treatment', 'non', '##com', '##pl', '##iance', ',', 'and', 'perceived', 'level', 'of', 'coe', '##rc', '##ion', '.', 'results', 'on', 'all', 'major', 'outcome', 'measures', ',', 'no', 'statistical', '[MASK]', 'significant', 'differences', '[MASK]', 'found', 'between', 'the', 'two', 'groups', '.', 'results', 'no', 'subject', 'was', 'arrested', 'for', 'a', 'violent', '[MASK]', '.', 'results', 'eighteen', 'percent', 'of', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', 'of', 'the', 'control', 'group', 'were', 'arrested', 'at', 'least', 'once', '.', 'results', 'the', 'percentage', 're', '[MASK]', '##pit', '##ali', '##zed', '[MASK]', '[MASK]', '-', 'up', 'was', 'about', 'the', 'same', 'for', 'both', 'groups', '-', '@', '[MASK]', 'and', '[MASK]', 'percent', ',', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', '[MASK]', 'significantly', '[MASK]', 'the', 'total', '[MASK]', 'of', 'days', 'hospitalized', 'during', 'the', 'follow', '-', 'up', 'period', '.', 'results', 'participants', "'", 'perceptions', 'of', 'their', 'quality', 'of', 'life', '[MASK]', 'level', 'of', '[MASK]', '[MASK]', '##ion', '[MASK]', 'about', 'the', 'same', '.', 'results', 'from', 'the', 'community', 'service', 'providers', "'", 'perspective', ',', 'patients', 'in', 'the', 'two', 'groups', 'were', 'similarly', 'adhere', '##nt', 'to', 'their', 'required', 'treatments', '.', 'conclusions', 'all', 'results', 'must', '[MASK]', '[MASK]', 'by', 'the', 'fact', 'that', 'no', 'pick', '-', 'up', 'order', 'procedures', 'for', 'non', '##com', '[MASK]', '##ian', '##t', 'subjects', 'in', 'the', 'court', '-', 'ordered', 'group', 'were', 'implemented', 'during', 'the', 'study', ',', 'which', 'compromised', 'the', 'differences', '[MASK]', 'the', 'conditions', '[MASK]', 'the', 'two', 'groups', ',', 'and', 'that', 'persons', 'with', 'a', 'history', 'of', 'violence', 'were', 'excluded', 'from', 'the', 'program', '.', '[SEP]']
{75: ',', 265: 'be', 14: 'commitment', 231: '##rc', 145: 'crime', 82: '.', 202: 'differ', 34: 'were', 233: 'were', 173: '##hos', 190: 'percent', 177: 'during', 300: 'between', 227: 'and', 230: 'coe', 62: '@', 207: 'number', 303: 'for', 101: '##oma', 178: 'follow', 130: 'were', 280: '##pl', 2: 'the', 192: '@', 73: ',', 12: 'out', 31: 'of', 37: ';', 266: 'qualified', 127: '##ly', 84: 'outcome', 204: 'in'}
loss:  19.62783432006836
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 65.62%
Average score: 14.25
{',': 'to', 'be': 'be', 'commitment': 'treatment', '##rc': '##flict', 'crime': 'crime', '.': '.', 'differ': 'differ', 'were': 'were', '##hos': '##hos', 'percent': 'zero', 'during': 'and', 'between': 'between', 'and': 'and', 'coe': 'physical', '@': '@', 'number': 'number', 'for': 'between', '##oma': '##oma', 'follow': 'follow', '##pl': '##pl', 'the': 'evaluation', 'out': 'out', 'of': 'of', ';': '.', 'qualified': 'supported', '##ly': '##ly', 'outcome': 'and', 'in': 'in'}
{',': tensor(10.6774), 'be': tensor(17.1436), 'commitment': tensor(9.5150), '##rc': tensor(12.9854), 'crime': tensor(12.6629), '.': tensor(15.3035), 'differ': tensor(14.3046), 'were': tensor(18.7850), '##hos': tensor(25.5397), 'percent': tensor(8.4182), 'during': tensor(8.2623), 'between': tensor(15.7012), 'and': tensor(14.1973), 'coe': tensor(9.0150), '@': tensor(11.4793), 'number': tensor(17.5258), 'for': tensor(14.2289), '##oma': tensor(24.8293), 'follow': tensor(15.8684), '##pl': tensor(25.3360), 'the': tensor(7.2399), 'out': tensor(12.9758), 'of': tensor(11.5032), ';': tensor(11.9925), 'qualified': tensor(13.5421), '##ly': tensor(18.4080), 'outcome': tensor(10.1436), 'in': tensor(11.3069)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'the', '[MASK]', 'evaluated', '[MASK]', 'effectiveness', 'of', 'a', 'three', '-', 'year', 'out', '##patient', 'commitment', 'pilot', 'program', 'established', 'in', '@', 'at', 'bellevue', '[MASK]', 'in', '[MASK]', 'york', 'city', '.', 'methods', 'a', 'total', 'of', '@', 'participants', 'were', 'randomly', 'assigned', ';', '@', 'received', 'court', '-', 'ordered', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', 'the', 'enhanced', '-', 'service', 'package', '[MASK]', '.', 'methods', 'between', '@', 'and', '@', 'percent', '[MASK]', 'the', 'subjects', 'completed', '[MASK]', 'at', 'one', ',', 'five', ',', 'and', '@', 'months', '[MASK]', 'hospital', 'discharge', '.', 'methods', '[MASK]', 'measures', 'included', 're', '##hos', '##pit', '[MASK]', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '##mpt', '##oma', '##tology', ',', 'treatment', 'non', '##com', '##pl', '##iance', ',', 'and', 'perceived', 'level', 'of', 'coe', '##rc', '##ion', '.', 'results', '[MASK]', 'all', 'major', 'outcome', 'measures', ',', 'no', 'statistical', '##ly', 'significant', 'differences', 'were', 'found', 'between', '[MASK]', 'two', 'groups', '.', 'results', 'no', 'subject', 'was', 'arrested', 'for', 'a', 'violent', 'crime', '.', 'results', 'eighteen', 'percent', 'of', 'the', 'court', '-', '[MASK]', 'group', 'and', '@', 'percent', 'of', 'the', '[MASK]', 'group', 'were', 'arrested', 'at', 'least', '[MASK]', '.', '[MASK]', 'the', 'percentage', 're', '##hos', '##pit', '##ali', '##zed', 'during', 'follow', '-', 'up', 'was', 'about', 'the', 'same', 'for', 'both', 'groups', '-', '@', 'percent', 'and', '@', 'percent', ',', 'respectively', '[MASK]', 'results', 'the', '[MASK]', 'did', '[MASK]', 'differ', 'significantly', 'in', 'the', 'total', 'number', 'of', 'days', 'hospitalized', 'during', '[MASK]', 'follow', '-', 'up', 'period', '.', 'results', 'participants', "'", 'perceptions', 'of', 'their', 'quality', '[MASK]', 'life', 'and', 'level', 'of', '[MASK]', '##rc', '##ion', 'were', 'about', 'the', 'same', '[MASK]', 'results', 'from', 'the', 'community', 'service', '[MASK]', '[MASK]', 'perspective', ',', 'patients', 'in', 'the', 'two', 'groups', 'were', 'similarly', 'adhere', '##nt', 'to', '[MASK]', 'required', '[MASK]', '.', 'conclusions', 'all', 'results', 'must', 'be', 'qualified', 'by', 'the', 'fact', '[MASK]', 'no', 'pick', '-', 'up', 'order', 'procedures', 'for', 'non', '##com', '##pl', '##ian', '##t', 'subjects', 'in', '[MASK]', 'court', '-', 'ordered', 'group', 'were', 'implemented', 'during', 'the', 'study', ',', 'which', 'compromised', '[MASK]', 'differences', 'between', 'the', 'conditions', 'for', 'the', 'two', 'groups', ',', 'and', 'that', 'persons', 'with', 'a', 'history', 'of', 'violence', 'were', 'excluded', 'from', 'the', '[MASK]', '.', '[SEP]']
{212: 'the', 24: 'new', 161: 'control', 1: 'objective', 66: 'of', 230: 'coe', 167: 'once', 298: 'the', 5: 'the', 259: 'treatments', 199: 'groups', 243: 'providers', 244: "'", 270: 'that', 320: 'program', 225: 'of', 257: 'their', 133: 'the', 70: 'interviews', 90: '##ali', 79: 'after', 3: 'study', 285: 'the', 119: 'on', 196: '.', 169: 'results', 237: '.', 201: 'not', 154: 'ordered', 84: 'outcome', 22: 'hospital', 58: 'only'}
loss:  20.348844528198242
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 59.38%
Average score: 14.82
{'the': 'the', 'new': 'new', 'control': 'same', 'objective': 'results', 'of': 'of', 'coe': 'coe', 'once': 'once', 'treatments': 'treatment', 'groups': 'subjects', 'providers': 'and', "'": 'group', 'that': 'that', 'program': 'study', 'their': 'the', 'interviews': 'treatment', '##ali': '##ali', 'after': 'after', 'study': 'study', 'on': 'from', '.': '.', 'results': 'results', 'not': 'not', 'ordered': 'ordered', 'outcome': 'and', 'hospital': 'hospital', 'only': 'program'}
{'the': tensor(13.9817), 'new': tensor(21.4321), 'control': tensor(9.7421), 'objective': tensor(12.9149), 'of': tensor(16.6984), 'coe': tensor(26.2283), 'once': tensor(16.5370), 'treatments': tensor(12.1775), 'groups': tensor(11.2656), 'providers': tensor(9.7493), "'": tensor(8.2858), 'that': tensor(15.1624), 'program': tensor(13.2124), 'their': tensor(12.4377), 'interviews': tensor(14.9084), '##ali': tensor(31.0454), 'after': tensor(11.5240), 'study': tensor(11.3190), 'on': tensor(12.3588), '.': tensor(13.2093), 'results': tensor(15.0647), 'not': tensor(16.5676), 'ordered': tensor(21.8121), 'outcome': tensor(10.7445), 'hospital': tensor(18.4105), 'only': tensor(8.4742)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'study', 'evaluated', 'the', 'effectiveness', 'of', 'a', 'three', '-', 'year', 'out', '##patient', '[MASK]', 'pilot', '[MASK]', 'established', 'in', '@', '[MASK]', 'bellevue', 'hospital', 'in', 'new', 'york', 'city', '.', 'methods', 'a', 'total', '[MASK]', '@', 'participants', 'were', '[MASK]', '[MASK]', ';', '@', 'received', 'court', '[MASK]', 'ordered', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', 'the', 'enhanced', '-', 'service', 'package', 'only', '[MASK]', 'methods', 'between', '@', 'and', '@', 'percent', 'of', 'the', 'subjects', 'completed', 'interviews', 'at', 'one', ',', 'five', ',', 'and', '@', 'months', 'after', 'hospital', 'discharge', '.', 'methods', 'outcome', 'measures', 'included', 're', '##hos', '##pit', '##ali', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '##mpt', '##oma', '##tology', ',', 'treatment', 'non', '##com', '##pl', '##iance', ',', 'and', 'perceived', 'level', 'of', 'coe', '##rc', '##ion', '.', 'results', 'on', 'all', 'major', 'outcome', 'measures', ',', 'no', 'statistical', '##ly', 'significant', 'differences', '[MASK]', 'found', 'between', 'the', '[MASK]', 'groups', '.', 'results', 'no', 'subject', 'was', 'arrested', 'for', 'a', 'violent', 'crime', '.', 'results', 'eighteen', 'percent', 'of', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', 'of', 'the', 'control', '[MASK]', 'were', 'arrested', 'at', 'least', 'once', '.', 'results', '[MASK]', 'percentage', 're', '##hos', '[MASK]', '##ali', '[MASK]', 'during', 'follow', '-', 'up', 'was', 'about', 'the', 'same', 'for', 'both', 'groups', '-', '@', 'percent', 'and', '@', 'percent', ',', 'respectively', '.', 'results', 'the', '[MASK]', 'did', 'not', 'differ', '[MASK]', 'in', 'the', 'total', 'number', 'of', 'days', 'hospitalized', 'during', 'the', 'follow', '-', '[MASK]', 'period', '[MASK]', '[MASK]', 'participants', "'", 'perceptions', 'of', 'their', '[MASK]', 'of', 'life', 'and', '[MASK]', 'of', 'coe', '##rc', '##ion', 'were', 'about', 'the', 'same', '[MASK]', '[MASK]', 'from', 'the', 'community', 'service', 'providers', "'", 'perspective', ',', 'patients', 'in', 'the', 'two', '[MASK]', 'were', 'similarly', '[MASK]', '##nt', 'to', 'their', '[MASK]', 'treatments', '.', 'conclusions', 'all', 'results', 'must', 'be', 'qualified', 'by', 'the', 'fact', 'that', 'no', 'pick', '-', 'up', 'order', 'procedures', 'for', 'non', '##com', '##pl', '##ian', '##t', 'subjects', 'in', 'the', 'court', '[MASK]', 'ordered', 'group', '[MASK]', 'implemented', 'during', '[MASK]', '[MASK]', ',', 'which', 'compromised', 'the', 'differences', 'between', 'the', 'conditions', 'for', '[MASK]', 'two', 'groups', ',', 'and', 'that', 'persons', 'with', 'a', 'history', 'of', '[MASK]', 'were', 'excluded', 'from', 'the', 'program', '.', '[SEP]']
{170: 'the', 215: 'up', 176: '##zed', 16: 'program', 199: 'groups', 224: 'quality', 218: 'results', 287: '-', 203: 'significantly', 228: 'level', 238: 'results', 59: '.', 31: 'of', 315: 'violence', 36: 'assigned', 237: '.', 290: 'were', 130: 'were', 174: '##pit', 20: 'at', 293: 'the', 254: 'adhere', 304: 'the', 258: 'required', 35: 'randomly', 251: 'groups', 294: 'study', 162: 'group', 134: 'two', 217: '.', 14: 'commitment', 41: '-'}
loss:  19.735504150390625
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 68.75%
Average score: 15.04
{'the': 'the', 'up': 'up', '##zed': '##zation', 'program': 'program', 'groups': 'groups', 'quality': 'quality', 'results': '.', '-': '-', 'significantly': 'significantly', 'level': 'level', '.': '.', 'of': 'of', 'violence': 'abuse', 'assigned': 'tested', 'were': 'were', '##pit': '##pit', 'at': 'at', 'adhere': 'adhere', 'required': 'previous', 'randomly': 'not', 'study': 'treatment', 'group': 'group', 'two': 'two', 'commitment': 'treatment'}
{'the': tensor(15.0187), 'up': tensor(18.9161), '##zed': tensor(25.4822), 'program': tensor(15.0038), 'groups': tensor(18.2107), 'quality': tensor(18.2533), 'results': tensor(12.5277), '-': tensor(19.8727), 'significantly': tensor(11.1321), 'level': tensor(15.1901), '.': tensor(12.1049), 'of': tensor(11.4355), 'violence': tensor(13.4421), 'assigned': tensor(11.4486), 'were': tensor(18.7489), '##pit': tensor(25.9503), 'at': tensor(9.8705), 'adhere': tensor(13.5094), 'required': tensor(9.8248), 'randomly': tensor(9.4515), 'study': tensor(12.9182), 'group': tensor(16.1245), 'two': tensor(16.1047), 'commitment': tensor(10.4479)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'study', 'evaluated', 'the', 'effectiveness', 'of', 'a', 'three', '-', 'year', 'out', '##patient', 'commitment', 'pilot', '[MASK]', 'established', 'in', '@', 'at', 'bellevue', 'hospital', 'in', 'new', 'york', '[MASK]', '.', 'methods', 'a', 'total', '[MASK]', '@', 'participants', 'were', 'randomly', 'assigned', ';', '@', 'received', 'court', '-', 'ordered', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', 'the', 'enhanced', '-', 'service', 'package', '[MASK]', '[MASK]', 'methods', 'between', '@', 'and', '@', 'percent', 'of', 'the', 'subjects', 'completed', 'interviews', 'at', 'one', ',', 'five', ',', 'and', '@', '[MASK]', 'after', 'hospital', 'discharge', '.', 'methods', 'outcome', 'measures', 'included', 're', '##hos', '##pit', '##ali', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', '[MASK]', 'sy', '##mpt', '##oma', '[MASK]', ',', 'treatment', '[MASK]', '[MASK]', '##pl', '##iance', ',', 'and', 'perceived', 'level', 'of', 'coe', '##rc', '##ion', '.', 'results', 'on', 'all', 'major', 'outcome', 'measures', ',', 'no', 'statistical', '[MASK]', '[MASK]', 'differences', 'were', '[MASK]', 'between', 'the', 'two', 'groups', '[MASK]', 'results', 'no', 'subject', 'was', 'arrested', 'for', '[MASK]', 'violent', 'crime', '.', 'results', 'eighteen', '[MASK]', 'of', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', 'of', 'the', 'control', 'group', 'were', 'arrested', 'at', 'least', 'once', '.', '[MASK]', 'the', 'percentage', 're', '##hos', '##pit', '##ali', '##zed', 'during', 'follow', '-', 'up', 'was', 'about', 'the', 'same', 'for', 'both', 'groups', '-', '@', 'percent', 'and', '@', 'percent', ',', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', 'differ', 'significantly', 'in', 'the', 'total', 'number', 'of', '[MASK]', '[MASK]', 'during', 'the', 'follow', '-', 'up', 'period', '.', 'results', 'participants', "'", 'perceptions', 'of', 'their', 'quality', 'of', 'life', 'and', 'level', 'of', '[MASK]', '##rc', '##ion', 'were', 'about', 'the', 'same', '.', 'results', 'from', 'the', 'community', 'service', 'providers', '[MASK]', 'perspective', ',', 'patients', 'in', 'the', '[MASK]', 'groups', 'were', 'similarly', '[MASK]', '[MASK]', 'to', '[MASK]', 'required', 'treatments', '.', 'conclusions', 'all', 'results', '[MASK]', '[MASK]', 'qualified', 'by', 'the', 'fact', '[MASK]', 'no', 'pick', '-', 'up', 'order', 'procedures', 'for', 'non', '##com', '##pl', '##ian', '[MASK]', '[MASK]', 'in', '[MASK]', 'court', '-', 'ordered', 'group', 'were', 'implemented', 'during', 'the', 'study', ',', 'which', 'compromised', 'the', 'differences', 'between', 'the', 'conditions', 'for', 'the', 'two', 'groups', ',', '[MASK]', 'that', 'persons', 'with', 'a', 'history', 'of', 'violence', 'were', 'excluded', 'from', 'the', 'program', '.', '[SEP]']
{149: 'percent', 136: '.', 78: 'months', 254: 'adhere', 169: 'results', 58: 'only', 257: 'their', 128: 'significant', 285: 'the', 26: 'city', 270: 'that', 282: '##t', 283: 'subjects', 250: 'two', 255: '##nt', 230: 'coe', 131: 'found', 105: 'non', 209: 'days', 244: "'", 102: '##tology', 265: 'be', 143: 'a', 106: '##com', 210: 'hospitalized', 59: '.', 98: ',', 31: 'of', 127: '##ly', 308: 'and', 16: 'program', 264: 'must'}
loss:  18.639862060546875
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 56.25%
Average score: 13.30
{'percent': 'members', '.': '.', 'months': 'percent', 'adhere': 'less', 'results': 'results', 'only': '.', 'their': 'the', 'significant': 'significant', 'the': 'the', 'city': 'city', 'that': 'that', '##t': '##t', 'subjects': 'patients', 'two': 'two', '##nt': 'entitled', 'coe': 'coe', 'found': 'found', 'non': 'schedule', 'days': 'patients', "'": "'", '##tology': '##tology', 'be': 'further', 'a': 'a', '##com': 'com', 'hospitalized': 'arrests', ',': ',', 'of': 'of', '##ly': 'or', 'and': 'and', 'program': 'program', 'must': 'were'}
{'percent': tensor(13.3602), '.': tensor(9.0998), 'months': tensor(11.7512), 'adhere': tensor(9.1837), 'results': tensor(15.2181), 'only': tensor(13.1063), 'their': tensor(10.9041), 'significant': tensor(7.4071), 'the': tensor(13.6690), 'city': tensor(16.7813), 'that': tensor(14.4568), '##t': tensor(18.1916), 'subjects': tensor(12.9143), 'two': tensor(12.7727), '##nt': tensor(10.2136), 'coe': tensor(25.6741), 'found': tensor(14.1012), 'non': tensor(8.7337), 'days': tensor(12.0451), "'": tensor(13.3700), '##tology': tensor(20.9695), 'be': tensor(10.5072), 'a': tensor(13.4371), '##com': tensor(14.3050), 'hospitalized': tensor(12.1833), ',': tensor(12.2185), 'of': tensor(11.5506), '##ly': tensor(12.8837), 'and': tensor(12.1988), 'program': tensor(14.5801), 'must': tensor(14.4815)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '(', 'der', '##ma', '##bon', '##d', '[MASK]', 'is', 'a', 'tissue', '`', '[MASK]', 'glue', "'", "'", 'useful', 'in', 'closing', 'surgical', 'skin', 'inc', '##ision', '##s', '[MASK]', 'objective', 'we', 'compared', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'with', 'sub', '##cut', '##icular', 'skin', 'su', '##tures', 'to', 'close', 'lap', '##aro', '##scopic', 'tr', '##oca', '##r', 'sites', '.', 'methods', 'a', 'random', '##ized', 'double', '-', 'armed', 'study', 'was', 'performed', 'with', '@', 'patients', '[MASK]', 'whom', '@', '[MASK]', '[MASK]', '##r', 'sites', 'were', 'closed', '.', 'methods', 'twenty', '-', 'nine', 'patients', 'underwent', 'sub', '##cut', '##icular', 'closure', 'with', '@', '-', '@', 'absorb', '##able', 'su', '##ture', ',', 'and', 'thirty', 'patients', 'received', 'closure', '[MASK]', 'oct', '##yl', '##cy', '[MASK]', '##ac', '##ryl', '##ate', 'in', 'accordance', 'with', 'the', 'recommendations', 'of', 'the', 'manufacturer', '(', 'et', '##hic', '##on', ';', 'somerville', ',', 'nj', ')', '.', '[MASK]', 'the', 'number', '[MASK]', 'su', '##tures', 'or', 'vial', '##s', 'of', 'oct', '[MASK]', '##cy', '##ano', '##ac', '[MASK]', '##ate', 'used', ',', 'closure', 'times', '[MASK]', 'and', 'post', '##oper', '##ative', '[MASK]', 'problems', 'were', 'recorded', '.', 'methods', 'wounds', '[MASK]', '[MASK]', '@', 'weeks', 'post', '##oper', '##ative', '##ly', 'for', '[MASK]', 'complications', '.', 'methods', 'closure', 'costs', '[MASK]', 'estimated', 'using', 'published', 'operating', 'room', 'time', 'per', 'hour', 'plus', 'the', '[MASK]', 'of', 'oct', '##yl', '##cy', '##ano', '[MASK]', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', '[MASK]', "'", 's', 'paired', '[MASK]', '-', 'test', 'was', 'used', 'for', 'statistical', 'analysis', '.', '[MASK]', 'the', 'overall', 'mean', 'time', 'required', 'for', 'skin', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '[MASK]', 'and', 'su', '##ture', 'was', '@', 'minutes', 'and', '@', 'minutes', ',', 'respectively', '(', 'p', '<', '@', ')', '.', 'results', 'an', 'average', 'of', '@', 'packets', 'of', 'su', '##ture', 'were', 'used', '[MASK]', 'close', '[MASK]', 'port', 'sites', 'in', 'a', 'particular', 'patient', '[MASK]', 'while', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'required', 'an', 'average', 'of', '@', 'vial', '##s', 'per', 'patient', '.', '[MASK]', 'wound', 'complications', 'consisted', 'of', 'sub', '##cut', '##icular', '[MASK]', '[MASK]', 'with', 'skin', 'separation', 'and', 'were', 'equally', 'common', 'in', 'the', 'two', '[MASK]', '.', 'results', 'the', 'overall', 'average', 'cost', 'per', 'closure', 'using', 'oct', '##yl', '[MASK]', '##ano', '##ac', '##ryl', '##ate', 'was', '$', '@', 'us', 'dollars', ',', 'while', '[MASK]', 'cost', 'for', 'closure', '[MASK]', 'su', '[MASK]', 'was', '$', '@', 'us', 'dollars', '(', '[MASK]', '<', '@', ')', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', '[MASK]', 'effective', '.', 'conclusions', 'the', 'method', 'yields', 'cost', 'savings', 'and', 'a', 'decrease', 'in', '[MASK]', 'time', 'of', 'more', 'than', '@', '[MASK]', 'per', 'case', '.', '[SEP]']
{19: '`', 266: 'all', 264: 'to', 76: 'tr', 73: 'in', 192: 'cost', 235: '##ate', 159: 'wound', 273: ',', 111: '##ano', 198: '##ac', 107: 'with', 338: 'the', 210: 't', 31: '.', 77: '##oca', 294: 'results', 394: 'minutes', 133: 'methods', 144: '##yl', 303: '##oma', 388: 'operative', 166: 'were', 206: 'student', 175: 'healing', 219: 'results', 302: 'ser', 326: '##cy', 314: 'groups', 136: 'of', 181: 'were', 148: '##ryl', 342: 'using', 375: 'and', 167: 'assessed', 351: 'p', 344: '##ture', 154: ',', 14: ')'}
loss:  19.314632415771484
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 53.85%
Average score: 14.81
{'`': "'", 'all': 'the', 'to': 'to', 'tr': '-', 'in': 'for', 'cost': 'amount', '##ate': '##ate', 'wound': 'closure', ',': ',', '##ano': '##ano', '##ac': '##ac', 'with': 'with', 'the': 'average', 't': 't', '.': '.', '##oca': 'ao', 'results': 'results', 'minutes': 'minutes', 'methods': 'from', '##yl': '##yl', '##oma': 'closure', 'operative': 'closure', 'were': 'were', 'student': 'ai', 'healing': 'wound', 'ser': 'closure', '##cy': '##cy', 'groups': 'cases', 'of': 'of', '##ryl': '##ryl', 'using': 'with', 'and': 'and', 'assessed': 'closed', 'p': 'p', '##ture': '##ture', ')': ')'}
{'`': tensor(10.9410), 'all': tensor(8.3238), 'to': tensor(14.2812), 'tr': tensor(11.1074), 'in': tensor(12.6115), 'cost': tensor(12.2918), '##ate': tensor(25.8741), 'wound': tensor(10.3553), ',': tensor(12.9364), '##ano': tensor(27.7114), '##ac': tensor(27.9605), 'with': tensor(14.5436), 'the': tensor(12.2752), 't': tensor(7.3440), '.': tensor(12.6494), '##oca': tensor(9.6052), 'results': tensor(14.4529), 'minutes': tensor(10.6911), 'methods': tensor(8.6015), '##yl': tensor(26.0444), '##oma': tensor(13.5904), 'operative': tensor(11.7994), 'were': tensor(14.8814), 'student': tensor(5.0968), 'healing': tensor(11.7252), 'ser': tensor(12.3616), '##cy': tensor(23.5654), 'groups': tensor(13.1022), 'of': tensor(15.6597), '##ryl': tensor(30.1378), 'using': tensor(12.7471), 'and': tensor(13.9248), 'assessed': tensor(10.9551), 'p': tensor(13.9362), '##ture': tensor(21.5988), ')': tensor(17.6295)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '(', 'der', '##ma', '[MASK]', '##d', ')', 'is', 'a', 'tissue', '`', '`', 'glue', "'", "'", 'useful', 'in', 'closing', 'surgical', 'skin', 'inc', '##ision', '##s', '.', 'objective', 'we', 'compared', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'with', 'sub', '##cut', '[MASK]', 'skin', 'su', '##tures', 'to', 'close', 'lap', '##aro', '##scopic', '[MASK]', '##oca', '##r', 'sites', '.', 'methods', '[MASK]', 'random', '##ized', 'double', '[MASK]', 'armed', 'study', 'was', 'performed', 'with', '@', 'patients', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '[MASK]', 'methods', 'twenty', '-', 'nine', 'patients', 'underwent', 'sub', '##cut', '##icular', '[MASK]', '[MASK]', '@', '-', '@', 'absorb', '##able', 'su', '[MASK]', ',', 'and', 'thirty', 'patients', 'received', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'in', 'accordance', 'with', 'the', 'recommendations', 'of', '[MASK]', 'manufacturer', '(', 'et', '##hic', '##on', ';', '[MASK]', ',', 'nj', ')', '.', 'methods', 'the', 'number', 'of', 'su', '##tures', 'or', 'vial', '##s', 'of', 'oct', '[MASK]', '##cy', '##ano', '##ac', '##ryl', '##ate', 'used', ',', 'closure', 'times', ',', '[MASK]', 'post', '##oper', '##ative', 'wound', 'problems', 'were', 'recorded', '.', 'methods', 'wounds', 'were', '[MASK]', '@', 'weeks', 'post', '##oper', '[MASK]', '[MASK]', 'for', 'healing', 'complications', '.', 'methods', 'closure', 'costs', '[MASK]', 'estimated', 'using', 'published', 'operating', 'room', 'time', 'per', '[MASK]', 'plus', 'the', 'cost', '[MASK]', 'oct', '##yl', '##cy', '[MASK]', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', 'student', "'", 's', 'paired', 't', '-', 'test', 'was', 'used', '[MASK]', 'statistical', 'analysis', '.', 'results', 'the', 'overall', '[MASK]', 'time', 'required', 'for', 'skin', '[MASK]', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'and', 'su', '##ture', 'was', '[MASK]', 'minutes', 'and', '@', 'minutes', ',', 'respectively', '(', 'p', '<', '@', ')', '[MASK]', 'results', 'an', 'average', 'of', '@', 'packets', 'of', 'su', '##ture', 'were', 'used', 'to', 'close', 'all', '[MASK]', 'sites', '[MASK]', 'a', 'particular', 'patient', ',', 'while', 'closure', 'with', 'oct', '##yl', '[MASK]', '##ano', '##ac', '[MASK]', '##ate', 'required', 'an', '[MASK]', '[MASK]', '@', 'vial', '[MASK]', 'per', '[MASK]', '.', 'results', 'wound', 'complications', 'consisted', 'of', 'sub', '##cut', '##icular', 'ser', '##oma', 'with', 'skin', 'separation', 'and', 'were', 'equally', 'common', 'in', 'the', 'two', 'groups', '.', 'results', 'the', 'overall', 'average', 'cost', 'per', 'closure', '[MASK]', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'was', '$', '@', 'us', 'dollars', ',', 'while', 'the', 'cost', 'for', 'closure', 'using', 'su', '##ture', 'was', '$', '@', '[MASK]', 'dollars', '(', 'p', '<', '@', ')', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', 'and', 'effective', '.', 'conclusions', 'the', 'method', 'yields', '[MASK]', 'savings', '[MASK]', 'a', 'decrease', 'in', 'operative', 'time', 'of', 'more', 'than', '@', 'minutes', '[MASK]', '[MASK]', '.', '[SEP]']
{290: '##s', 252: '.', 93: 'with', 348: 'us', 82: '.', 55: 'tr', 173: '##ly', 395: 'per', 155: 'and', 12: '##bon', 227: 'closure', 172: '##ative', 61: 'a', 144: '##yl', 384: 'and', 193: 'of', 286: 'average', 292: 'patient', 279: '##cy', 46: '##icular', 282: '##ryl', 396: 'case', 215: 'for', 181: 'were', 382: 'cost', 92: 'closure', 189: 'hour', 167: 'assessed', 267: 'port', 287: 'of', 65: '-', 323: 'using', 197: '##ano', 128: 'somerville', 269: 'in', 100: '##ture', 240: '@', 121: 'the', 222: 'mean'}
loss:  19.53663444519043
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 69.23%
Average score: 14.91
{'##s': '##s', '.': '.', 'with': 'with', 'us': 'us', 'tr': 'tr', '##ly': 'procedures', 'per': 'per', 'and': 'and', '##bon': '##mi', 'closure': 'closure', '##ative': '##ative', 'a': 'a', '##yl': '##yl', 'of': '@', 'average': 'average', 'patient': 'patient', '##cy': '##cy', '##icular': '##icular', '##ryl': '##ryl', 'case': 'each', 'for': 'for', 'were': 'were', 'cost': 'significant', 'hour': 'patient', 'assessed': 'closed', 'port': 'the', '-': '-', 'using': 'with', '##ano': '##ano', 'somerville': 'newark', 'in': 'in', '##ture': '##tures', '@': '@', 'the': 'the', 'mean': 'operating'}
{'##s': tensor(13.4128), '.': tensor(14.5160), 'with': tensor(9.1722), 'us': tensor(13.4642), 'tr': tensor(23.4746), '##ly': tensor(9.1824), 'per': tensor(10.2355), 'and': tensor(10.6424), '##bon': tensor(9.9000), 'closure': tensor(12.0337), '##ative': tensor(22.3131), 'a': tensor(11.6809), '##yl': tensor(25.7118), 'of': tensor(10.5268), 'average': tensor(13.4469), 'patient': tensor(10.9952), '##cy': tensor(23.8404), '##icular': tensor(19.5548), '##ryl': tensor(29.5874), 'case': tensor(8.2343), 'for': tensor(12.2091), 'were': tensor(15.1175), 'cost': tensor(10.0115), 'hour': tensor(13.2558), 'assessed': tensor(14.1804), 'port': tensor(8.7653), '-': tensor(14.2386), 'using': tensor(13.5081), '##ano': tensor(26.9060), 'somerville': tensor(12.9155), 'in': tensor(13.9715), '##ture': tensor(22.0302), '@': tensor(18.9450), 'the': tensor(12.3831), 'mean': tensor(11.3286)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '(', 'der', '##ma', '[MASK]', '[MASK]', ')', 'is', 'a', 'tissue', '`', '`', 'glue', '[MASK]', "'", 'useful', 'in', 'closing', 'surgical', 'skin', 'inc', '##ision', '##s', '.', 'objective', 'we', 'compared', 'skin', 'oct', '##yl', '[MASK]', '[MASK]', '##ac', '##ryl', '##ate', 'with', 'sub', '[MASK]', '##icular', 'skin', 'su', '[MASK]', 'to', 'close', 'lap', '[MASK]', '##scopic', 'tr', '##oca', '##r', 'sites', '.', 'methods', 'a', 'random', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'study', 'was', 'performed', 'with', '@', 'patients', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', '[MASK]', '.', 'methods', 'twenty', '-', '[MASK]', 'patients', 'underwent', 'sub', '##cut', '##icular', '[MASK]', 'with', '[MASK]', '-', '@', 'absorb', '##able', '[MASK]', '##ture', ',', 'and', 'thirty', '[MASK]', 'received', 'closure', '[MASK]', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '[MASK]', '[MASK]', 'with', 'the', 'recommendations', 'of', 'the', 'manufacturer', '(', 'et', '##hic', '##on', ';', 'somerville', ',', 'nj', ')', '.', 'methods', 'the', 'number', 'of', 'su', '##tures', 'or', 'vial', '[MASK]', 'of', 'oct', '##yl', '##cy', '[MASK]', '##ac', '##ryl', '##ate', 'used', ',', 'closure', 'times', ',', 'and', 'post', '##oper', '##ative', 'wound', 'problems', 'were', 'recorded', '.', 'methods', 'wounds', 'were', 'assessed', '@', 'weeks', 'post', '##oper', '##ative', '##ly', 'for', 'healing', 'complications', '.', 'methods', 'closure', 'costs', 'were', 'estimated', 'using', 'published', '[MASK]', 'room', 'time', 'per', '[MASK]', 'plus', '[MASK]', '[MASK]', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', 'student', "'", 's', 'paired', 't', '-', 'test', 'was', 'used', 'for', 'statistical', 'analysis', '.', 'results', 'the', 'overall', 'mean', 'time', 'required', 'for', 'skin', 'closure', 'using', 'oct', '[MASK]', '##cy', '##ano', '##ac', '##ryl', '##ate', 'and', 'su', '##ture', 'was', '@', 'minutes', 'and', '@', 'minutes', ',', 'respectively', '(', 'p', '<', '@', '[MASK]', '.', '[MASK]', 'an', 'average', 'of', '@', 'packets', 'of', 'su', '##ture', 'were', 'used', 'to', 'close', '[MASK]', 'port', 'sites', 'in', 'a', 'particular', 'patient', ',', 'while', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'required', 'an', 'average', 'of', '@', 'vial', '##s', 'per', 'patient', '.', 'results', 'wound', 'complications', 'consisted', 'of', 'sub', '##cut', '##icular', '[MASK]', '##oma', 'with', 'skin', 'separation', 'and', 'were', 'equally', 'common', 'in', 'the', 'two', 'groups', '[MASK]', 'results', 'the', 'overall', 'average', 'cost', 'per', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'was', '$', '@', 'us', 'dollars', ',', 'while', 'the', 'cost', 'for', 'closure', 'using', 'su', '##ture', 'was', '[MASK]', '@', 'us', 'dollars', '(', '[MASK]', '<', '[MASK]', ')', '.', 'conclusions', 'lap', '##aro', '[MASK]', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', 'and', 'effective', '.', 'conclusions', 'the', 'method', 'yields', 'cost', 'savings', '[MASK]', 'a', 'decrease', 'in', 'operative', 'time', 'of', 'more', 'than', '@', '[MASK]', 'per', 'case', '.', '[SEP]']
{185: 'operating', 39: '##ano', 64: 'double', 21: "'", 189: 'hour', 192: 'cost', 45: '##cut', 315: '.', 99: 'su', 359: '##scopic', 65: '-', 394: 'minutes', 12: '##bon', 351: 'p', 141: '##s', 94: '@', 49: '##tures', 107: 'with', 81: 'closed', 63: '##ized', 13: '##d', 116: 'accordance', 266: 'all', 253: 'results', 92: 'closure', 86: 'nine', 66: 'armed', 104: 'patients', 346: '$', 191: 'the', 384: 'and', 38: '##cy', 302: 'ser', 115: 'in', 230: '##yl', 353: '@', 146: '##ano', 53: '##aro', 251: ')'}
loss:  18.820165634155273
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 56.41%
Average score: 14.34
{'operating': 'patient', '##ano': '##ano', 'double': '##ized', "'": 'glue', 'hour': 'patient', 'cost': 'packets', '##cut': '##cut', '.': '.', 'su': 'su', '##scopic': '##scopic', '-': 'controlled', 'minutes': 'minutes', '##bon': '-', 'p': 'p', '##s': '##s', '@': '@', '##tures': '##ture', 'with': 'with', 'closed': 'closed', '##ized': '##ized', '##d': '##t', 'accordance': ',', 'all': '@', 'results': 'results', 'closure': 'closure', 'nine': 'five', 'armed': 'clinical', 'patients': 'patients', '$': '$', 'the': 'the', 'and': 'and', '##cy': '##scopic', 'ser': 'aden', 'in': ',', '##yl': '##yl', '##aro': '##aro', ')': ')'}
{'operating': tensor(7.1286), '##ano': tensor(27.6867), 'double': tensor(10.1367), "'": tensor(10.0007), 'hour': tensor(12.2329), 'cost': tensor(13.4088), '##cut': tensor(25.0934), '.': tensor(13.4425), 'su': tensor(22.3410), '##scopic': tensor(26.1038), '-': tensor(8.5492), 'minutes': tensor(12.5027), '##bon': tensor(8.7110), 'p': tensor(13.8612), '##s': tensor(16.7558), '@': tensor(13.7367), '##tures': tensor(23.2636), 'with': tensor(12.9294), 'closed': tensor(11.8362), '##ized': tensor(12.0264), '##d': tensor(9.0079), 'accordance': tensor(8.9846), 'all': tensor(9.5564), 'results': tensor(13.0817), 'closure': tensor(14.3101), 'nine': tensor(12.1773), 'armed': tensor(7.9939), 'patients': tensor(12.7661), '$': tensor(13.3041), 'the': tensor(9.0471), 'and': tensor(11.5281), '##cy': tensor(13.2318), 'ser': tensor(12.5417), 'in': tensor(9.8024), '##yl': tensor(26.5445), '##aro': tensor(26.2360), ')': tensor(18.6479)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '[MASK]', '##ano', '[MASK]', '##ryl', '##ate', '(', 'der', '##ma', '##bon', '##d', ')', 'is', 'a', 'tissue', '`', '`', 'glue', '[MASK]', "'", 'useful', 'in', 'closing', 'surgical', 'skin', 'inc', '##ision', '##s', '.', 'objective', '[MASK]', 'compared', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'with', '[MASK]', '##cut', '##icular', 'skin', 'su', '[MASK]', 'to', 'close', 'lap', '##aro', '##scopic', 'tr', '##oca', '##r', 'sites', '.', 'methods', 'a', '[MASK]', '[MASK]', 'double', '-', 'armed', 'study', 'was', 'performed', 'with', '@', 'patients', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '.', 'methods', 'twenty', '-', 'nine', 'patients', '[MASK]', 'sub', '##cut', '##icular', '[MASK]', 'with', '@', '[MASK]', '@', 'absorb', '##able', '[MASK]', '##ture', ',', 'and', 'thirty', 'patients', 'received', 'closure', 'with', 'oct', '##yl', '##cy', '[MASK]', '##ac', '##ryl', '##ate', 'in', 'accordance', 'with', 'the', 'recommendations', 'of', 'the', 'manufacturer', '(', 'et', '[MASK]', '##on', ';', '[MASK]', ',', 'nj', ')', '.', 'methods', 'the', 'number', 'of', 'su', '##tures', '[MASK]', 'vial', '##s', 'of', 'oct', '[MASK]', '##cy', '[MASK]', '##ac', '##ryl', '##ate', 'used', ',', 'closure', 'times', ',', 'and', 'post', '##oper', '[MASK]', 'wound', 'problems', 'were', 'recorded', '.', '[MASK]', 'wounds', 'were', '[MASK]', '@', 'weeks', 'post', '##oper', '##ative', '##ly', 'for', 'healing', 'complications', '.', 'methods', 'closure', 'costs', 'were', '[MASK]', 'using', '[MASK]', 'operating', 'room', 'time', '[MASK]', 'hour', 'plus', '[MASK]', 'cost', '[MASK]', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '[MASK]', 'methods', 'student', "'", 's', 'paired', 't', '-', 'test', 'was', '[MASK]', 'for', 'statistical', 'analysis', '.', 'results', 'the', 'overall', 'mean', 'time', 'required', 'for', 'skin', 'closure', 'using', 'oct', '##yl', '[MASK]', '##ano', '##ac', '##ryl', '##ate', 'and', 'su', '##ture', 'was', '@', 'minutes', 'and', '@', 'minutes', ',', 'respectively', '(', 'p', '<', '@', ')', '.', 'results', 'an', 'average', '[MASK]', '@', 'packets', 'of', 'su', '##ture', 'were', 'used', 'to', 'close', 'all', 'port', 'sites', 'in', 'a', 'particular', 'patient', ',', 'while', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'required', 'an', 'average', 'of', '@', 'vial', '##s', 'per', 'patient', '.', 'results', '[MASK]', 'complications', '[MASK]', 'of', 'sub', '##cut', '##icular', '[MASK]', '##oma', 'with', '[MASK]', 'separation', 'and', 'were', 'equally', 'common', 'in', 'the', 'two', 'groups', '.', 'results', 'the', 'overall', 'average', 'cost', 'per', 'closure', '[MASK]', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'was', '[MASK]', '@', '[MASK]', 'dollars', ',', 'while', 'the', 'cost', 'for', 'closure', 'using', 'su', '##ture', 'was', '$', '@', 'us', 'dollars', '(', 'p', '<', '@', ')', '.', 'conclusions', 'lap', '##aro', '##scopic', '[MASK]', '-', 'site', 'skin', 'closure', 'with', 'oct', '[MASK]', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', 'and', 'effective', '.', 'conclusions', 'the', 'method', 'yields', 'cost', 'savings', 'and', 'a', 'decrease', 'in', 'operative', 'time', 'of', 'more', 'than', '@', 'minutes', 'per', 'case', '.', '[SEP]']
{323: 'using', 295: 'wound', 128: 'somerville', 256: 'of', 164: 'methods', 139: 'or', 49: '##tures', 33: 'we', 63: '##ized', 191: 'the', 360: 'port', 367: '##yl', 297: 'consisted', 305: 'skin', 182: 'estimated', 204: '.', 158: '##ative', 188: 'per', 21: "'", 302: 'ser', 231: '##cy', 4: '##cy', 146: '##ano', 125: '##hic', 167: 'assessed', 144: '##yl', 99: 'su', 88: 'underwent', 62: 'random', 184: 'published', 111: '##ano', 6: '##ac', 44: 'sub', 334: 'us', 214: 'used', 193: 'of', 92: 'closure', 95: '-', 332: '$'}
loss:  20.02541160583496
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 43.59%
Average score: 14.24
{'using': 'with', 'wound': 'of', 'somerville': 'princeton', 'of': 'of', 'methods': 'the', 'or': 'and', '##tures': '##ture', 'we': 'tests', '##ized': ',', 'the': 'the', 'port': 'on', '##yl': '##yl', 'consisted': 'typical', 'skin': 'no', 'estimated': 'calculated', '.': '.', '##ative': '##ative', 'per': '@', "'": 'glue', 'ser': 'aden', '##cy': '##cy', '##ano': '##ano', '##hic': '##hi', 'assessed': 'closed', 'su': 'su', 'underwent': 'received', 'random': 'single', 'published': 'the', '##ac': '##ac', 'sub': 'sub', 'us': 'us', 'used': 'used', 'closure': 'skin', '-': 'and', '$': '$'}
{'using': tensor(13.2907), 'wound': tensor(9.3495), 'somerville': tensor(12.7756), 'of': tensor(11.7264), 'methods': tensor(8.2748), 'or': tensor(11.0381), '##tures': tensor(22.7904), 'we': tensor(7.6980), '##ized': tensor(8.4366), 'the': tensor(10.9056), 'port': tensor(9.6422), '##yl': tensor(26.7754), 'consisted': tensor(9.2089), 'skin': tensor(8.2199), 'estimated': tensor(13.7517), '.': tensor(12.6816), '##ative': tensor(22.5980), 'per': tensor(10.4224), "'": tensor(9.8774), 'ser': tensor(12.1720), '##cy': tensor(26.0075), '##ano': tensor(27.8214), '##hic': tensor(12.8394), 'assessed': tensor(14.4957), 'su': tensor(22.1708), 'underwent': tensor(16.8059), 'random': tensor(8.4980), 'published': tensor(8.7125), '##ac': tensor(26.3353), 'sub': tensor(19.7419), 'us': tensor(13.7685), 'used': tensor(14.2122), 'closure': tensor(10.7135), '-': tensor(9.0423), '$': tensor(15.5487)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '[MASK]', '##ate', '(', 'der', '##ma', '##bon', '[MASK]', ')', 'is', '[MASK]', 'tissue', '`', '`', 'glue', "'", "'", 'useful', 'in', 'closing', 'surgical', 'skin', 'inc', '##ision', '##s', '.', 'objective', 'we', 'compared', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'with', 'sub', '##cut', '##icular', 'skin', 'su', '##tures', 'to', 'close', 'lap', '##aro', '[MASK]', 'tr', '##oca', '##r', 'sites', '.', 'methods', 'a', 'random', '##ized', 'double', '[MASK]', 'armed', 'study', 'was', 'performed', 'with', '@', 'patients', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '.', 'methods', 'twenty', '-', 'nine', 'patients', 'underwent', 'sub', '[MASK]', '[MASK]', 'closure', 'with', '@', '-', '@', 'absorb', '##able', 'su', '[MASK]', ',', 'and', 'thirty', 'patients', 'received', 'closure', 'with', 'oct', '##yl', '##cy', '[MASK]', '[MASK]', '##ryl', '##ate', 'in', 'accordance', 'with', 'the', 'recommendations', 'of', 'the', 'manufacturer', '(', 'et', '[MASK]', '##on', ';', 'somerville', ',', 'nj', '[MASK]', '.', '[MASK]', 'the', 'number', 'of', 'su', '##tures', '[MASK]', 'vial', '##s', '[MASK]', 'oct', '##yl', '##cy', '##ano', '[MASK]', '##ryl', '##ate', 'used', ',', 'closure', 'times', ',', 'and', 'post', '##oper', '##ative', 'wound', '[MASK]', 'were', 'recorded', '[MASK]', 'methods', 'wounds', 'were', 'assessed', '@', '[MASK]', 'post', '##oper', '##ative', '##ly', 'for', '[MASK]', 'complications', '[MASK]', 'methods', 'closure', '[MASK]', 'were', 'estimated', 'using', 'published', 'operating', 'room', 'time', 'per', 'hour', 'plus', 'the', 'cost', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', 'student', "'", 's', 'paired', 't', '-', '[MASK]', 'was', '[MASK]', 'for', 'statistical', 'analysis', '[MASK]', 'results', '[MASK]', 'overall', '[MASK]', 'time', 'required', 'for', 'skin', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'and', 'su', '##ture', 'was', '@', '[MASK]', 'and', '@', 'minutes', ',', 'respectively', '(', 'p', '<', '@', ')', '.', 'results', 'an', 'average', 'of', '@', 'packets', 'of', 'su', '##ture', 'were', '[MASK]', 'to', 'close', 'all', 'port', 'sites', 'in', 'a', 'particular', 'patient', ',', 'while', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '[MASK]', 'an', 'average', 'of', '@', 'vial', '##s', 'per', '[MASK]', '.', 'results', 'wound', 'complications', 'consisted', 'of', 'sub', '##cut', '##icular', 'ser', '##oma', 'with', 'skin', 'separation', 'and', 'were', 'equally', 'common', 'in', 'the', 'two', 'groups', '.', '[MASK]', 'the', 'overall', 'average', 'cost', 'per', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '[MASK]', '[MASK]', '##ate', '[MASK]', '$', '@', 'us', 'dollars', ',', 'while', 'the', 'cost', 'for', 'closure', 'using', 'su', '##ture', 'was', '$', '[MASK]', 'us', 'dollars', '(', 'p', '<', '@', ')', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', 'and', 'effective', '.', 'conclusions', '[MASK]', 'method', '[MASK]', 'cost', 'savings', 'and', 'a', 'decrease', 'in', 'operative', '[MASK]', 'of', 'more', 'than', '@', 'minutes', 'per', 'case', '.', '[SEP]']
{180: 'costs', 91: '##icular', 177: '.', 147: '##ac', 100: '##ture', 316: 'results', 65: '-', 263: 'used', 7: '##ryl', 241: 'minutes', 220: 'the', 331: 'was', 163: '.', 284: 'required', 381: 'yields', 142: 'of', 379: 'the', 111: '##ano', 214: 'used', 389: 'time', 139: 'or', 169: 'weeks', 133: 'methods', 292: 'patient', 16: 'a', 54: '##scopic', 112: '##ac', 160: 'problems', 218: '.', 131: ')', 175: 'healing', 212: 'test', 222: 'mean', 328: '##ac', 347: '@', 329: '##ryl', 90: '##cut', 125: '##hic', 13: '##d'}
loss:  19.151782989501953
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 56.41%
Average score: 13.70
{'costs': 'times', '##icular': '-', '.': '.', '##ac': '##ac', '##ture': '##tures', 'results': 'results', '-': '-', 'used': 'used', '##ryl': '##ryl', 'minutes': 'hours', 'the': 'and', 'was': 'was', 'required': 'required', 'yields': 'showed', 'of': 'of', '##ano': '##ano', 'time': 'time', 'or': 'and', 'weeks': 'and', 'methods': 'notes', 'patient': 'hour', 'a': 'a', '##scopic': '##scopic', 'problems': 'complications', ')': ')', 'healing': 'wound', 'test': 'cell', 'mean': 'closure', '@': '@', '##cut': '-', '##hic': '##hi', '##d': '##ate'}
{'costs': tensor(16.0927), '##icular': tensor(11.4713), '.': tensor(13.0757), '##ac': tensor(14.7977), '##ture': tensor(23.2157), 'results': tensor(13.4509), '-': tensor(14.3134), 'used': tensor(13.7230), '##ryl': tensor(25.9509), 'minutes': tensor(11.1559), 'the': tensor(7.3254), 'was': tensor(15.9277), 'required': tensor(13.3785), 'yields': tensor(8.6942), 'of': tensor(14.3677), '##ano': tensor(19.9878), 'time': tensor(12.0630), 'or': tensor(10.3689), 'weeks': tensor(9.4732), 'methods': tensor(9.7581), 'patient': tensor(10.9016), 'a': tensor(12.7123), '##scopic': tensor(19.8636), 'problems': tensor(15.0298), ')': tensor(16.7822), 'healing': tensor(13.5116), 'test': tensor(8.1637), 'mean': tensor(9.9031), '@': tensor(14.1753), '##cut': tensor(14.9952), '##hic': tensor(12.3164), '##d': tensor(11.3481)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', 'levels', 'are', 'associated', 'with', 'left', '[MASK]', '##ric', '##ular', 'mass', '[MASK]', 'l', '##v', '##m', ')', 'in', 'insulin', '-', '[MASK]', 'individuals', '[MASK]', 'background', 'anti', '##hy', '##per', '[MASK]', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', 'and', 'insulin', 'metabolism', '[MASK]', '[MASK]', '##m', ')', 'and', 'on', 'l', '##v', '##m', '.', 'background', 'to', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '[MASK]', '##tens', '##ive', '[MASK]', 'on', 'l', '##v', '##m', 'are', 'associated', '[MASK]', 'its', '[MASK]', 'on', 'gi', '##m', ',', 'we', 'compared', 'the', 'effects', 'of', 'ate', '##no', '[MASK]', '[MASK]', 'and', '[MASK]', '##ind', '##op', '##ril', 'on', 'these', 'parameters', '[MASK]', 'a', 'group', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', 'hyper', '##tens', '##ives', '.', 'results', 'a', 'total', 'of', '@', 'obe', '##se', ',', 'non', '##dia', '##bet', '##ic', 'hyper', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '/', '-', '@', 'years', ',', 'had', 'a', 'body', 'mass', 'index', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '@', ')', ',', 'were', 'free', 'of', 'corona', '##ry', 'or', 'val', '[MASK]', '##lar', 'heart', 'disease', ',', 'and', 'had', 'normal', 'l', '##v', 'function', 'were', 'random', '##ized', '[MASK]', 'treatment', 'with', 'ate', '##no', '##lo', '[MASK]', '(', 'n', '=', '[MASK]', ')', 'or', 'per', '##ind', '##op', '##ril', '(', 'n', '=', '@', ')', '.', 'results', 'echo', '##card', '##io', '##graphic', 'l', '##v', '##m', 'corrected', 'for', 'height', '(', 'l', '##v', '##m', '/', 'height', ')', 'and', 'gi', '##m', '(', '@', '-', 'hour', 'intra', '##ven', '##ous', 'glucose', 'tolerance', 'test', ')', 'were', 'measured', 'after', '@', 'to', '@', 'weeks', 'of', 'wash', '[MASK]', 'and', '@', 'months', 'of', 'treatment', '.', 'results', 'baseline', '[MASK]', 'were', 'similar', '[MASK]', 'both', 'groups', '.', 'results', 'ate', '##no', '##lo', '##l', 'and', '[MASK]', '##ind', '##op', '##ril', 'effectively', 'reduced', 'blood', 'pressure', '(', 'from', '@', '+', '/', '-', '[MASK]', '/', '@', '+', '/', '-', '@', 'to', '@', '+', '[MASK]', '-', '@', '/', '@', '+', '/', '[MASK]', '@', 'mm', 'h', '[MASK]', 'and', 'from', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', '[MASK]', '[MASK]', '##g', ',', 'respectively', ',', 'for', 'the', 'ate', '##no', '[MASK]', '##l', 'and', 'per', '##ind', '##op', '##ril', 'groups', ';', 'p', ':', '[MASK]', '[MASK]', ')', '.', 'results', '[MASK]', '##no', '##lo', '##l', 'significantly', 'worsened', 'gi', '##m', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '[MASK]', '-', '@', 'mm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', '[MASK]', 'fast', '##ing', '[MASK]', 'levels', '(', '@', '+', '/', '-', '[MASK]', 'to', '@', '+', '[MASK]', '-', '[MASK]', 'pm', '##ol', '[MASK]', 'l', ';', 'p', ':', '=', '[MASK]', ')', ',', 'and', 'most', 'other', 'relevant', 'metabolic', 'measures', '(', 'p', ':', '<', '@', 'for', 'all', '[MASK]', '.', '[SEP]']
{86: 'per', 177: '##l', 62: 'therapy', 84: '##l', 247: 'in', 339: '=', 288: '-', 383: 'insulin', 83: '##lo', 69: 'with', 29: '##tens', 405: '@', 367: '/', 394: '/', 271: '@', 380: ',', 344: 'ate', 41: 'gi', 10: 'vent', 22: 'resistant', 40: '(', 281: '/', 14: '(', 421: ')', 71: 'effects', 328: '##lo', 93: 'in', 59: '##per', 181: '@', 257: 'per', 396: '@', 24: '.', 171: 'to', 292: '##g', 319: 'h', 235: '##out', 244: 'characteristics', 340: '@', 390: '@', 399: '/', 318: 'mm', 157: '##vu'}
loss:  22.19333839416504
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 80.95%
Average score: 16.61
{'per': 'per', '##l': '##l', 'therapy': 'drugs', 'in': 'of', '=': '=', '-': '/', 'insulin': 'glucose', '##lo': '##lo', 'with': 'with', '##tens': '##tens', '@': '@', '/': '/', ',': ',', 'ate': 'ate', 'gi': 'gi', 'vent': 'vent', 'resistant': 'resistant', '(': '(', ')': ')', 'effects': 'effects', '##per': '##per', '.': '.', 'to': 'for', '##g': '##g', 'h': 'h', '##out': '##out', 'characteristics': '##s', 'mm': 'mm', '##vu': '##vu'}
{'per': tensor(21.9780), '##l': tensor(22.5860), 'therapy': tensor(17.8166), 'in': tensor(11.1299), '=': tensor(14.6816), '-': tensor(12.0260), 'insulin': tensor(14.2417), '##lo': tensor(25.7212), 'with': tensor(15.4044), '##tens': tensor(25.9383), '@': tensor(16.3686), '/': tensor(17.7706), ',': tensor(12.0856), 'ate': tensor(21.3818), 'gi': tensor(14.1389), 'vent': tensor(20.3154), 'resistant': tensor(15.9575), '(': tensor(20.3177), ')': tensor(15.6455), 'effects': tensor(15.9428), '##per': tensor(26.2695), '.': tensor(14.2381), 'to': tensor(12.6418), '##g': tensor(14.2383), 'h': tensor(11.4391), '##out': tensor(12.0424), 'characteristics': tensor(12.0542), 'mm': tensor(9.4906), '##vu': tensor(17.6933)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', 'levels', 'are', 'associated', 'with', 'left', 'vent', '##ric', '##ular', 'mass', '(', 'l', '##v', '##m', ')', 'in', '[MASK]', '-', 'resistant', 'individuals', '.', 'background', 'anti', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', 'and', 'insulin', 'metabolism', '(', 'gi', '##m', ')', 'and', 'on', 'l', '##v', '##m', '.', 'background', 'to', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '##per', '##tens', '##ive', 'therapy', 'on', 'l', '##v', '##m', '[MASK]', '[MASK]', 'with', 'its', 'effects', 'on', '[MASK]', '##m', ',', 'we', 'compared', 'the', 'effects', 'of', 'ate', '##no', '##lo', '##l', 'and', '[MASK]', '##ind', '##op', '##ril', '[MASK]', '[MASK]', 'parameters', 'in', 'a', 'group', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', 'hyper', '##tens', '##ives', '.', 'results', 'a', 'total', 'of', '@', 'obe', '##se', '[MASK]', 'non', '[MASK]', '##bet', '##ic', 'hyper', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '/', '[MASK]', '@', 'years', ',', 'had', 'a', 'body', '[MASK]', 'index', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '@', '[MASK]', ',', '[MASK]', 'free', 'of', 'corona', '##ry', 'or', 'val', '##vu', '##lar', 'heart', 'disease', ',', '[MASK]', '[MASK]', 'normal', 'l', '##v', 'function', 'were', '[MASK]', '[MASK]', 'to', 'treatment', '[MASK]', 'ate', '[MASK]', '##lo', '##l', '(', 'n', '=', '@', ')', 'or', 'per', '[MASK]', '##op', '##ril', '(', 'n', '=', '@', ')', '.', 'results', 'echo', '[MASK]', '##io', '##graphic', 'l', '##v', '##m', 'corrected', '[MASK]', 'height', '(', 'l', '##v', '##m', '/', 'height', ')', 'and', 'gi', '##m', '(', '@', '-', 'hour', '[MASK]', '##ven', '##ous', 'glucose', 'tolerance', 'test', ')', 'were', 'measured', 'after', '@', 'to', '@', 'weeks', 'of', 'wash', '##out', 'and', '[MASK]', '[MASK]', 'of', 'treatment', '.', 'results', 'baseline', 'characteristics', 'were', 'similar', '[MASK]', 'both', 'groups', '.', 'results', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '[MASK]', 'effectively', '[MASK]', 'blood', 'pressure', '[MASK]', 'from', '@', '+', '/', '-', '@', '/', '@', '[MASK]', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '[MASK]', '+', '/', '-', '@', 'mm', 'h', '##g', 'and', 'from', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', '[MASK]', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', ',', 'respectively', ',', 'for', 'the', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '[MASK]', 'groups', ';', 'p', ':', '=', '@', ')', '.', 'results', 'ate', '##no', '##lo', '##l', 'significantly', 'worsened', 'gi', '[MASK]', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '[MASK]', '@', 'to', '@', '+', '/', '-', '@', 'mm', '##ol', '/', '[MASK]', ';', 'p', ':', '[MASK]', '@', ')', ',', 'fast', '##ing', 'insulin', 'levels', '(', '@', '+', '/', '-', '@', 'to', '[MASK]', '+', '/', '-', '@', 'pm', '##ol', '/', 'l', ';', 'p', '[MASK]', '=', '@', ')', ',', 'and', 'most', 'other', '[MASK]', 'metabolic', 'measures', '(', 'p', '[MASK]', '<', '@', 'for', 'all', '[MASK]', '.', '[SEP]']
{148: ')', 262: 'reduced', 68: 'associated', 373: 'l', 173: 'with', 73: 'gi', 421: ')', 91: 'these', 274: '+', 163: 'had', 377: '=', 116: '##dia', 114: ',', 162: 'and', 86: 'per', 170: '##ized', 403: ':', 150: 'were', 135: 'mass', 237: '@', 219: 'intra', 238: 'months', 392: '@', 285: '@', 334: '##ril', 351: '##m', 169: 'random', 411: 'relevant', 260: '##ril', 67: 'are', 90: 'on', 185: '##ind', 416: ':', 196: '##card', 203: 'for', 175: '##no', 362: '-', 20: 'insulin', 128: '-', 265: '(', 247: 'in', 306: 'to'}
loss:  20.02480125427246
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 64.29%
Average score: 14.46
{')': ')', 'reduced': 'reduced', 'associated': 'compared', 'l': 'l', 'with': 'with', 'gi': 'gi', 'these': 'different', '+': '+', 'had': 'a', '=': '=', '##dia': '##dia', ',': 'and', 'and': 'and', 'per': 'per', '##ized': 'compared', ':': ':', 'were': 'were', 'mass': 'weight', '@': '@', 'intra': 'intra', 'months': 'duration', '##ril': '##ril', '##m': '##m', 'random': 'not', 'relevant': 'normal', 'are': 'vary', 'on': 'on', '##ind': '##ind', '##card': '##card', 'for': 'head', '##no': '##no', '-': '-', 'insulin': 'insulin', '(': ',', 'in': 'for', 'to': '+'}
{')': tensor(14.1403), 'reduced': tensor(15.0434), 'associated': tensor(11.1168), 'l': tensor(12.3926), 'with': tensor(11.8837), 'gi': tensor(14.8518), 'these': tensor(7.7931), '+': tensor(13.5509), 'had': tensor(8.0152), '=': tensor(17.3159), '##dia': tensor(19.7107), ',': tensor(11.1139), 'and': tensor(11.8177), 'per': tensor(22.5271), '##ized': tensor(10.8649), ':': tensor(15.8321), 'were': tensor(11.9875), 'mass': tensor(13.8979), '@': tensor(16.4335), 'intra': tensor(19.6281), 'months': tensor(11.0151), '##ril': tensor(26.9907), '##m': tensor(19.1327), 'random': tensor(9.7188), 'relevant': tensor(8.6502), 'are': tensor(9.3399), 'on': tensor(9.4375), '##ind': tensor(24.4729), '##card': tensor(21.8078), 'for': tensor(6.9755), '##no': tensor(29.7287), '-': tensor(12.6901), 'insulin': tensor(16.8416), '(': tensor(9.7517), 'in': tensor(13.4605), 'to': tensor(10.7283)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', 'levels', 'are', '[MASK]', 'with', 'left', 'vent', '##ric', '##ular', '[MASK]', '(', 'l', '##v', '##m', '[MASK]', 'in', 'insulin', '-', 'resistant', '[MASK]', '.', 'background', '[MASK]', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', 'and', 'insulin', 'metabolism', '(', 'gi', '[MASK]', ')', 'and', 'on', 'l', '##v', '##m', '.', 'background', 'to', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '##per', '##tens', '##ive', 'therapy', 'on', 'l', '##v', '[MASK]', 'are', 'associated', 'with', 'its', 'effects', 'on', 'gi', '##m', ',', '[MASK]', 'compared', 'the', 'effects', 'of', 'ate', '##no', '##lo', '##l', 'and', '[MASK]', '##ind', '##op', '##ril', 'on', '[MASK]', 'parameters', 'in', 'a', '[MASK]', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', '[MASK]', '##tens', '##ives', '.', 'results', 'a', 'total', 'of', '[MASK]', 'obe', '##se', ',', 'non', '##dia', '##bet', '##ic', 'hyper', '[MASK]', '##ives', 'who', 'were', 'aged', '@', '+', '/', '-', '@', 'years', ',', 'had', 'a', 'body', 'mass', 'index', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '@', ')', ',', 'were', 'free', 'of', 'corona', '##ry', 'or', 'val', '##vu', '##lar', 'heart', 'disease', '[MASK]', 'and', '[MASK]', 'normal', 'l', '##v', 'function', 'were', 'random', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '##l', '(', 'n', '=', '[MASK]', ')', 'or', '[MASK]', '[MASK]', '##op', '##ril', '(', 'n', '=', '@', ')', '.', 'results', 'echo', '##card', '##io', '##graphic', '[MASK]', '##v', '##m', '[MASK]', 'for', '[MASK]', '(', 'l', '##v', '##m', '/', 'height', ')', 'and', 'gi', '[MASK]', '(', '@', '-', 'hour', 'intra', '##ven', '##ous', 'glucose', 'tolerance', 'test', ')', 'were', 'measured', 'after', '@', 'to', '[MASK]', 'weeks', '[MASK]', 'wash', '##out', 'and', '@', 'months', 'of', 'treatment', '.', 'results', 'baseline', '[MASK]', 'were', 'similar', 'in', 'both', 'groups', '.', '[MASK]', 'ate', '##no', '##lo', '##l', '[MASK]', '[MASK]', '##ind', '##op', '[MASK]', 'effectively', 'reduced', 'blood', 'pressure', '(', 'from', '@', '+', '/', '-', '@', '/', '@', '+', '[MASK]', '-', '@', '[MASK]', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', 'and', 'from', '[MASK]', '+', '[MASK]', '-', '@', '/', '@', '+', '/', '[MASK]', '@', 'to', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '[MASK]', 'mm', 'h', '##g', ',', 'respectively', ',', 'for', 'the', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'groups', ';', 'p', ':', '=', '@', ')', '.', 'results', 'ate', '##no', '##lo', '##l', 'significantly', 'worsened', 'gi', '[MASK]', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', 'mm', '##ol', '/', 'l', ';', 'p', ':', '[MASK]', '@', ')', ',', 'fast', '##ing', 'insulin', 'levels', '(', '@', '+', '/', '-', '[MASK]', 'to', '[MASK]', '+', '/', '-', '@', 'pm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', '[MASK]', 'and', '[MASK]', 'other', 'relevant', 'metabolic', 'measures', '(', 'p', ':', '<', '@', 'for', 'all', ')', '.', '[SEP]']
{244: 'characteristics', 18: ')', 409: 'most', 275: '/', 297: '/', 184: 'per', 181: '@', 26: 'anti', 204: 'height', 42: '##m', 377: '=', 231: '@', 163: 'had', 23: 'individuals', 295: '@', 86: 'per', 233: 'of', 251: 'results', 256: 'and', 103: 'hyper', 185: '##ind', 111: '@', 278: 'to', 202: 'corrected', 392: '@', 407: ',', 260: '##ril', 214: '##m', 91: 'these', 13: 'mass', 7: 'associated', 95: 'group', 76: 'we', 120: '##tens', 317: '@', 199: 'l', 66: '##m', 351: '##m', 304: '-', 257: 'per', 161: ',', 390: '@'}
loss:  20.35481834411621
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 71.43%
Average score: 14.93
{'characteristics': 'results', ')': ')', 'most': 'performed', '/': '/', 'per': 'per', '@': '@', 'anti': 'anti', 'height': 'height', '##m': '##m', '=': '=', 'had': 'had', 'individuals': 'patients', 'of': 'of', 'results': 'both', 'and': 'and', 'hyper': 'hyper', '##ind': '##ind', 'to': '/', 'corrected': 'tests', ',': ',', '##ril': '##ril', 'these': 'glucose', 'mass': 'pressure', 'associated': 'associated', 'group': 'group', 'we': 'researchers', '##tens': '##tens', 'l': 'l', '-': '@'}
{'characteristics': tensor(11.9889), ')': tensor(19.7616), 'most': tensor(9.1642), '/': tensor(15.6553), 'per': tensor(19.9375), '@': tensor(16.0207), 'anti': tensor(22.5084), 'height': tensor(7.5132), '##m': tensor(19.0262), '=': tensor(15.9770), 'had': tensor(10.8916), 'individuals': tensor(13.3019), 'of': tensor(12.5027), 'results': tensor(9.7841), 'and': tensor(12.5495), 'hyper': tensor(23.9057), '##ind': tensor(18.4325), 'to': tensor(12.5630), 'corrected': tensor(10.9732), ',': tensor(15.5964), '##ril': tensor(25.1354), 'these': tensor(9.6232), 'mass': tensor(11.6636), 'associated': tensor(13.8834), 'group': tensor(13.1974), 'we': tensor(8.9148), '##tens': tensor(23.3743), 'l': tensor(15.5727), '-': tensor(13.5328)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', '[MASK]', 'insulin', '[MASK]', 'are', 'associated', 'with', 'left', 'vent', '##ric', '##ular', 'mass', '(', 'l', '##v', '##m', ')', 'in', 'insulin', '-', 'resistant', 'individuals', '.', '[MASK]', 'anti', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', 'and', 'insulin', 'metabolism', '(', '[MASK]', '##m', ')', 'and', 'on', 'l', '[MASK]', '##m', '.', 'background', 'to', 'evaluate', 'whether', '[MASK]', 'effects', 'of', 'anti', '##hy', '##per', '[MASK]', '##ive', '[MASK]', 'on', 'l', '##v', '##m', 'are', 'associated', 'with', 'its', 'effects', 'on', 'gi', '##m', '[MASK]', 'we', 'compared', 'the', 'effects', 'of', 'ate', '##no', '##lo', '##l', 'and', '[MASK]', '##ind', '##op', '##ril', 'on', '[MASK]', '[MASK]', 'in', 'a', 'group', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', 'hyper', '##tens', '##ives', '.', 'results', 'a', 'total', 'of', '@', 'obe', '##se', '[MASK]', 'non', '##dia', '##bet', '##ic', '[MASK]', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '/', '-', '@', 'years', ',', 'had', 'a', 'body', 'mass', 'index', 'of', '@', '+', '/', '-', '[MASK]', 'kg', '/', 'm', '(', '@', ')', ',', 'were', 'free', '[MASK]', '[MASK]', '##ry', 'or', 'val', '##vu', '[MASK]', 'heart', 'disease', ',', 'and', 'had', 'normal', 'l', '##v', 'function', '[MASK]', 'random', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '##l', '(', 'n', '=', '@', ')', 'or', 'per', '##ind', '[MASK]', '##ril', '[MASK]', '[MASK]', '=', '@', ')', '.', 'results', '[MASK]', '##card', '##io', '##graphic', 'l', '##v', '##m', 'corrected', 'for', 'height', '(', 'l', '##v', '##m', '/', 'height', ')', 'and', 'gi', '##m', '(', '@', '-', 'hour', 'intra', '##ven', '##ous', 'glucose', 'tolerance', 'test', ')', 'were', 'measured', 'after', '@', 'to', '[MASK]', 'weeks', '[MASK]', 'wash', '##out', 'and', '@', 'months', '[MASK]', 'treatment', '.', 'results', 'baseline', 'characteristics', 'were', 'similar', 'in', 'both', 'groups', '.', 'results', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '[MASK]', 'effectively', 'reduced', 'blood', 'pressure', '(', 'from', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '[MASK]', '+', '/', '-', '@', 'mm', 'h', '##g', 'and', 'from', '[MASK]', '[MASK]', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '[MASK]', ',', 'respectively', ',', 'for', 'the', 'ate', '##no', '##lo', '##l', '[MASK]', 'per', '##ind', '##op', '##ril', '[MASK]', ';', 'p', ':', '=', '@', ')', '.', 'results', 'ate', '##no', '##lo', '##l', 'significantly', 'worsened', 'gi', '##m', 'parameters', '[MASK]', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', 'mm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', ',', 'fast', '##ing', 'insulin', 'levels', '(', '@', '+', '[MASK]', '-', '[MASK]', '[MASK]', '[MASK]', '+', '/', '-', '[MASK]', 'pm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', ',', '[MASK]', 'most', 'other', '[MASK]', 'metabolic', 'measures', '(', 'p', ':', '[MASK]', '@', 'for', 'all', ')', '.', '[SEP]']
{168: 'were', 25: 'background', 75: ',', 186: '##op', 114: ',', 153: 'corona', 408: 'and', 3: 'and', 388: '/', 330: 'and', 239: 'of', 260: '##ril', 91: 'these', 54: 'the', 158: '##lar', 92: 'parameters', 233: 'of', 142: '@', 417: '<', 188: '(', 390: '@', 47: '##v', 119: 'hyper', 231: '@', 189: 'n', 320: '##g', 295: '@', 152: 'of', 62: 'therapy', 285: '@', 391: 'to', 41: 'gi', 60: '##tens', 411: 'relevant', 353: ',', 396: '@', 296: '+', 5: 'levels', 195: 'echo', 335: 'groups', 392: '@', 86: 'per'}
loss:  20.68082618713379
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 66.67%
Average score: 15.86
{'were': 'when', 'background': 'different', ',': 'for', '##op': '##op', 'corona': 'corona', 'and': 'and', '/': '/', 'of': 'of', '##ril': '##ril', 'these': 'insulin', 'the': 'the', '##lar': '##lar', 'parameters': 'metabolism', '@': '@', '<': '=', '(': '(', '##v': '##v', 'hyper': 'hyper', 'n': 'n', '##g': '##g', 'therapy': 'drugs', 'to': '@', 'gi': 'gi', '##tens': '##tens', 'relevant': 'normal', '+': '@', 'levels': 'levels', 'echo': 'electro', 'groups': 'groups', 'per': 'per'}
{'were': tensor(11.4045), 'background': tensor(11.3970), ',': tensor(9.4197), '##op': tensor(26.9600), 'corona': tensor(18.7614), 'and': tensor(14.1778), '/': tensor(14.8111), 'of': tensor(11.9302), '##ril': tensor(27.9245), 'these': tensor(11.7347), 'the': tensor(13.7953), '##lar': tensor(15.3917), 'parameters': tensor(11.7555), '@': tensor(14.8523), '<': tensor(15.2763), '(': tensor(18.3474), '##v': tensor(23.1428), 'hyper': tensor(22.9645), 'n': tensor(10.2958), '##g': tensor(18.1855), 'therapy': tensor(16.6100), 'to': tensor(14.4390), 'gi': tensor(14.9596), '##tens': tensor(27.4899), 'relevant': tensor(8.3747), '+': tensor(16.7726), 'levels': tensor(12.7668), 'echo': tensor(12.5610), 'groups': tensor(9.3055), 'per': tensor(19.9765)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', 'levels', 'are', 'associated', 'with', 'left', 'vent', '##ric', '##ular', 'mass', '(', 'l', '##v', '##m', ')', 'in', 'insulin', '-', 'resistant', '[MASK]', '.', 'background', 'anti', '##hy', '[MASK]', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', 'and', 'insulin', 'metabolism', '(', 'gi', '##m', ')', 'and', 'on', 'l', '##v', '##m', '.', 'background', 'to', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '##per', '##tens', '##ive', 'therapy', 'on', 'l', '##v', '##m', '[MASK]', 'associated', 'with', 'its', 'effects', 'on', 'gi', '##m', ',', 'we', 'compared', '[MASK]', '[MASK]', '[MASK]', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'on', 'these', 'parameters', 'in', 'a', '[MASK]', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', 'hyper', '##tens', '##ives', '.', 'results', 'a', 'total', 'of', '@', '[MASK]', '##se', ',', '[MASK]', '##dia', '##bet', '##ic', 'hyper', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '/', '-', '@', 'years', ',', 'had', 'a', 'body', 'mass', '[MASK]', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '@', ')', ',', 'were', 'free', 'of', 'corona', '##ry', '[MASK]', 'val', '##vu', '##lar', 'heart', 'disease', ',', 'and', '[MASK]', '[MASK]', 'l', '##v', 'function', 'were', '[MASK]', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '##l', '(', 'n', '=', '[MASK]', ')', 'or', 'per', '##ind', '##op', '##ril', '(', 'n', '=', '[MASK]', ')', '.', 'results', 'echo', '##card', '##io', '##graphic', 'l', '##v', '##m', '[MASK]', 'for', 'height', '(', 'l', '##v', '##m', '[MASK]', '[MASK]', ')', 'and', 'gi', '##m', '(', '@', '-', 'hour', 'intra', '##ven', '##ous', '[MASK]', 'tolerance', 'test', ')', 'were', '[MASK]', 'after', '@', 'to', '@', 'weeks', 'of', 'wash', '##out', 'and', '@', 'months', 'of', 'treatment', '.', 'results', '[MASK]', 'characteristics', 'were', 'similar', 'in', 'both', 'groups', '.', 'results', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'effectively', 'reduced', '[MASK]', 'pressure', '(', 'from', '@', '+', '/', '-', '[MASK]', '[MASK]', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', 'and', 'from', '@', '+', '/', '[MASK]', '@', '[MASK]', '@', '+', '/', '-', '@', '[MASK]', '@', '+', '/', '-', '@', '[MASK]', '[MASK]', '+', '/', '-', '[MASK]', 'mm', 'h', '##g', ',', 'respectively', ',', 'for', 'the', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '[MASK]', '[MASK]', ';', 'p', '[MASK]', '=', '@', ')', '.', 'results', 'ate', '##no', '##lo', '##l', 'significantly', '[MASK]', 'gi', '##m', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '[MASK]', '/', '-', '[MASK]', 'to', '@', '+', '/', '-', '@', 'mm', '##ol', '/', '[MASK]', ';', 'p', ':', '=', '@', ')', ',', 'fast', '##ing', 'insulin', 'levels', '(', '@', '+', '/', '-', '@', 'to', '[MASK]', '+', '/', '-', '@', '[MASK]', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', ',', 'and', 'most', 'other', '[MASK]', 'metabolic', 'measures', '(', 'p', ':', '[MASK]', '@', 'for', 'all', ')', '.', '[SEP]']
{243: 'baseline', 112: 'obe', 164: 'normal', 80: 'of', 209: '/', 312: '/', 373: 'l', 349: 'worsened', 272: '/', 271: '@', 417: '<', 191: '@', 95: 'group', 222: 'glucose', 335: 'groups', 23: 'individuals', 411: 'relevant', 300: '/', 397: 'pm', 227: 'measured', 363: '@', 79: 'effects', 210: 'height', 360: '+', 306: 'to', 155: 'or', 313: '@', 78: 'the', 202: 'corrected', 392: '@', 338: ':', 67: 'are', 169: 'random', 317: '@', 28: '##per', 181: '@', 136: 'index', 298: '-', 163: 'had', 115: 'non', 263: 'blood', 334: '##ril'}
loss:  19.267072677612305
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 61.90%
Average score: 13.61
{'baseline': 'and', 'obe': 'obe', 'normal': 'of', 'of': 'of', '/': 'to', 'l': 'l', 'worsened': 'reduced', '@': '@', '<': '=', 'group': 'group', 'glucose': 'glucose', 'groups': '##ril', 'individuals': 'individuals', 'relevant': 'basic', 'pm': 'mm', 'measured': 'compared', 'effects': 'values', 'height': '@', '+': '+', 'to': 'to', 'or': 'and', 'the': 'the', 'corrected': 'tests', ':': ':', 'are': 'are', 'random': 'random', '##per': '##per', 'index': 'index', '-': '-', 'had': 'had', 'non': 'non', 'blood': 'blood', '##ril': '##ril'}
{'baseline': tensor(11.4378), 'obe': tensor(18.8989), 'normal': tensor(7.8184), 'of': tensor(13.1850), '/': tensor(11.0498), 'l': tensor(11.1866), 'worsened': tensor(15.9573), '@': tensor(15.1742), '<': tensor(12.5210), 'group': tensor(12.8116), 'glucose': tensor(11.8989), 'groups': tensor(21.8551), 'individuals': tensor(13.9280), 'relevant': tensor(8.6558), 'pm': tensor(16.3638), 'measured': tensor(10.3720), 'effects': tensor(10.4321), 'height': tensor(6.7807), '+': tensor(15.8864), 'to': tensor(10.0496), 'or': tensor(13.0961), 'the': tensor(10.8780), 'corrected': tensor(12.3916), ':': tensor(16.9584), 'are': tensor(15.4283), 'random': tensor(12.8090), '##per': tensor(26.4062), 'index': tensor(11.5580), '-': tensor(11.6029), 'had': tensor(9.6762), 'non': tensor(12.5725), 'blood': tensor(13.7346), '##ril': tensor(25.6398)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', 'of', 'the', 'study', 'was', 'to', 'assess', 'semantic', 'pri', '##ming', 'to', 'emotion', 'and', '[MASK]', '##mot', '##ion', 'cue', 'words', 'using', 'a', 'novel', 'measure', 'of', 'association', '##al', 'breadth', 'for', 'participants', 'who', '[MASK]', 'took', 'rapid', 'eye', 'movement', '(', 're', '##m', ')', 'or', 'non', '##ra', '##pid', 'eye', 'movement', '(', 'nr', '##em', ')', 'nap', '##s', 'or', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', '[MASK]', '##ming', '[MASK]', 're', '##m', 'sleep', 'consolidation', 'and', 're', '##m', 'sleep', 'in', '##ert', '##ia', 'effects', '.', '[MASK]', 'the', 'association', '##al', 'breadth', '[MASK]', 'was', 'applied', '[MASK]', 'both', '[MASK]', 'pri', '##ming', '[MASK]', ',', 'where', 'cue', '-', 'words', 'were', 'signaled', 'to', 'be', 'memo', '##rized', 'prior', 'to', 'sleep', '(', 'prime', '##d', ')', '[MASK]', 'and', 'a', 'non', '[MASK]', '##imi', '##ng', 'condition', '[MASK]', 'where', 'cue', 'words', '[MASK]', 'not', 'memo', '[MASK]', '(', 'non', '##pr', '##ime', '##d', ')', '.', 'methods', 'cue', 'words', 'were', 'either', 'emotional', '[MASK]', 'positive', ',', 'negative', ')', 'or', 'none', '##mot', '##ional', '.', '[MASK]', 'participants', 'were', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', 'a', 'sleep', '[MASK]', ',', 'which', 'was', 'subsequently', 'split', 'into', 'nr', '##em', 'or', 're', '##m', 'groups', 'depending', 'on', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', '[MASK]', 'sleep', 'laboratory', '.', '[MASK]', 'fifty', '-', 'eight', 'healthy', 'participants', '(', '@', 'male', ')', 'ages', '@', 'to', '[MASK]', 'y', '(', 'mage', '=', '@', '@', 'y', ')', '.', 'results', 'the', '[MASK]', '##m', 'group', 'scored', 'higher', 'than', 'the', 'nr', '##em', 'or', 'wake', 'groups', 'on', 'prime', '##d', '[MASK]', 'but', 'not', 'non', '##pr', '##ime', '##d', '[MASK]', 'cue', 'words', ';', '[MASK]', 'effect', '[MASK]', '[MASK]', 'for', 'positive', 'than', 'for', 'negative', 'cue', 'words', '.', 'results', 'however', ',', 're', '##m', 'time', 'and', 'percent', '[MASK]', 'negatively', 'with', 'degree', 'of', 'emotional', 'pri', '##ming', '.', 'results', 'pri', '##ming', 'occurred', 'for', 're', '##m', 'awakening', '##s', 'but', 'not', 'for', 'nr', '##em', '[MASK]', '##s', ',', '[MASK]', 'when', '[MASK]', 'latter', '[MASK]', 'episodes', 'contained', 'some', 're', '##m', 'sleep', '.', 'conclusions', 'association', '##al', 'breadth', 'may', 'be', 'selective', '##ly', 'consolidated', 'during', '[MASK]', '##m', 'sleep', '[MASK]', 'stimuli', 'that', 'have', 'been', 'tagged', 'as', 'important', 'for', '[MASK]', 'memory', 'retrieval', '.', '[MASK]', 'that', 'pri', '##ming', 'decreased', 'with', 're', '##m', 'time', 'and', 'was', 'higher', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', 'two', 'ex', '##pl', '##ana', '##tory', 're', '##m', 'sleep', 'processes', ':', '[MASK]', '##m', 'sleep', 'consolidation', 'serving', 'emotional', 'down', '[MASK]', '##gul', '##ation', 'and', 're', '##m', 'sleep', 'in', '##ert', '##ia', '.', '[SEP]']
{148: 'methods', 109: ',', 236: 'emotional', 286: 'even', 16: 'none', 63: 'to', 356: 're', 124: '##rized', 113: '##pr', 87: 'a', 121: 'were', 242: 'was', 202: '@', 308: 're', 229: ',', 363: '##re', 163: 'condition', 85: 'in', 243: 'stronger', 82: 'task', 90: 'condition', 288: 'the', 61: 'pri', 324: 'conclusions', 189: 'methods', 32: 'either', 311: 'for', 185: 'based', 240: 'the', 283: 'awakening', 77: 'methods', 290: 'sleep', 320: 'future', 117: ',', 260: 'correlated', 214: 're', 138: '('}
loss:  19.07345199584961
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 62.16%
Average score: 14.13
{'methods': 'results', ',': ',', 'emotional': ')', 'even': 'even', 'none': 'loco', 'to': 'to', 're': 're', '##rized': '##rized', '##pr': '##pr', 'a': 'a', 'were': 'were', 'was': 'was', '@': '@', '##re': '##re', 'condition': 'condition', 'in': 'to', 'stronger': 'higher', 'task': 'test', 'the': 'the', 'pri': 'pri', 'conclusions': 'evidence', 'either': 'either', 'for': 'with', 'based': 'based', 'awakening': 'awakening', 'sleep': 'two', 'future': 'the', 'correlated': 'correlated', '(': '('}
{'methods': tensor(12.8189), ',': tensor(15.4347), 'emotional': tensor(14.6862), 'even': tensor(11.6717), 'none': tensor(11.7993), 'to': tensor(12.2780), 're': tensor(14.3892), '##rized': tensor(24.7641), '##pr': tensor(21.8523), 'a': tensor(10.4745), 'were': tensor(17.3334), 'was': tensor(10.4681), '@': tensor(12.5394), '##re': tensor(19.6389), 'condition': tensor(15.5965), 'in': tensor(13.7717), 'stronger': tensor(12.0247), 'task': tensor(11.2785), 'the': tensor(9.3409), 'pri': tensor(20.9169), 'conclusions': tensor(12.9594), 'either': tensor(13.4221), 'for': tensor(10.8720), 'based': tensor(9.3764), 'awakening': tensor(17.3024), 'sleep': tensor(12.6089), 'future': tensor(8.1970), 'correlated': tensor(13.4485), '(': tensor(18.6229)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', '[MASK]', 'goal', 'of', 'the', 'study', 'was', '[MASK]', 'assess', 'semantic', 'pri', '##ming', 'to', 'emotion', 'and', 'none', '[MASK]', '##ion', '[MASK]', 'words', 'using', 'a', 'novel', 'measure', 'of', 'association', '##al', 'breadth', 'for', 'participants', 'who', '[MASK]', 'took', 'rapid', 'eye', '[MASK]', '(', '[MASK]', '##m', ')', 'or', 'non', '[MASK]', '##pid', 'eye', 'movement', '(', 'nr', '##em', ')', 'nap', '[MASK]', 'or', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', 'pri', '##ming', 'to', 're', '##m', 'sleep', 'consolidation', 'and', '[MASK]', '##m', 'sleep', 'in', '##ert', '##ia', 'effects', '.', 'methods', '[MASK]', 'association', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', 'pri', '##ming', 'condition', ',', 'where', 'cue', '[MASK]', 'words', 'were', 'signaled', 'to', 'be', 'memo', '##rized', 'prior', 'to', '[MASK]', '(', 'prime', '##d', ')', ',', 'and', 'a', 'non', '##pr', '[MASK]', '##ng', 'condition', ',', 'where', 'cue', 'words', 'were', 'not', 'memo', '##rized', '(', '[MASK]', '##pr', '##ime', '##d', ')', '.', 'methods', 'cue', 'words', 'were', 'either', 'emotional', '(', 'positive', ',', 'negative', ')', 'or', 'none', '##mot', '##ional', '.', 'methods', 'participants', '[MASK]', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', 'a', 'sleep', 'condition', ',', 'which', 'was', 'subsequently', 'split', '[MASK]', 'nr', '##em', 'or', 're', '##m', 'groups', 'depending', 'on', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', 'based', 'sleep', 'laboratory', '.', 'methods', 'fifty', '-', 'eight', 'healthy', '[MASK]', '(', '@', 'male', ')', 'ages', '@', 'to', '@', 'y', '(', '[MASK]', '=', '@', '@', 'y', ')', '.', '[MASK]', '[MASK]', 're', '##m', 'group', 'scored', 'higher', 'than', 'the', 'nr', '##em', '[MASK]', 'wake', 'groups', 'on', 'prime', '##d', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', 'effect', 'was', 'stronger', 'for', 'positive', 'than', 'for', 'negative', 'cue', 'words', '.', 'results', 'however', ',', '[MASK]', '##m', 'time', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', 'of', '[MASK]', 'pri', '##ming', '.', 'results', 'pri', '##ming', 'occurred', '[MASK]', 're', '##m', 'awakening', '##s', 'but', 'not', 'for', 'nr', '##em', 'awakening', '##s', ',', 'even', 'when', 'the', 'latter', 'sleep', '[MASK]', 'contained', 'some', 're', '##m', 'sleep', '.', 'conclusions', 'association', '##al', 'breadth', 'may', 'be', 'selective', '##ly', 'consolidated', 'during', 're', '##m', 'sleep', 'for', 'stimuli', 'that', '[MASK]', 'been', 'tagged', '[MASK]', 'important', 'for', 'future', '[MASK]', 'retrieval', '.', 'conclusions', '[MASK]', 'pri', '##ming', 'decreased', 'with', 're', '[MASK]', 'time', 'and', 'was', 'higher', 'only', 'for', 're', '[MASK]', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', 'two', 'ex', '##pl', '##ana', '##tory', 're', '##m', 'sleep', 'processes', ':', '[MASK]', '##m', 'sleep', 'consolidation', '[MASK]', 'emotional', 'down', '##re', '##gul', '##ation', 'and', '[MASK]', '##m', '[MASK]', 'in', '[MASK]', '##ia', '.', '[SEP]']
{369: 'sleep', 317: 'as', 223: 'or', 32: 'either', 2: 'the', 321: 'memory', 331: '##m', 8: 'to', 255: 're', 150: 'were', 169: 'into', 43: '##ra', 52: '##s', 367: 're', 205: 'mage', 114: '##imi', 38: 're', 194: 'participants', 104: 'sleep', 265: 'emotional', 78: 'the', 19: 'cue', 360: 'serving', 371: '##ert', 291: 'episodes', 94: '-', 36: 'movement', 339: '##m', 213: 'the', 314: 'have', 273: 'for', 126: 'non', 356: 're', 69: 're', 17: '##mot', 325: 'that', 212: 'results'}
loss:  19.972280502319336
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 67.57%
Average score: 14.44
{'sleep': 'awakening', 'as': 'as', 'or': 'and', 'either': 'either', 'the': 'the', 'memory': 'memory', '##m': '##m', 'to': 'to', 're': 're', 'were': 'were', 'into': 'into', '##ra': '##cus', '##s': '##s', 'mage': 'age', '##imi': '##ime', 'participants': 'individuals', 'emotional': 'semantic', 'cue': 'cue', 'serving': ',', '##ert': '##ert', 'episodes': 'condition', '-': 'cue', 'movement': 'movement', 'have': 'have', 'for': 'for', 'non': 'non', '##mot': '##mot', 'that': 'that', 'results': 'the'}
{'sleep': tensor(15.1680), 'as': tensor(13.7510), 'or': tensor(10.2503), 'either': tensor(13.7300), 'the': tensor(9.1974), 'memory': tensor(12.1020), '##m': tensor(21.7320), 'to': tensor(14.3094), 're': tensor(18.2004), 'were': tensor(15.9038), 'into': tensor(14.0541), '##ra': tensor(15.6553), '##s': tensor(10.9710), 'mage': tensor(7.5561), '##imi': tensor(22.3593), 'participants': tensor(10.0354), 'emotional': tensor(13.4271), 'cue': tensor(13.3181), 'serving': tensor(11.0025), '##ert': tensor(24.2680), 'episodes': tensor(11.2347), '-': tensor(12.0323), 'movement': tensor(18.6557), 'have': tensor(14.7533), 'for': tensor(12.7049), 'non': tensor(16.0839), '##mot': tensor(24.7498), 'that': tensor(10.6528), 'results': tensor(10.9326)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', 'of', 'the', 'study', 'was', '[MASK]', 'assess', 'semantic', 'pri', '##ming', 'to', 'emotion', 'and', 'none', '##mot', '##ion', 'cue', 'words', 'using', 'a', 'novel', 'measure', 'of', 'association', '##al', 'breadth', 'for', 'participants', 'who', 'either', 'took', 'rapid', 'eye', 'movement', '(', 're', '##m', '[MASK]', 'or', 'non', '##ra', '##pid', '[MASK]', '[MASK]', '(', 'nr', '[MASK]', ')', 'nap', '##s', 'or', 'who', 'remained', '[MASK]', ';', 'assess', 'relation', 'of', 'pri', '##ming', 'to', 're', '##m', 'sleep', 'consolidation', 'and', 're', '[MASK]', 'sleep', 'in', '##ert', '##ia', 'effects', '.', 'methods', 'the', 'association', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', 'pri', '##ming', 'condition', ',', '[MASK]', '[MASK]', '[MASK]', 'words', 'were', 'signaled', 'to', 'be', 'memo', '##rized', 'prior', 'to', 'sleep', '(', 'prime', '##d', ')', ',', '[MASK]', 'a', 'non', '##pr', '##imi', '[MASK]', 'condition', ',', 'where', 'cue', 'words', 'were', 'not', 'memo', '##rized', '(', 'non', '##pr', '##ime', '##d', ')', '.', 'methods', '[MASK]', 'words', 'were', 'either', 'emotional', '(', 'positive', '[MASK]', 'negative', ')', 'or', 'none', '##mot', '##ional', '.', 'methods', 'participants', 'were', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', 'a', 'sleep', 'condition', '[MASK]', '[MASK]', 'was', '[MASK]', 'split', '[MASK]', 'nr', '##em', 'or', 're', '[MASK]', 'groups', '[MASK]', 'on', 'stage', 'at', 'awakening', '.', '[MASK]', 'hospital', '-', '[MASK]', '[MASK]', 'laboratory', '.', 'methods', 'fifty', '-', 'eight', '[MASK]', 'participants', '(', '@', 'male', ')', 'ages', '@', 'to', '[MASK]', 'y', '(', 'mage', '=', '@', '@', 'y', ')', '.', 'results', 'the', 're', '##m', 'group', 'scored', 'higher', 'than', 'the', '[MASK]', '##em', 'or', 'wake', 'groups', 'on', 'prime', '##d', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', 'effect', 'was', 'stronger', 'for', 'positive', 'than', 'for', 'negative', 'cue', 'words', '.', '[MASK]', 'however', '[MASK]', 're', '##m', '[MASK]', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', 'of', 'emotional', 'pri', '##ming', '.', '[MASK]', 'pri', '##ming', 'occurred', 'for', 're', '##m', 'awakening', '##s', 'but', 'not', 'for', 'nr', '##em', 'awakening', '##s', ',', 'even', 'when', 'the', 'latter', 'sleep', 'episodes', 'contained', 'some', 're', '##m', 'sleep', '.', 'conclusions', 'association', '##al', 'breadth', 'may', 'be', 'selective', '##ly', 'consolidated', 'during', 're', '##m', 'sleep', 'for', 'stimuli', 'that', 'have', 'been', 'tagged', '[MASK]', 'important', 'for', 'future', 'memory', 'retrieval', '.', '[MASK]', 'that', 'pri', '##ming', '[MASK]', 'with', 're', '##m', 'time', '[MASK]', 'was', 'higher', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', 'two', 'ex', '##pl', '##ana', '##tory', 're', '##m', 'sleep', 'processes', ':', 're', '##m', 'sleep', '[MASK]', 'serving', 'emotional', 'down', '##re', '##gul', '##ation', 'and', 're', '##m', 'sleep', 'in', '[MASK]', '##ia', '[MASK]', '[SEP]']
{70: '##m', 221: 'nr', 257: 'time', 186: 'sleep', 164: ',', 133: 'cue', 185: 'based', 94: '-', 169: 'into', 324: 'conclusions', 49: '##em', 254: ',', 202: '@', 371: '##ert', 359: 'consolidation', 40: ')', 92: 'where', 93: 'cue', 115: '##ng', 8: 'to', 182: 'methods', 174: '##m', 176: 'depending', 269: 'results', 328: 'decreased', 165: 'which', 373: '.', 140: ',', 317: 'as', 45: 'eye', 252: 'results', 167: 'subsequently', 333: 'and', 56: 'awake', 46: 'movement', 193: 'healthy', 110: 'and'}
loss:  18.933462142944336
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 54.05%
Average score: 13.27
{'##m': '##m', 'nr': 'nr', 'time': 'scores', 'sleep': 'based', ',': 'or', 'cue': 'where', 'based': 'based', '-': 'cue', 'into': 'into', 'conclusions': 'evidence', '##em': '##em', '@': '@', '##ert': '##ert', 'consolidation': ',', ')': ')', 'where': 'where', '##ng': '##nal', 'to': 'to', 'methods': 'a', 'depending': 'and', 'results': 'results', 'decreased': 'associated', 'which': 'which', '.': '.', 'as': 'as', 'eye': '##al', 'subsequently': 'randomly', 'and': 'and', 'awake': 'awake', 'movement': 'movement', 'healthy': '%'}
{'##m': tensor(23.0428), 'nr': tensor(20.5677), 'time': tensor(6.9942), 'sleep': tensor(8.5690), ',': tensor(13.0854), 'cue': tensor(17.5498), 'based': tensor(9.2091), '-': tensor(16.3125), 'into': tensor(12.9602), 'conclusions': tensor(11.8021), '##em': tensor(19.1703), '@': tensor(11.5482), '##ert': tensor(21.7833), 'consolidation': tensor(8.6131), ')': tensor(19.4493), 'where': tensor(19.2599), '##ng': tensor(12.4155), 'to': tensor(13.9437), 'methods': tensor(8.2049), 'depending': tensor(9.5492), 'results': tensor(9.3719), 'decreased': tensor(9.2037), 'which': tensor(8.6841), '.': tensor(17.6050), 'as': tensor(13.3705), 'eye': tensor(8.0030), 'subsequently': tensor(13.5081), 'and': tensor(15.7992), 'awake': tensor(14.2704), 'movement': tensor(9.4965), 'healthy': tensor(7.9458)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', 'of', 'the', 'study', 'was', 'to', 'assess', 'semantic', 'pri', '##ming', 'to', 'emotion', 'and', 'none', '##mot', '##ion', 'cue', 'words', 'using', 'a', 'novel', 'measure', 'of', 'association', '##al', 'breadth', 'for', 'participants', 'who', 'either', 'took', 'rapid', 'eye', 'movement', '(', 're', '##m', ')', 'or', 'non', '##ra', '##pid', 'eye', 'movement', '(', 'nr', '##em', '[MASK]', 'nap', '##s', 'or', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', 'pri', '##ming', 'to', 're', '[MASK]', 'sleep', 'consolidation', 'and', 're', '##m', 'sleep', 'in', '##ert', '##ia', 'effects', '.', 'methods', 'the', 'association', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', 'pri', '##ming', 'condition', ',', 'where', 'cue', '-', 'words', 'were', 'signaled', '[MASK]', 'be', 'memo', '##rized', 'prior', 'to', 'sleep', '(', 'prime', '##d', ')', ',', 'and', 'a', 'non', '##pr', '##imi', '##ng', 'condition', '[MASK]', 'where', 'cue', 'words', 'were', 'not', 'memo', '##rized', '(', 'non', '##pr', '[MASK]', '##d', '[MASK]', '.', 'methods', 'cue', 'words', 'were', 'either', '[MASK]', '[MASK]', 'positive', '[MASK]', 'negative', ')', 'or', 'none', '##mot', '##ional', '.', '[MASK]', '[MASK]', 'were', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', 'a', '[MASK]', 'condition', ',', 'which', 'was', 'subsequently', 'split', 'into', 'nr', '##em', 'or', 're', '[MASK]', 'groups', 'depending', 'on', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', 'based', 'sleep', 'laboratory', '.', 'methods', 'fifty', '-', 'eight', 'healthy', 'participants', '(', '@', 'male', ')', 'ages', '@', 'to', '@', 'y', '(', '[MASK]', '[MASK]', '@', '@', 'y', ')', '.', 'results', 'the', 're', '##m', 'group', 'scored', 'higher', '[MASK]', 'the', 'nr', '##em', 'or', 'wake', 'groups', 'on', 'prime', '[MASK]', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', 'effect', 'was', 'stronger', 'for', 'positive', 'than', 'for', '[MASK]', 'cue', 'words', '[MASK]', 'results', 'however', ',', 're', '##m', 'time', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', 'of', 'emotional', 'pri', '##ming', '.', 'results', '[MASK]', '##ming', 'occurred', 'for', 're', '##m', 'awakening', '[MASK]', 'but', 'not', 'for', 'nr', '[MASK]', 'awakening', '##s', ',', 'even', 'when', 'the', 'latter', 'sleep', 'episodes', 'contained', 'some', 're', '##m', 'sleep', '.', '[MASK]', 'association', '##al', 'breadth', 'may', 'be', 'selective', '##ly', 'consolidated', 'during', 're', '##m', 'sleep', '[MASK]', 'stimuli', 'that', '[MASK]', 'been', 'tagged', 'as', 'important', 'for', 'future', '[MASK]', 'retrieval', '.', 'conclusions', '[MASK]', 'pri', '##ming', 'decreased', '[MASK]', '[MASK]', '[MASK]', 'time', '[MASK]', 'was', 'higher', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', 'two', 'ex', '[MASK]', '##ana', '[MASK]', 're', '[MASK]', 'sleep', 'processes', ':', 're', '##m', 'sleep', 'consolidation', 'serving', 'emotional', 'down', '##re', '##gul', '[MASK]', 'and', 're', '##m', '[MASK]', '[MASK]', '##ert', '##ia', '.', '[SEP]']
{228: '##d', 298: 'conclusions', 369: 'sleep', 325: 'that', 329: 'with', 137: 'emotional', 248: 'negative', 365: '##ation', 140: ',', 333: 'and', 314: 'have', 331: '##m', 130: ')', 65: '##m', 350: '##tory', 138: '(', 98: 'to', 128: '##ime', 330: 're', 270: 'pri', 148: 'methods', 277: '##s', 117: ',', 206: '=', 162: 'sleep', 205: 'mage', 50: ')', 149: 'participants', 352: '##m', 251: '.', 219: 'than', 311: 'for', 174: '##m', 348: '##pl', 321: 'memory', 282: '##em', 370: 'in'}
loss:  20.525310516357422
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 64.86%
Average score: 14.53
{'##d': '##d', 'conclusions': 'the', 'sleep': 'wake', 'that': 'that', 'with': 'the', 'emotional': 'either', 'negative': 'emotional', '##ation': '##ation', ',': ',', 'and': 'and', 'have': 'have', '##m': '##m', ')': ')', '##tory': '##tory', '(': '(', 'to': 'to', '##ime': '##ime', 're': 'the', 'pri': 'pri', 'methods': 'participants', '##s': '##s', '=': '*', 'mage': '*', 'participants': 'words', '.': '.', 'than': 'than', 'for': 'with', '##pl': '##pl', 'memory': 'memory', '##em': '##em', 'in': 'in'}
{'##d': tensor(18.4874), 'conclusions': tensor(9.1070), 'sleep': tensor(11.8216), 'that': tensor(9.0890), 'with': tensor(7.1863), 'emotional': tensor(10.7354), 'negative': tensor(11.2675), '##ation': tensor(22.5902), ',': tensor(16.7858), 'and': tensor(10.1737), 'have': tensor(14.9376), '##m': tensor(22.5056), ')': tensor(15.8748), '##tory': tensor(15.3562), '(': tensor(16.2864), 'to': tensor(15.8554), '##ime': tensor(25.1638), 're': tensor(6.6088), 'pri': tensor(21.2240), 'methods': tensor(9.4922), '##s': tensor(16.3902), '=': tensor(6.7763), 'mage': tensor(6.0245), 'participants': tensor(14.0372), '.': tensor(13.9282), 'than': tensor(14.1463), 'for': tensor(10.5488), '##pl': tensor(23.9632), 'memory': tensor(12.7471), '##em': tensor(21.9364), 'in': tensor(19.5061)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using pretrained weights
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', '[MASK]', 'the', 'study', 'was', 'to', 'assess', 'semantic', 'pri', '##ming', 'to', 'emotion', '[MASK]', 'none', '##mot', '##ion', 'cue', 'words', 'using', 'a', 'novel', 'measure', 'of', 'association', '##al', 'breadth', 'for', 'participants', 'who', 'either', 'took', 'rapid', 'eye', 'movement', '(', 're', '[MASK]', ')', 'or', 'non', '##ra', '##pid', 'eye', 'movement', '[MASK]', 'nr', '[MASK]', ')', 'nap', '##s', '[MASK]', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', 'pri', '##ming', 'to', 're', '##m', 'sleep', 'consolidation', 'and', 're', '##m', 'sleep', 'in', '##ert', '##ia', 'effects', '.', 'methods', '[MASK]', 'association', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', 'pri', '##ming', 'condition', ',', 'where', 'cue', '[MASK]', '[MASK]', 'were', 'signaled', 'to', 'be', 'memo', '##rized', 'prior', 'to', 'sleep', '[MASK]', 'prime', '##d', ')', ',', 'and', 'a', '[MASK]', '##pr', '##imi', '##ng', 'condition', ',', 'where', 'cue', 'words', '[MASK]', 'not', 'memo', '##rized', '(', 'non', '##pr', '##ime', '##d', '[MASK]', '.', 'methods', 'cue', 'words', '[MASK]', 'either', 'emotional', '(', 'positive', ',', 'negative', ')', 'or', 'none', '##mot', '##ional', '.', 'methods', 'participants', 'were', 'randomly', 'assigned', 'to', 'either', 'an', '[MASK]', '[MASK]', 'wake', ')', '[MASK]', 'a', '[MASK]', 'condition', ',', '[MASK]', 'was', 'subsequently', 'split', 'into', 'nr', '##em', 'or', 're', '##m', 'groups', 'depending', 'on', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', 'based', 'sleep', 'laboratory', '[MASK]', 'methods', 'fifty', '-', 'eight', 'healthy', 'participants', '(', '@', 'male', ')', 'ages', '@', 'to', '@', 'y', '(', 'mage', '=', '@', '[MASK]', 'y', ')', '.', '[MASK]', 'the', 're', '##m', 'group', 'scored', 'higher', 'than', 'the', 'nr', '##em', 'or', 'wake', 'groups', 'on', 'prime', '##d', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', '[MASK]', 'cue', 'words', ';', 'the', 'effect', 'was', '[MASK]', 'for', 'positive', 'than', 'for', 'negative', '[MASK]', 'words', '.', 'results', 'however', ',', 're', '##m', 'time', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', 'of', '[MASK]', 'pri', '##ming', '[MASK]', 'results', 'pri', '##ming', 'occurred', 'for', '[MASK]', '##m', '[MASK]', '##s', '[MASK]', 'not', 'for', 'nr', '##em', 'awakening', '[MASK]', ',', 'even', 'when', 'the', 'latter', 'sleep', 'episodes', 'contained', 'some', 're', '##m', 'sleep', '.', 'conclusions', 'association', '##al', 'breadth', 'may', 'be', 'selective', '##ly', 'consolidated', 'during', 're', '##m', 'sleep', 'for', '[MASK]', 'that', 'have', 'been', 'tagged', '[MASK]', 'important', 'for', 'future', 'memory', 'retrieval', '.', 'conclusions', 'that', 'pri', '##ming', 'decreased', 'with', 're', '##m', 'time', 'and', 'was', '[MASK]', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', 'two', 'ex', '##pl', '##ana', '##tory', 're', '##m', '[MASK]', 'processes', ':', 're', '##m', 'sleep', 'consolidation', 'serving', 'emotional', '[MASK]', '##re', '##gul', '##ation', 'and', 're', '##m', 'sleep', 'in', '[MASK]', '##ia', '.', '[SEP]']
{236: 'emotional', 249: 'cue', 265: 'emotional', 49: '##em', 15: 'and', 208: '@', 312: 'stimuli', 162: 'sleep', 317: 'as', 268: '.', 39: '##m', 353: 'sleep', 105: '(', 112: 'non', 121: 'were', 165: 'which', 284: '##s', 276: 'awakening', 95: 'words', 4: 'of', 53: 'or', 212: 'results', 47: '(', 130: ')', 188: '.', 135: 'were', 94: '-', 78: 'the', 243: 'stronger', 274: 're', 335: 'higher', 156: 'awake', 371: '##ert', 278: 'but', 160: 'or', 157: '(', 362: 'down'}
loss:  19.997882843017578
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 67.57%
Average score: 15.03
{'emotional': 'semantic', 'cue': 'cue', '##em': '##em', 'and': 'or', '@': '@', 'stimuli': 'tasks', 'sleep': 'sleep', 'as': 'as', '.': 'study', '##m': '##m', '(': '(', 'non': 'non', 'were': 'were', 'which': 'which', '##s': '##s', 'awakening': 'awakening', 'words': 'words', 'of': 'of', 'or': 'or', 'results': 'results', ')': ')', '-': 'words', 'the': 'the', 'stronger': 'greater', 're': 're', 'higher': 'activated', 'awake': 'emotional', '##ert': '##ert', 'but': 'but', 'down': 'down'}
{'emotional': tensor(10.1270), 'cue': tensor(15.4602), '##em': tensor(19.7688), 'and': tensor(9.9158), '@': tensor(10.8250), 'stimuli': tensor(12.7849), 'sleep': tensor(13.6619), 'as': tensor(13.9153), '.': tensor(8.0559), '##m': tensor(22.1608), '(': tensor(18.7409), 'non': tensor(15.8582), 'were': tensor(14.4719), 'which': tensor(12.9662), '##s': tensor(16.2899), 'awakening': tensor(18.4234), 'words': tensor(20.2175), 'of': tensor(16.0979), 'or': tensor(13.8753), 'results': tensor(9.7167), ')': tensor(19.6842), '-': tensor(19.9550), 'the': tensor(10.2416), 'stronger': tensor(13.9288), 're': tensor(16.8363), 'higher': tensor(10.4987), 'awake': tensor(14.1946), '##ert': tensor(23.4819), 'but': tensor(14.3483), 'down': tensor(14.4331)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'ad', '##ren', '##er', '##gic', 'activation', 'is', 'thought', '[MASK]', '[MASK]', 'an', 'important', '[MASK]', '##mina', '[MASK]', 'of', 'outcome', 'in', 'subjects', 'with', 'chronic', '[MASK]', 'failure', '(', 'ch', '##f', ')', ',', 'but', 'baseline', 'or', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '##gic', 'activity', 'have', 'not', '[MASK]', 'previously', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', 'with', 'a', 'powerful', 'anti', '##ad', '[MASK]', '##er', '##gic', 'agent', '.', 'results', 'systemic', 've', '##nous', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'measured', 'at', 'baseline', ',', '@', 'months', ',', 'and', '@', 'months', 'in', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', 'place', '##bo', 'treatment', 'with', '[MASK]', 'beta', '-', 'block', '##er', '/', '[MASK]', '##mp', '##ath', '[MASK]', '##ytic', 'agent', 'bu', '##cin', '##do', '##lo', '##l', '.', 'results', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', 'level', 'was', 'associated', 'with', 'a', 'progressive', 'increase', 'in', 'rates', '[MASK]', 'death', 'or', 'death', 'plus', '[MASK]', '##f', 'hospital', '##ization', 'that', 'was', 'independent', 'of', 'treatment', 'group', '.', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'also', 'a', 'highly', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '##or', 'of', 'death', '.', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', 'the', 'change', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', '[MASK]', 'treatment', 'group', '-', 'dependent', '.', 'results', '[MASK]', 'the', 'place', '##bo', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '[MASK]', '[MASK]', '[MASK]', ',', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'increase', 'at', '@', 'months', 'was', 'associated', 'with', 'increased', '[MASK]', 'risks', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', '.', 'results', '[MASK]', 'the', 'bu', '##cin', '##do', '[MASK]', '##l', '-', 'treated', 'group', 'but', 'not', '[MASK]', '[MASK]', 'place', '##bo', '-', 'treated', 'group', ',', 'the', '@', 'st', 'qu', '##art', '##ile', 'of', 'marked', 'nor', '##ep', '##ine', '[MASK]', '##rine', 'reduction', '[MASK]', 'associated', 'with', 'an', 'increased', 'mortality', 'risk', '.', 'results', 'a', '[MASK]', '-', 'based', '[MASK]', '[MASK]', 'that', '@', '%', 'of', 'the', 'bu', '##cin', '##do', '##lo', '##l', 'group', 'but', 'only', '@', '%', 'of', 'the', '[MASK]', '##bo', 'group', 'were', 'at', 'an', 'increased', 'risk', 'for', 'death', 'related', '[MASK]', 'marked', 'reduction', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', '[MASK]', '@', 'months', '.', 'conclusions', 'in', '[MASK]', ',', 'a', 'subset', '[MASK]', 'patients', 'treated', '[MASK]', 'bu', '##cin', '[MASK]', '##lo', '[MASK]', 'had', 'an', '[MASK]', 'risk', 'of', 'death', 'as', 'the', 'result', 'of', 'sy', '##mp', '##ath', '##ol', '##ysis', ',', '[MASK]', 'compromised', 'the', '[MASK]', 'of', 'this', 'third', '-', 'generation', '[MASK]', '-', 'block', '##er', '.', '[SEP]']
{305: 'method', 229: 'group', 271: 'the', 362: '##l', 13: 'deter', 204: 'and', 56: '##ren', 135: 'of', 354: 'of', 379: 'which', 270: 'in', 227: '-', 357: 'with', 360: '##do', 42: 'been', 263: '##lo', 140: 'ch', 15: '##nt', 22: 'heart', 292: 'was', 388: 'beta', 258: 'in', 365: 'increased', 382: 'efficacy', 101: 'the', 335: 'to', 9: 'to', 302: 'likelihood', 289: '##ph', 350: 'best', 245: 'subsequent', 344: 'at', 211: 'in', 228: 'treated', 324: 'place', 306: 'indicated', 110: '##ol', 107: 'sy', 10: 'be'}
loss:  22.76003074645996
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 82.05%
Average score: 16.59
{'method': 'analysis', 'group': 'treatment', 'the': 'the', '##l': '##l', 'deter': 'deter', 'and': 'and', '##ren': '##ren', 'of': 'of', 'which': 'which', 'in': 'in', '-': 'group', 'with': 'with', '##do': '##do', 'been': 'been', '##lo': '##lo', 'ch': 'ch', '##nt': '##nt', 'heart': 'heart', 'was': 'was', 'beta': 'beta', 'increased': 'increased', 'efficacy': 'efficacy', 'to': 'to', 'likelihood': 'population', '##ph': '##ph', 'best': 'contrast', 'subsequent': 'relative', 'at': 'at', 'treated': 'treated', 'place': 'place', 'indicated': 'showed', '##ol': '##ol', 'sy': 'sy', 'be': 'be'}
{'method': tensor(12.6979), 'group': tensor(8.4210), 'the': tensor(12.0957), '##l': tensor(16.0905), 'deter': tensor(17.1269), 'and': tensor(14.3484), '##ren': tensor(22.1221), 'of': tensor(14.9229), 'which': tensor(13.1936), 'in': tensor(13.3043), '-': tensor(10.3698), 'with': tensor(16.0084), '##do': tensor(27.1501), 'been': tensor(20.0171), '##lo': tensor(26.7829), 'ch': tensor(19.5334), '##nt': tensor(18.4931), 'heart': tensor(16.5630), 'was': tensor(14.5792), 'beta': tensor(16.3638), 'increased': tensor(17.5019), 'efficacy': tensor(14.9670), 'to': tensor(17.2650), 'likelihood': tensor(8.9714), '##ph': tensor(27.5674), 'best': tensor(13.0692), 'subsequent': tensor(11.0107), 'at': tensor(14.5672), 'treated': tensor(8.9148), 'place': tensor(23.0531), 'indicated': tensor(12.9441), '##ol': tensor(22.1281), 'sy': tensor(26.9255), 'be': tensor(14.9908)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'ad', '##ren', '##er', '##gic', 'activation', '[MASK]', 'thought', 'to', 'be', 'an', 'important', 'deter', '##mina', '##nt', 'of', 'outcome', 'in', 'subjects', 'with', 'chronic', 'heart', '[MASK]', '(', 'ch', '[MASK]', ')', ',', 'but', 'baseline', '[MASK]', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '##gic', 'activity', '[MASK]', 'not', '[MASK]', 'previously', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', 'with', 'a', 'powerful', 'anti', '##ad', '##ren', '[MASK]', '##gic', 'agent', '[MASK]', 'results', 'systemic', 've', '##nous', '[MASK]', '##ep', '##ine', '##ph', '##rine', '[MASK]', 'measured', 'at', '[MASK]', ',', '@', 'months', ',', 'and', '@', 'months', '[MASK]', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', 'place', '##bo', 'treatment', 'with', 'the', 'beta', '-', 'block', '##er', '/', 'sy', '##mp', '##ath', '##ol', '##ytic', '[MASK]', 'bu', '##cin', '##do', '##lo', '##l', '.', 'results', 'baseline', '[MASK]', '##ep', '[MASK]', '[MASK]', '##rine', 'level', 'was', 'associated', 'with', '[MASK]', 'progressive', 'increase', 'in', 'rates', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', 'that', 'was', 'independent', 'of', 'treatment', 'group', '.', '[MASK]', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '##ep', '##ine', '##ph', '##rine', '[MASK]', 'also', 'a', 'highly', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '##or', 'of', 'death', '.', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', 'the', 'change', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', '[MASK]', 'treatment', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '##bo', '-', 'treated', '[MASK]', 'but', 'not', 'in', 'the', '[MASK]', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', ',', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'increase', 'at', '[MASK]', 'months', '[MASK]', 'associated', 'with', 'increased', '[MASK]', '[MASK]', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', '[MASK]', 'results', 'in', 'the', 'bu', '[MASK]', '##do', '##lo', '##l', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'place', '##bo', '-', '[MASK]', 'group', ',', 'the', '@', 'st', 'qu', '##art', '##ile', 'of', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', '[MASK]', '[MASK]', 'associated', 'with', 'an', 'increased', 'mortality', 'risk', '.', 'results', 'a', 'likelihood', '-', 'based', 'method', 'indicated', 'that', '@', '%', 'of', 'the', '[MASK]', '[MASK]', '##do', '##lo', '##l', '[MASK]', 'but', 'only', '@', '%', 'of', 'the', 'place', '##bo', '[MASK]', 'were', 'at', 'an', 'increased', 'risk', 'for', 'death', 'related', 'to', 'marked', 'reduction', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', '.', '[MASK]', 'in', 'best', '[MASK]', 'a', 'subset', 'of', 'patients', 'treated', 'with', 'bu', '##cin', '##do', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', 'the', 'result', 'of', 'sy', '##mp', '##ath', '##ol', '##ysis', ',', 'which', 'compromised', '[MASK]', 'efficacy', '[MASK]', 'this', 'third', '-', 'generation', 'beta', '-', 'block', '##er', '.', '[SEP]']
{292: 'was', 73: 'baseline', 222: 'bu', 245: 'subsequent', 164: 'was', 57: '##er', 123: '##ine', 151: 'results', 26: '##f', 261: '##cin', 204: 'and', 317: 'group', 291: 'reduction', 246: 'risks', 23: 'failure', 275: 'treated', 217: 'group', 256: '.', 313: '##cin', 7: 'is', 348: 'conclusions', 381: 'the', 241: 'was', 326: 'group', 124: '##ph', 121: 'nor', 351: ',', 312: 'bu', 40: 'have', 81: 'in', 383: 'of', 112: 'agent', 60: '.', 70: 'was', 31: 'or', 42: 'been', 239: '@', 130: 'a', 65: 'nor'}
loss:  21.707914352416992
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 74.36%
Average score: 15.37
{'was': 'were', 'baseline': 'baseline', 'bu': 'bu', 'subsequent': 'progression', '##er': '##er', '##ine': '##ine', 'results': 'results', '##f': '##f', '##cin': '##cin', 'and': 'and', 'group': 'patients', 'reduction': 'increase', 'risks': 'rates', 'failure': 'failure', 'treated': 'treated', '.': '.', 'is': 'is', 'conclusions': 'results', 'the': 'the', '##ph': '##ph', 'nor': 'nor', ',': ',', 'have': 'did', 'in': 'in', 'of': 'of', 'agent': 'drug', 'or': 'and', 'been': 'been', '@': '@', 'a': 'a'}
{'was': tensor(13.9375), 'baseline': tensor(12.4882), 'bu': tensor(14.4939), 'subsequent': tensor(8.5981), '##er': tensor(25.8134), '##ine': tensor(22.9792), 'results': tensor(12.9354), '##f': tensor(17.9278), '##cin': tensor(20.9865), 'and': tensor(14.3864), 'group': tensor(11.4926), 'reduction': tensor(11.2706), 'risks': tensor(15.7648), 'failure': tensor(16.7652), 'treated': tensor(16.9220), '.': tensor(14.9050), 'is': tensor(15.5378), 'conclusions': tensor(14.7903), 'the': tensor(14.4850), '##ph': tensor(24.7831), 'nor': tensor(21.5586), ',': tensor(9.9616), 'have': tensor(14.3705), 'in': tensor(12.2053), 'of': tensor(16.6620), 'agent': tensor(10.6122), 'or': tensor(10.4673), 'been': tensor(14.3781), '@': tensor(14.6780), 'a': tensor(15.0356)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', '[MASK]', '##ren', '##er', '##gic', 'activation', 'is', 'thought', 'to', 'be', '[MASK]', '[MASK]', 'deter', '##mina', '##nt', 'of', '[MASK]', 'in', 'subjects', 'with', 'chronic', 'heart', 'failure', '(', 'ch', '##f', ')', ',', 'but', 'baseline', 'or', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '[MASK]', 'activity', 'have', 'not', 'been', '[MASK]', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', '[MASK]', 'a', 'powerful', 'anti', '##ad', '##ren', '##er', '##gic', 'agent', '.', 'results', 'systemic', 've', '##nous', 'nor', '##ep', '##ine', '##ph', '##rine', 'was', 'measured', 'at', 'baseline', ',', '@', '[MASK]', '[MASK]', 'and', '[MASK]', 'months', '[MASK]', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', 'place', '##bo', 'treatment', 'with', 'the', 'beta', '-', 'block', '##er', '/', '[MASK]', '##mp', '##ath', '##ol', '##ytic', 'agent', 'bu', '##cin', '##do', '##lo', '##l', '[MASK]', 'results', 'baseline', 'nor', '##ep', '[MASK]', '##ph', '##rine', 'level', 'was', 'associated', 'with', 'a', 'progressive', 'increase', 'in', 'rates', '[MASK]', 'death', '[MASK]', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', 'that', 'was', 'independent', 'of', 'treatment', 'group', '.', 'results', 'on', 'multi', '##var', '[MASK]', 'analysis', ',', '[MASK]', 'nor', '##ep', '##ine', '##ph', '[MASK]', 'was', 'also', 'a', '[MASK]', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '##or', 'of', 'death', '.', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', 'the', 'change', 'in', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', 'and', 'treatment', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '##bo', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', ',', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'increase', 'at', '@', 'months', 'was', 'associated', 'with', 'increased', 'subsequent', 'risks', 'of', 'death', 'or', '[MASK]', 'plus', '[MASK]', '##f', 'hospital', '##ization', '.', 'results', 'in', 'the', 'bu', '##cin', '##do', '[MASK]', '##l', '[MASK]', 'treated', 'group', 'but', 'not', 'in', 'the', 'place', '[MASK]', '-', 'treated', '[MASK]', ',', 'the', '@', 'st', 'qu', '##art', '##ile', 'of', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'reduction', 'was', '[MASK]', 'with', '[MASK]', 'increased', '[MASK]', 'risk', '.', 'results', 'a', 'likelihood', '-', '[MASK]', 'method', 'indicated', '[MASK]', '@', '[MASK]', 'of', 'the', 'bu', '[MASK]', '##do', '##lo', '##l', 'group', 'but', 'only', '@', '%', 'of', 'the', 'place', '##bo', 'group', 'were', 'at', 'an', 'increased', 'risk', 'for', 'death', 'related', 'to', 'marked', 'reduction', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', '.', 'conclusions', '[MASK]', 'best', ',', 'a', 'subset', 'of', 'patients', 'treated', 'with', 'bu', '[MASK]', '##do', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', '[MASK]', '[MASK]', 'of', 'sy', '##mp', '##ath', '##ol', '[MASK]', ',', 'which', 'compromised', 'the', 'efficacy', 'of', 'this', 'third', '-', 'generation', 'beta', '-', 'block', '##er', '.', '[SEP]']
{43: 'previously', 377: '##ysis', 191: '##ep', 77: ',', 304: 'based', 297: 'mortality', 273: '##bo', 167: 'highly', 370: 'the', 309: '%', 38: '##gic', 293: 'associated', 51: 'with', 313: '##cin', 123: '##ine', 17: 'outcome', 12: 'important', 276: 'group', 155: '##iate', 107: 'sy', 265: '-', 263: '##lo', 135: 'of', 11: 'an', 2: 'ad', 81: 'in', 163: '##rine', 371: 'result', 137: 'or', 158: 'baseline', 76: 'months', 79: '@', 118: '.', 359: '##cin', 250: 'death', 295: 'an', 252: 'ch', 307: 'that', 349: 'in'}
loss:  22.696922302246094
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 82.05%
Average score: 17.21
{'previously': 'well', '##ysis': '##ysis', '##ep': '##ep', ',': ',', 'based': 'based', 'mortality': 'death', '##bo': '##bo', 'highly': 'highly', 'the': 'a', '%': '%', '##gic': '##gic', 'associated': 'associated', 'with': 'with', '##cin': '##cin', '##ine': '##ine', 'outcome': 'death', 'important': 'primary', 'group': 'group', '##iate': '##iate', 'sy': 'sy', '-': '-', '##lo': '##lo', 'of': 'of', 'an': 'an', 'ad': 'ad', 'in': 'from', '##rine': '##rine', 'result': 'result', 'or': 'or', 'baseline': 'baseline', 'months': 'months', '@': '@', '.': '.', 'death': 'death', 'ch': 'ch', 'that': 'that'}
{'previously': tensor(11.4269), '##ysis': tensor(20.1414), '##ep': tensor(28.0983), ',': tensor(14.4226), 'based': tensor(10.5851), 'mortality': tensor(10.6584), '##bo': tensor(23.0862), 'highly': tensor(12.5973), 'the': tensor(13.4267), '%': tensor(19.7716), '##gic': tensor(23.4901), 'associated': tensor(19.1881), 'with': tensor(16.8231), '##cin': tensor(25.0021), '##ine': tensor(25.8881), 'outcome': tensor(15.5890), 'important': tensor(11.6864), 'group': tensor(14.9601), '##iate': tensor(20.8317), 'sy': tensor(28.0466), '-': tensor(16.6368), '##lo': tensor(26.7588), 'of': tensor(16.9424), 'an': tensor(13.7227), 'ad': tensor(18.1079), 'in': tensor(7.2525), '##rine': tensor(22.9816), 'result': tensor(13.1318), 'or': tensor(16.9169), 'baseline': tensor(9.7330), 'months': tensor(12.0589), '@': tensor(15.9344), '.': tensor(14.7897), 'death': tensor(14.8218), 'ch': tensor(20.2854), 'that': tensor(13.8460)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'ad', '##ren', '##er', '##gic', '[MASK]', 'is', 'thought', '[MASK]', 'be', 'an', 'important', '[MASK]', '##mina', '##nt', 'of', 'outcome', 'in', 'subjects', 'with', 'chronic', 'heart', '[MASK]', '(', 'ch', '##f', ')', '[MASK]', 'but', 'baseline', 'or', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '##gic', 'activity', 'have', 'not', 'been', 'previously', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', '[MASK]', 'a', 'powerful', 'anti', '##ad', '##ren', '##er', '##gic', 'agent', '.', 'results', 'systemic', 've', '##nous', 'nor', '##ep', '##ine', '##ph', '##rine', '[MASK]', 'measured', 'at', 'baseline', '[MASK]', '@', 'months', ',', '[MASK]', '@', 'months', 'in', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', 'compared', 'place', '##bo', 'treatment', '[MASK]', 'the', 'beta', '-', 'block', '##er', '/', 'sy', '##mp', '##ath', '##ol', '##ytic', 'agent', 'bu', '##cin', '##do', '##lo', '##l', '.', 'results', 'baseline', 'nor', '[MASK]', '##ine', '[MASK]', '##rine', 'level', 'was', 'associated', 'with', 'a', 'progressive', 'increase', 'in', 'rates', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '[MASK]', 'that', 'was', 'independent', 'of', 'treatment', 'group', '[MASK]', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'was', 'also', 'a', 'highly', 'significant', '(', '[MASK]', '<', '@', ')', 'independent', 'predict', '##or', 'of', 'death', '.', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', 'the', 'change', 'in', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', '[MASK]', 'outcomes', '[MASK]', 'complex', 'and', 'treatment', 'group', '-', 'dependent', '.', 'results', 'in', 'the', 'place', '##bo', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', ',', 'marked', 'nor', '##ep', '[MASK]', '##ph', '##rine', 'increase', '[MASK]', '@', 'months', 'was', 'associated', 'with', 'increased', 'subsequent', 'risks', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', '.', 'results', '[MASK]', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', 'but', 'not', 'in', 'the', 'place', '##bo', '-', 'treated', 'group', ',', 'the', '@', 'st', 'qu', '##art', '##ile', '[MASK]', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', '[MASK]', 'was', 'associated', 'with', 'an', 'increased', 'mortality', '[MASK]', '.', 'results', 'a', 'likelihood', '-', 'based', '[MASK]', 'indicated', 'that', '@', '[MASK]', 'of', 'the', '[MASK]', '##cin', '##do', '##lo', '##l', 'group', 'but', 'only', '@', '%', 'of', 'the', '[MASK]', '[MASK]', 'group', 'were', 'at', 'an', 'increased', 'risk', 'for', 'death', '[MASK]', 'to', 'marked', 'reduction', '[MASK]', 'nor', '##ep', '##ine', '##ph', '##rine', '[MASK]', '@', '[MASK]', '.', 'conclusions', 'in', 'best', ',', 'a', 'subset', 'of', 'patients', 'treated', 'with', 'bu', '##cin', '##do', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', 'the', 'result', '[MASK]', 'sy', '##mp', '[MASK]', '##ol', '##ysis', '[MASK]', 'which', 'compromised', 'the', 'efficacy', 'of', 'this', 'third', '[MASK]', 'generation', '[MASK]', '-', 'block', '[MASK]', '.', '[SEP]']
{346: 'months', 324: 'place', 391: '##er', 124: '##ph', 344: 'at', 202: 'was', 386: '-', 298: 'risk', 74: ',', 200: 'clinical', 309: '%', 258: 'in', 100: 'with', 122: '##ep', 23: 'failure', 388: 'beta', 9: 'to', 375: '##ath', 284: 'of', 234: '##ine', 238: 'at', 28: ',', 325: '##bo', 6: 'activation', 378: ',', 338: 'in', 51: 'with', 13: 'deter', 334: 'related', 150: '.', 305: 'method', 70: 'was', 170: 'p', 160: '##ep', 143: '##ization', 372: 'of', 291: 'reduction', 312: 'bu', 78: 'and'}
loss:  23.169933319091797
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 79.49%
Average score: 17.08
{'months': 'months', 'place': 'place', '##er': '##er', '##ph': '##ph', 'at': 'at', 'was': 'was', '-': '-', 'risk': 'rate', ',': ',', 'clinical': 'clinical', '%': '%', 'in': 'in', 'with': 'with', '##ep': '##ep', 'failure': 'disease', 'beta': 'beta', 'to': 'to', '##ath': '##ath', 'of': 'of', '##ine': '##ine', '##bo': 'treatment', 'activation': 'activity', 'deter': 'deter', 'related': 'due', '.': '.', 'method': 'analysis', 'p': 'p', '##ization': '##ization', 'reduction': 'increase', 'bu': 'bu', 'and': 'and'}
{'months': tensor(14.5071), 'place': tensor(11.7291), '##er': tensor(18.5993), '##ph': tensor(26.9285), 'at': tensor(13.8201), 'was': tensor(13.7629), '-': tensor(18.2499), 'risk': tensor(14.5613), ',': tensor(13.6436), 'clinical': tensor(10.8758), '%': tensor(19.5877), 'in': tensor(15.3392), 'with': tensor(16.7453), '##ep': tensor(27.8958), 'failure': tensor(16.6512), 'beta': tensor(15.6977), 'to': tensor(21.8813), '##ath': tensor(27.9416), 'of': tensor(16.1167), '##ine': tensor(25.4328), '##bo': tensor(13.5194), 'activation': tensor(15.3154), 'deter': tensor(18.9639), 'related': tensor(14.2907), '.': tensor(13.5087), 'method': tensor(12.9653), 'p': tensor(13.2617), '##ization': tensor(20.8885), 'reduction': tensor(11.3881), 'bu': tensor(21.2788), 'and': tensor(14.2619)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test01.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', '[MASK]', '##ren', '[MASK]', '##gic', 'activation', 'is', 'thought', '[MASK]', 'be', 'an', 'important', '[MASK]', '##mina', '##nt', 'of', 'outcome', 'in', 'subjects', 'with', 'chronic', 'heart', 'failure', '(', 'ch', '##f', ')', ',', 'but', 'baseline', 'or', 'serial', 'changes', 'in', 'ad', '##ren', '##er', '##gic', 'activity', 'have', 'not', 'been', 'previously', 'investigated', 'in', 'a', 'large', 'patient', 'sample', 'treated', 'with', 'a', 'powerful', 'anti', '##ad', '##ren', '##er', '##gic', 'agent', '[MASK]', 'results', 'systemic', 've', '##nous', 'nor', '##ep', '[MASK]', '##ph', '##rine', 'was', 'measured', '[MASK]', '[MASK]', ',', '@', 'months', ',', 'and', '@', 'months', 'in', 'the', 'beta', '-', 'block', '##er', 'evaluation', 'of', 'survival', 'trial', '(', 'best', ')', ',', 'which', '[MASK]', 'place', '[MASK]', 'treatment', '[MASK]', 'the', 'beta', '-', 'block', '##er', '/', 'sy', '##mp', '##ath', '##ol', '[MASK]', 'agent', 'bu', '##cin', '##do', '##lo', '##l', '.', 'results', 'baseline', '[MASK]', '[MASK]', '##ine', '##ph', '##rine', 'level', 'was', 'associated', '[MASK]', 'a', 'progressive', 'increase', 'in', 'rates', 'of', 'death', 'or', 'death', 'plus', 'ch', '##f', 'hospital', '##ization', 'that', 'was', 'independent', 'of', 'treatment', 'group', '.', 'results', 'on', 'multi', '##var', '##iate', 'analysis', ',', 'baseline', 'nor', '##ep', '##ine', '##ph', '[MASK]', 'was', 'also', 'a', '[MASK]', 'significant', '(', 'p', '<', '@', ')', 'independent', 'predict', '[MASK]', 'of', 'death', '.', 'results', 'in', 'contrast', ',', 'the', 'relation', 'of', 'the', 'change', '[MASK]', 'nor', '##ep', '##ine', '##ph', '##rine', 'at', '@', 'months', 'to', 'subsequent', 'clinical', 'outcomes', 'was', 'complex', 'and', 'treatment', 'group', '-', '[MASK]', '.', 'results', 'in', '[MASK]', 'place', '##bo', '[MASK]', 'treated', 'group', 'but', 'not', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', ',', 'marked', 'nor', '##ep', '##ine', '##ph', '##rine', 'increase', '[MASK]', '@', 'months', 'was', 'associated', 'with', 'increased', 'subsequent', 'risks', 'of', 'death', 'or', '[MASK]', 'plus', 'ch', '##f', '[MASK]', '##ization', '.', 'results', 'in', 'the', 'bu', '##cin', '##do', '##lo', '##l', '-', 'treated', 'group', 'but', 'not', 'in', '[MASK]', 'place', '##bo', '-', 'treated', 'group', ',', 'the', '@', 'st', 'qu', '##art', '##ile', 'of', 'marked', 'nor', '[MASK]', '##ine', '##ph', '##rine', 'reduction', 'was', 'associated', 'with', 'an', '[MASK]', 'mortality', 'risk', '.', '[MASK]', 'a', '[MASK]', '-', 'based', '[MASK]', 'indicated', 'that', '@', '%', 'of', 'the', 'bu', '##cin', '##do', '##lo', '##l', 'group', 'but', 'only', '@', '%', 'of', 'the', '[MASK]', '##bo', 'group', 'were', 'at', 'an', 'increased', 'risk', '[MASK]', 'death', 'related', 'to', 'marked', 'reduction', 'in', 'nor', '##ep', '[MASK]', '[MASK]', '##rine', 'at', '@', 'months', '.', 'conclusions', '[MASK]', 'best', ',', 'a', 'subset', 'of', '[MASK]', 'treated', 'with', 'bu', '##cin', '##do', '##lo', '##l', 'had', 'an', 'increased', 'risk', 'of', 'death', 'as', 'the', 'result', 'of', 'sy', '##mp', '##ath', '##ol', '##ysis', ',', 'which', 'compromised', '[MASK]', 'efficacy', 'of', 'this', 'third', '-', 'generation', 'beta', '-', 'block', '[MASK]', '.', '[SEP]']
{355: 'patients', 176: '##or', 167: 'highly', 13: 'deter', 98: '##bo', 122: '##ep', 4: '##er', 250: 'death', 341: '##ine', 271: 'the', 254: 'hospital', 349: 'in', 100: 'with', 305: 'method', 60: '.', 9: 'to', 391: '##er', 163: '##rine', 238: 'at', 67: '##ine', 332: 'for', 212: 'the', 381: 'the', 296: 'increased', 342: '##ph', 2: 'ad', 215: '-', 302: 'likelihood', 111: '##ytic', 208: 'dependent', 121: 'nor', 189: 'in', 96: 'compared', 72: 'at', 287: '##ep', 73: 'baseline', 300: 'results', 324: 'place', 129: 'with'}
loss:  23.960420608520508
prediction_scores:  torch.Size([1, 394, 30522])
Accuracy: 87.18%
Average score: 17.67
{'patients': 'patients', '##or': '##or', 'highly': 'highly', 'deter': 'deter', '##bo': '##bo', '##ep': '##ep', '##er': '##er', 'death': 'death', '##ine': '##ine', 'the': 'the', 'hospital': 'hospital', 'in': 'in', 'with': 'with', 'method': 'analysis', '.': '.', 'to': 'to', '##rine': '##rine', 'at': 'at', 'for': 'of', 'increased': 'increased', '##ph': '##ph', 'ad': 'ad', '-': '-', 'likelihood': 'population', '##ytic': '##ytic', 'dependent': 'wide', 'nor': 'nor', 'compared': 'compared', 'baseline': 'baseline', 'results': 'results', 'place': 'place'}
{'patients': tensor(14.5673), '##or': tensor(24.3652), 'highly': tensor(11.8370), 'deter': tensor(18.9121), '##bo': tensor(19.8097), '##ep': tensor(29.3160), '##er': tensor(19.6559), 'death': tensor(15.2077), '##ine': tensor(26.9400), 'the': tensor(14.6181), 'hospital': tensor(22.0332), 'in': tensor(16.0153), 'with': tensor(17.5499), 'method': tensor(12.6443), '.': tensor(15.9987), 'to': tensor(22.3751), '##rine': tensor(24.0694), 'at': tensor(14.5357), 'for': tensor(17.0130), 'increased': tensor(16.1116), '##ph': tensor(25.2299), 'ad': tensor(19.1245), '-': tensor(17.3488), 'likelihood': tensor(8.1409), '##ytic': tensor(19.6184), 'dependent': tensor(11.5649), 'nor': tensor(12.1832), 'compared': tensor(16.1338), 'baseline': tensor(10.2724), 'results': tensor(11.2016), 'place': tensor(23.3346)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', '[MASK]', 'evaluated', 'the', 'effectiveness', 'of', '[MASK]', 'three', '-', 'year', 'out', '##patient', 'commitment', 'pilot', 'program', 'established', 'in', '@', 'at', 'bellevue', 'hospital', 'in', 'new', 'york', '[MASK]', '.', 'methods', 'a', 'total', 'of', '@', 'participants', 'were', 'randomly', 'assigned', ';', '@', 'received', 'court', '-', 'ordered', 'treatment', ',', '[MASK]', '[MASK]', 'enhanced', 'services', ',', '[MASK]', '@', 'received', 'the', 'enhanced', '-', 'service', 'package', 'only', '[MASK]', 'methods', 'between', '@', 'and', '@', 'percent', 'of', 'the', 'subjects', 'completed', 'interviews', 'at', 'one', ',', 'five', ',', 'and', '@', 'months', 'after', 'hospital', 'discharge', '.', '[MASK]', 'outcome', 'measures', 'included', 're', '##hos', '[MASK]', '##ali', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '##mpt', '##oma', '##tology', ',', 'treatment', 'non', '##com', '[MASK]', '##iance', ',', 'and', 'perceived', '[MASK]', '[MASK]', 'coe', '##rc', '##ion', '.', 'results', 'on', 'all', 'major', 'outcome', 'measures', ',', 'no', 'statistical', '##ly', 'significant', 'differences', 'were', 'found', 'between', 'the', 'two', 'groups', '.', '[MASK]', 'no', 'subject', 'was', 'arrested', 'for', 'a', 'violent', 'crime', '.', 'results', 'eighteen', 'percent', 'of', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', '[MASK]', 'the', 'control', 'group', '[MASK]', 'arrested', 'at', '[MASK]', 'once', '.', 'results', 'the', 'percentage', 're', '##hos', '##pit', '##ali', '##zed', 'during', 'follow', '-', 'up', '[MASK]', 'about', 'the', 'same', 'for', 'both', 'groups', '-', '@', 'percent', 'and', '@', 'percent', ',', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', 'differ', 'significantly', 'in', 'the', 'total', '[MASK]', 'of', '[MASK]', 'hospitalized', 'during', 'the', 'follow', '[MASK]', 'up', 'period', '.', '[MASK]', 'participants', "'", 'perceptions', 'of', 'their', 'quality', 'of', '[MASK]', 'and', 'level', 'of', 'coe', '##rc', '##ion', 'were', 'about', 'the', 'same', '.', '[MASK]', 'from', 'the', 'community', 'service', 'providers', "'", 'perspective', ',', 'patients', 'in', 'the', 'two', 'groups', 'were', '[MASK]', 'adhere', '##nt', 'to', 'their', 'required', 'treatments', '.', 'conclusions', '[MASK]', 'results', 'must', '[MASK]', 'qualified', 'by', 'the', 'fact', 'that', 'no', 'pick', '-', 'up', 'order', '[MASK]', 'for', 'non', '##com', '[MASK]', '[MASK]', '##t', 'subjects', 'in', 'the', 'court', '-', 'ordered', 'group', 'were', 'implemented', 'during', '[MASK]', 'study', ',', 'which', 'compromised', 'the', '[MASK]', 'between', 'the', 'conditions', 'for', 'the', 'two', 'groups', ',', '[MASK]', 'that', 'persons', 'with', 'a', 'history', 'of', 'violence', 'were', 'excluded', 'from', 'the', 'program', '.', '[SEP]']
{276: 'procedures', 308: 'and', 59: '.', 89: '##pit', 280: '##pl', 3: 'study', 137: 'results', 209: 'days', 181: 'was', 45: 'which', 159: 'of', 50: 'and', 214: '-', 226: 'life', 207: 'number', 113: 'of', 26: 'city', 281: '##ian', 299: 'differences', 253: 'similarly', 163: 'were', 166: 'least', 262: 'all', 83: 'methods', 238: 'results', 218: 'results', 293: 'the', 8: 'a', 46: 'included', 107: '##pl', 112: 'level', 265: 'be'}
loss:  21.414766311645508
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 68.75%
Average score: 15.93
{'procedures': 'programs', 'and': 'and', '.': '.', '##pit': '##pit', '##pl': '##pl', 'study': 'study', 'results': '[UNK]', 'days': 'subjects', 'was': 'was', 'which': '@', 'of': 'of', '-': '-', 'life': 'life', 'number': 'number', 'city': 'city', '##ian': '##itan', 'differences': 'relationship', 'similarly': 'more', 'were': 'were', 'least': 'least', 'all': 'the', 'methods': 'major', 'the': 'the', 'a': 'a', 'included': 'received', 'level': 'level', 'be': 'be'}
{'procedures': tensor(12.2568), 'and': tensor(14.9728), '.': tensor(16.0779), '##pit': tensor(27.1520), '##pl': tensor(24.0393), 'study': tensor(14.4952), 'results': tensor(9.9985), 'days': tensor(13.3316), 'was': tensor(16.2251), 'which': tensor(14.1722), 'of': tensor(13.8083), '-': tensor(24.5640), 'life': tensor(21.4579), 'number': tensor(15.7673), 'city': tensor(15.6553), '##ian': tensor(21.8771), 'differences': tensor(13.7593), 'similarly': tensor(11.1448), 'were': tensor(15.3840), 'least': tensor(18.5614), 'all': tensor(10.4416), 'methods': tensor(11.2909), 'the': tensor(14.2718), 'a': tensor(14.3575), 'included': tensor(12.9375), 'level': tensor(13.2774), 'be': tensor(18.7120)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', '[MASK]', 'the', 'study', 'evaluated', 'the', 'effectiveness', 'of', 'a', 'three', '-', 'year', 'out', '##patient', 'commitment', 'pilot', 'program', 'established', 'in', '[MASK]', 'at', 'bellevue', '[MASK]', 'in', 'new', 'york', 'city', '.', 'methods', 'a', 'total', 'of', '@', 'participants', 'were', 'randomly', 'assigned', ';', '[MASK]', 'received', 'court', '-', 'ordered', 'treatment', '[MASK]', 'which', 'included', 'enhanced', '[MASK]', ',', 'and', '@', 'received', 'the', 'enhanced', '-', '[MASK]', 'package', 'only', '.', 'methods', 'between', '@', 'and', '@', 'percent', 'of', 'the', 'subjects', 'completed', 'interviews', 'at', 'one', ',', 'five', ',', 'and', '[MASK]', 'months', 'after', 'hospital', 'discharge', '.', 'methods', 'outcome', 'measures', 'included', 're', '[MASK]', '##pit', '##ali', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '##mpt', '##oma', '##tology', ',', 'treatment', 'non', '##com', '##pl', '##iance', ',', 'and', 'perceived', 'level', 'of', 'coe', '[MASK]', '##ion', '.', 'results', 'on', 'all', 'major', 'outcome', '[MASK]', ',', 'no', 'statistical', '[MASK]', 'significant', 'differences', 'were', 'found', '[MASK]', 'the', 'two', 'groups', '.', '[MASK]', 'no', 'subject', 'was', 'arrested', 'for', '[MASK]', 'violent', 'crime', '.', 'results', 'eighteen', 'percent', 'of', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', 'of', 'the', 'control', 'group', 'were', 'arrested', 'at', 'least', 'once', '.', 'results', 'the', '[MASK]', 're', '##hos', '##pit', '##ali', '##zed', 'during', '[MASK]', '-', 'up', 'was', 'about', 'the', 'same', '[MASK]', 'both', 'groups', '-', '@', 'percent', 'and', '@', 'percent', ',', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', 'differ', 'significantly', 'in', '[MASK]', 'total', 'number', 'of', 'days', 'hospitalized', 'during', 'the', '[MASK]', '-', 'up', '[MASK]', '.', 'results', 'participants', "'", 'perceptions', 'of', 'their', 'quality', 'of', 'life', '[MASK]', 'level', 'of', 'coe', '##rc', '##ion', 'were', 'about', 'the', 'same', '.', 'results', 'from', '[MASK]', 'community', 'service', '[MASK]', "'", '[MASK]', ',', 'patients', 'in', 'the', 'two', 'groups', 'were', 'similarly', '[MASK]', '##nt', 'to', '[MASK]', '[MASK]', 'treatments', '.', 'conclusions', 'all', 'results', 'must', 'be', 'qualified', 'by', 'the', 'fact', 'that', 'no', 'pick', '-', 'up', 'order', 'procedures', 'for', 'non', '##com', '##pl', '##ian', '##t', 'subjects', 'in', 'the', 'court', '-', '[MASK]', 'group', 'were', 'implemented', 'during', 'the', 'study', ',', 'which', 'compromised', 'the', '[MASK]', 'between', '[MASK]', 'conditions', 'for', 'the', 'two', 'groups', ',', 'and', 'that', '[MASK]', 'with', 'a', 'history', 'of', 'violence', 'were', 'excluded', 'from', 'the', 'program', '.', '[SEP]']
{288: 'ordered', 240: 'the', 178: 'follow', 216: 'period', 227: 'and', 245: 'perspective', 44: ',', 1: 'objective', 77: '@', 123: 'measures', 143: 'a', 115: '##rc', 257: 'their', 88: '##hos', 137: 'results', 243: 'providers', 19: '@', 301: 'the', 22: 'hospital', 205: 'the', 213: 'follow', 38: '@', 310: 'persons', 171: 'percentage', 254: 'adhere', 299: 'differences', 185: 'for', 48: 'services', 132: 'between', 56: 'service', 258: 'required', 127: '##ly'}
loss:  20.33021354675293
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 59.38%
Average score: 15.06
{'ordered': 'ordered', 'the': 'the', 'follow': 'follow', 'period': 'period', 'and': 'and', 'perspective': 'study', ',': ',', 'objective': ',', '@': '@', 'measures': 'measures', 'a': 'any', '##rc': '##rc', 'their': 'the', '##hos': '##hos', 'results': 'results', 'providers': 'providers', 'hospital': 'hospital', 'persons': 'subjects', 'percentage': 'number', 'adhere': 'adhere', 'differences': 'relationship', 'for': 'for', 'services': 'treatment', 'between': 'between', 'service': 'treatment', 'required': 'two', '##ly': '##ly'}
{'ordered': tensor(20.9003), 'the': tensor(14.6564), 'follow': tensor(14.5744), 'period': tensor(13.3489), 'and': tensor(14.2798), 'perspective': tensor(10.9118), ',': tensor(14.1142), 'objective': tensor(10.7800), '@': tensor(16.0486), 'measures': tensor(20.3552), 'a': tensor(12.2368), '##rc': tensor(26.1448), 'their': tensor(8.8011), '##hos': tensor(25.9793), 'results': tensor(15.0264), 'providers': tensor(11.8126), 'hospital': tensor(17.1190), 'persons': tensor(15.4770), 'percentage': tensor(11.1322), 'adhere': tensor(13.6015), 'differences': tensor(13.8414), 'for': tensor(14.2750), 'services': tensor(12.8159), 'between': tensor(18.2444), 'service': tensor(11.9684), 'required': tensor(7.9273), '##ly': tensor(20.3786)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'study', 'evaluated', '[MASK]', 'effectiveness', 'of', 'a', 'three', '[MASK]', 'year', 'out', '##patient', 'commitment', 'pilot', 'program', '[MASK]', 'in', '@', 'at', 'bellevue', 'hospital', 'in', 'new', 'york', 'city', '[MASK]', 'methods', '[MASK]', '[MASK]', 'of', '@', 'participants', 'were', 'randomly', 'assigned', ';', '@', 'received', 'court', '-', 'ordered', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', 'the', 'enhanced', '-', 'service', 'package', 'only', '.', 'methods', '[MASK]', '@', 'and', '@', 'percent', 'of', 'the', 'subjects', 'completed', '[MASK]', 'at', 'one', '[MASK]', 'five', ',', 'and', '@', 'months', 'after', '[MASK]', 'discharge', '.', 'methods', 'outcome', 'measures', 'included', 're', '##hos', '##pit', '##ali', '##zation', ',', 'arrest', ',', '[MASK]', 'of', 'life', ',', 'sy', '##mpt', '##oma', '##tology', ',', 'treatment', 'non', '[MASK]', '[MASK]', '##iance', '[MASK]', 'and', 'perceived', 'level', 'of', 'coe', '##rc', '##ion', '.', 'results', 'on', 'all', 'major', 'outcome', 'measures', ',', 'no', 'statistical', '##ly', 'significant', 'differences', 'were', 'found', 'between', 'the', 'two', 'groups', '.', 'results', '[MASK]', 'subject', 'was', '[MASK]', 'for', '[MASK]', 'violent', 'crime', '.', 'results', 'eighteen', 'percent', 'of', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', 'of', 'the', 'control', '[MASK]', 'were', 'arrested', 'at', 'least', 'once', '.', 'results', 'the', '[MASK]', 're', '##hos', '##pit', '##ali', '##zed', 'during', 'follow', '[MASK]', '[MASK]', 'was', 'about', 'the', 'same', 'for', '[MASK]', 'groups', '-', '@', 'percent', 'and', '@', 'percent', ',', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', 'differ', 'significantly', 'in', '[MASK]', 'total', 'number', 'of', 'days', 'hospitalized', 'during', 'the', 'follow', '-', 'up', 'period', '.', '[MASK]', 'participants', "'", 'perceptions', 'of', 'their', 'quality', 'of', 'life', 'and', 'level', 'of', 'coe', '##rc', '[MASK]', 'were', 'about', 'the', 'same', '.', 'results', 'from', 'the', 'community', 'service', '[MASK]', "'", 'perspective', ',', 'patients', 'in', 'the', 'two', 'groups', 'were', 'similarly', 'adhere', '##nt', 'to', 'their', 'required', 'treatments', '.', 'conclusions', 'all', 'results', '[MASK]', 'be', 'qualified', 'by', 'the', 'fact', 'that', 'no', '[MASK]', '-', 'up', 'order', 'procedures', 'for', 'non', '##com', '##pl', '##ian', '##t', 'subjects', 'in', 'the', 'court', '-', 'ordered', '[MASK]', 'were', 'implemented', 'during', 'the', 'study', ',', 'which', 'compromised', 'the', '[MASK]', 'between', 'the', 'conditions', 'for', 'the', 'two', 'groups', ',', '[MASK]', 'that', 'persons', '[MASK]', 'a', 'history', 'of', 'violence', 'were', 'excluded', 'from', 'the', 'program', '.', '[SEP]']
{107: '##pl', 27: '.', 141: 'arrested', 5: 'the', 61: 'between', 232: '##ion', 29: 'a', 311: 'with', 243: 'providers', 70: 'interviews', 272: 'pick', 138: 'no', 264: 'must', 30: 'total', 143: 'a', 95: 'quality', 205: 'the', 218: 'results', 186: 'both', 289: 'group', 179: '-', 80: 'hospital', 10: '-', 106: '##com', 171: 'percentage', 299: 'differences', 109: ',', 17: 'established', 162: 'group', 308: 'and', 180: 'up', 73: ','}
loss:  20.945293426513672
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 65.62%
Average score: 14.56
{'##pl': '##pl', '.': '.', 'arrested': 'arrested', 'the': 'the', 'between': 'on', '##ion': '##ion', 'a': 'a', 'with': 'with', 'providers': 'providers', 'interviews': 'treatment', 'pick': 'follow', 'no': 'one', 'must': 'can', 'total': 'total', 'quality': 'quality', 'results': '[UNK]', 'both': 'both', 'group': 'group', '-': '-', 'hospital': 'their', '##com': '##com', 'percentage': 'number', 'differences': 'relationship', ',': ',', 'established': 'based', 'and': 'and', 'up': 'up'}
{'##pl': tensor(21.5950), '.': tensor(13.3293), 'arrested': tensor(11.1399), 'the': tensor(14.6894), 'between': tensor(11.1970), '##ion': tensor(25.3954), 'a': tensor(10.0907), 'with': tensor(15.9918), 'providers': tensor(14.3848), 'interviews': tensor(13.3615), 'pick': tensor(18.8544), 'no': tensor(11.8724), 'must': tensor(15.4177), 'total': tensor(11.3017), 'quality': tensor(19.8892), 'results': tensor(10.2178), 'both': tensor(13.8414), 'group': tensor(13.0312), '-': tensor(19.3671), 'hospital': tensor(11.1180), '##com': tensor(15.3856), 'percentage': tensor(10.7707), 'differences': tensor(13.6859), ',': tensor(15.2921), 'established': tensor(10.4057), 'and': tensor(13.0307), 'up': tensor(18.4801)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'study', 'evaluated', 'the', 'effectiveness', 'of', 'a', 'three', '-', 'year', 'out', '##patient', 'commitment', 'pilot', 'program', '[MASK]', 'in', '@', 'at', 'bellevue', 'hospital', 'in', 'new', 'york', 'city', '.', 'methods', 'a', 'total', '[MASK]', '@', 'participants', 'were', '[MASK]', 'assigned', ';', '@', '[MASK]', 'court', '-', 'ordered', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', 'the', 'enhanced', '-', '[MASK]', 'package', '[MASK]', '.', 'methods', '[MASK]', '@', 'and', '@', 'percent', '[MASK]', 'the', '[MASK]', 'completed', 'interviews', 'at', '[MASK]', '[MASK]', '[MASK]', ',', 'and', '@', 'months', 'after', 'hospital', 'discharge', '.', 'methods', '[MASK]', 'measures', 'included', 're', '##hos', '##pit', '##ali', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '[MASK]', '##oma', '##tology', ',', 'treatment', 'non', '##com', '##pl', '##iance', ',', 'and', 'perceived', 'level', 'of', 'coe', '##rc', '##ion', '.', 'results', 'on', 'all', '[MASK]', '[MASK]', 'measures', ',', 'no', 'statistical', '##ly', 'significant', 'differences', 'were', '[MASK]', 'between', 'the', 'two', 'groups', '.', 'results', 'no', 'subject', 'was', 'arrested', 'for', 'a', 'violent', 'crime', '.', 'results', 'eighteen', 'percent', '[MASK]', 'the', 'court', '-', 'ordered', 'group', 'and', '@', 'percent', 'of', 'the', 'control', 'group', 'were', 'arrested', '[MASK]', 'least', 'once', '.', 'results', 'the', 'percentage', 're', '##hos', '##pit', '##ali', '##zed', 'during', 'follow', '-', 'up', 'was', 'about', 'the', 'same', 'for', 'both', 'groups', '-', '@', 'percent', '[MASK]', '@', 'percent', '[MASK]', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', 'differ', 'significantly', 'in', 'the', 'total', 'number', 'of', 'days', 'hospitalized', '[MASK]', 'the', '[MASK]', '-', 'up', 'period', '.', 'results', 'participants', "'", 'perceptions', 'of', 'their', '[MASK]', 'of', 'life', 'and', 'level', 'of', 'coe', '##rc', '##ion', 'were', 'about', 'the', 'same', '.', 'results', 'from', 'the', '[MASK]', 'service', 'providers', "'", 'perspective', ',', '[MASK]', 'in', 'the', 'two', 'groups', 'were', 'similarly', 'adhere', '##nt', 'to', 'their', 'required', 'treatments', '.', 'conclusions', 'all', 'results', 'must', 'be', 'qualified', 'by', 'the', 'fact', 'that', 'no', 'pick', '[MASK]', 'up', 'order', 'procedures', 'for', 'non', '##com', '##pl', '##ian', '##t', 'subjects', 'in', 'the', '[MASK]', '-', 'ordered', 'group', 'were', 'implemented', 'during', '[MASK]', 'study', '[MASK]', 'which', 'compromised', 'the', 'differences', 'between', '[MASK]', 'conditions', 'for', 'the', 'two', 'groups', ',', 'and', 'that', '[MASK]', 'with', 'a', 'history', 'of', 'violence', 'were', 'excluded', 'from', 'the', 'program', '.', '[SEP]']
{286: 'court', 74: 'five', 301: 'the', 73: ',', 61: 'between', 211: 'during', 56: 'service', 213: 'follow', 72: 'one', 58: 'only', 247: 'patients', 310: 'persons', 194: ',', 150: 'of', 293: 'the', 17: 'established', 100: '##mpt', 84: 'outcome', 39: 'received', 295: ',', 131: 'found', 31: 'of', 224: 'quality', 191: 'and', 165: 'at', 273: '-', 35: 'randomly', 241: 'community', 66: 'of', 121: 'major', 68: 'subjects', 122: 'outcome'}
loss:  21.116485595703125
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 56.25%
Average score: 14.60
{'court': 'court', 'five': 'months', 'the': 'the', ',': ',', 'between': 'a', 'during': 'during', 'service': 'services', 'follow': 'follow', 'one': 'the', 'only': 'treatment', 'patients': 'subjects', 'persons': 'subjects', 'of': 'of', 'established': 'conducted', '##mpt': '##mpt', 'outcome': 'three', 'received': 'received', 'found': 'found', 'quality': 'quality', 'and': 'and', 'at': 'at', '-': '-', 'randomly': 'randomly', 'community': 'health', 'major': 'the', 'subjects': 'participants'}
{'court': tensor(16.5909), 'five': tensor(8.1607), 'the': tensor(14.9962), ',': tensor(15.9846), 'between': tensor(10.3937), 'during': tensor(13.8913), 'service': tensor(13.1967), 'follow': tensor(18.5563), 'one': tensor(8.1746), 'only': tensor(9.5551), 'patients': tensor(15.0231), 'persons': tensor(16.2718), 'of': tensor(15.5579), 'established': tensor(9.9041), '##mpt': tensor(23.4309), 'outcome': tensor(9.3457), 'received': tensor(17.7232), 'found': tensor(16.2132), 'quality': tensor(20.8140), 'and': tensor(15.8747), 'at': tensor(16.4485), '-': tensor(22.0016), 'randomly': tensor(17.1062), 'community': tensor(10.7178), 'major': tensor(9.3964), 'subjects': tensor(14.1710)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test02.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'study', 'evaluated', 'the', 'effectiveness', 'of', 'a', 'three', '-', 'year', 'out', '[MASK]', 'commitment', 'pilot', 'program', 'established', 'in', '@', '[MASK]', 'bellevue', 'hospital', 'in', 'new', 'york', 'city', '.', 'methods', '[MASK]', 'total', 'of', '@', 'participants', 'were', 'randomly', 'assigned', ';', '@', 'received', 'court', '-', 'ordered', 'treatment', ',', 'which', 'included', 'enhanced', 'services', ',', 'and', '@', 'received', '[MASK]', 'enhanced', '-', 'service', 'package', 'only', '.', 'methods', 'between', '@', 'and', '@', 'percent', 'of', 'the', 'subjects', '[MASK]', 'interviews', 'at', 'one', ',', 'five', ',', 'and', '@', 'months', 'after', 'hospital', 'discharge', '.', 'methods', 'outcome', 'measures', 'included', 're', '##hos', '##pit', '##ali', '##zation', ',', 'arrest', ',', 'quality', 'of', 'life', ',', 'sy', '##mpt', '##oma', '##tology', ',', 'treatment', 'non', '##com', '##pl', '##iance', ',', 'and', '[MASK]', 'level', 'of', 'coe', '[MASK]', '##ion', '.', 'results', 'on', '[MASK]', 'major', '[MASK]', 'measures', ',', 'no', 'statistical', '##ly', 'significant', 'differences', 'were', '[MASK]', '[MASK]', 'the', '[MASK]', 'groups', '.', 'results', '[MASK]', 'subject', 'was', 'arrested', '[MASK]', 'a', 'violent', 'crime', '.', 'results', 'eighteen', 'percent', 'of', '[MASK]', 'court', '-', 'ordered', 'group', 'and', '[MASK]', '[MASK]', 'of', 'the', 'control', 'group', '[MASK]', 'arrested', 'at', 'least', 'once', '.', 'results', 'the', 'percentage', 're', '##hos', '##pit', '##ali', '##zed', 'during', 'follow', '-', 'up', 'was', 'about', 'the', '[MASK]', 'for', 'both', 'groups', '-', '@', 'percent', 'and', '@', 'percent', ',', 'respectively', '.', 'results', 'the', 'groups', 'did', 'not', 'differ', 'significantly', 'in', '[MASK]', 'total', 'number', 'of', 'days', '[MASK]', 'during', 'the', 'follow', '-', 'up', 'period', '.', 'results', 'participants', "'", 'perceptions', 'of', 'their', 'quality', 'of', '[MASK]', 'and', 'level', 'of', 'coe', '##rc', '##ion', 'were', 'about', 'the', 'same', '.', 'results', 'from', 'the', 'community', 'service', 'providers', "'", 'perspective', ',', 'patients', 'in', 'the', 'two', 'groups', 'were', 'similarly', 'adhere', '##nt', 'to', '[MASK]', 'required', 'treatments', '.', 'conclusions', 'all', 'results', 'must', 'be', 'qualified', '[MASK]', 'the', 'fact', '[MASK]', 'no', 'pick', '-', '[MASK]', 'order', 'procedures', 'for', 'non', '##com', '##pl', '##ian', '##t', 'subjects', 'in', 'the', 'court', '-', 'ordered', 'group', 'were', 'implemented', 'during', 'the', '[MASK]', '[MASK]', 'which', 'compromised', 'the', 'differences', 'between', 'the', '[MASK]', 'for', 'the', 'two', 'groups', ',', '[MASK]', 'that', 'persons', 'with', 'a', 'history', 'of', '[MASK]', 'were', 'excluded', 'from', 'the', '[MASK]', '.', '[SEP]']
{13: '##patient', 163: 'were', 158: 'percent', 151: 'the', 257: 'their', 294: 'study', 134: 'two', 111: 'perceived', 120: 'all', 20: 'at', 320: 'program', 270: 'that', 295: ',', 131: 'found', 267: 'by', 122: 'outcome', 226: 'life', 274: 'up', 302: 'conditions', 210: 'hospitalized', 142: 'for', 308: 'and', 205: 'the', 53: 'the', 132: 'between', 138: 'no', 29: 'a', 69: 'completed', 315: 'violence', 184: 'same', 115: '##rc', 157: '@'}
loss:  20.543336868286133
prediction_scores:  torch.Size([1, 323, 30522])
Accuracy: 59.38%
Average score: 14.14
{'##patient': '##patient', 'were': 'were', 'percent': 'percent', 'the': 'an', 'their': 'the', 'study': 'trial', 'two': 'two', 'perceived': 'overall', 'all': 'the', 'at': '[UNK]', 'program': 'study', 'that': 'that', ',': ',', 'found': 'observed', 'by': 'for', 'outcome': 'outcome', 'life': 'life', 'up': 'up', 'conditions': 'results', 'hospitalized': 'spent', 'for': 'for', 'and': 'and', 'between': 'between', 'no': 'one', 'a': 'a', 'completed': 'completed', 'violence': 'violence', 'same': 'same', '##rc': '##rc', '@': 'one'}
{'##patient': tensor(17.3566), 'were': tensor(14.5193), 'percent': tensor(15.3761), 'the': tensor(13.1476), 'their': tensor(12.0776), 'study': tensor(13.2223), 'two': tensor(14.1050), 'perceived': tensor(10.1291), 'all': tensor(13.2134), 'at': tensor(8.1981), 'program': tensor(13.4104), 'that': tensor(16.1186), ',': tensor(11.9827), 'found': tensor(16.2924), 'by': tensor(12.0046), 'outcome': tensor(16.0960), 'life': tensor(21.5578), 'up': tensor(11.0531), 'conditions': tensor(13.0819), 'hospitalized': tensor(11.2701), 'for': tensor(14.5370), 'and': tensor(12.5561), 'between': tensor(16.4239), 'no': tensor(12.3864), 'a': tensor(13.1127), 'completed': tensor(13.2852), 'violence': tensor(11.5828), 'same': tensor(19.8335), '##rc': tensor(26.4760), '@': tensor(9.9305)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '(', '[MASK]', '##ma', '##bon', '##d', ')', 'is', 'a', 'tissue', '`', '`', 'glue', "'", "'", 'useful', 'in', '[MASK]', 'surgical', 'skin', '[MASK]', '##ision', '##s', '.', 'objective', 'we', '[MASK]', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'with', '[MASK]', '[MASK]', '##icular', 'skin', 'su', '##tures', '[MASK]', 'close', 'lap', '##aro', '##scopic', 'tr', '##oca', '##r', 'sites', '.', 'methods', 'a', 'random', '[MASK]', 'double', '-', 'armed', 'study', 'was', 'performed', 'with', '@', 'patients', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '.', 'methods', 'twenty', '-', 'nine', 'patients', 'underwent', 'sub', '##cut', '##icular', 'closure', 'with', '@', '-', '[MASK]', 'absorb', '##able', '[MASK]', '##ture', ',', 'and', 'thirty', 'patients', 'received', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'in', 'accordance', 'with', 'the', 'recommendations', 'of', 'the', '[MASK]', '(', 'et', '##hic', '##on', ';', 'somerville', '[MASK]', 'nj', ')', '[MASK]', 'methods', '[MASK]', 'number', 'of', 'su', '##tures', 'or', 'vial', '##s', 'of', 'oct', '[MASK]', '##cy', '##ano', '##ac', '##ryl', '##ate', 'used', ',', 'closure', 'times', '[MASK]', 'and', 'post', '##oper', '##ative', 'wound', '[MASK]', 'were', 'recorded', '.', 'methods', 'wounds', 'were', 'assessed', '@', 'weeks', '[MASK]', '##oper', '##ative', '##ly', 'for', 'healing', 'complications', '.', 'methods', 'closure', 'costs', 'were', 'estimated', 'using', 'published', 'operating', 'room', 'time', '[MASK]', 'hour', 'plus', 'the', 'cost', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', 'student', "'", 's', 'paired', 't', '-', 'test', 'was', 'used', 'for', '[MASK]', 'analysis', '.', 'results', 'the', 'overall', 'mean', 'time', 'required', 'for', '[MASK]', 'closure', 'using', 'oct', '##yl', '[MASK]', '##ano', '##ac', '##ryl', '##ate', 'and', 'su', '##ture', 'was', '@', 'minutes', 'and', '[MASK]', 'minutes', ',', 'respectively', '(', 'p', '<', '@', ')', '.', 'results', 'an', 'average', 'of', '@', 'packets', 'of', '[MASK]', '##ture', 'were', 'used', 'to', 'close', 'all', 'port', 'sites', 'in', 'a', 'particular', 'patient', ',', '[MASK]', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '[MASK]', 'required', 'an', 'average', 'of', '[MASK]', 'vial', '##s', 'per', '[MASK]', '.', 'results', '[MASK]', 'complications', 'consisted', 'of', 'sub', '##cut', '##icular', 'ser', '[MASK]', 'with', 'skin', 'separation', 'and', 'were', 'equally', 'common', 'in', 'the', 'two', 'groups', '.', 'results', 'the', 'overall', 'average', 'cost', 'per', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '[MASK]', 'was', '$', '@', 'us', 'dollars', ',', '[MASK]', 'the', 'cost', '[MASK]', '[MASK]', 'using', 'su', '##ture', '[MASK]', '$', '@', 'us', 'dollars', '(', 'p', '<', '[MASK]', '[MASK]', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', '[MASK]', 'effective', '.', 'conclusions', 'the', 'method', 'yields', 'cost', 'savings', 'and', 'a', 'decrease', 'in', 'operative', 'time', '[MASK]', 'more', 'than', '@', 'minutes', 'per', 'case', '.', '[SEP]']
{34: 'compared', 303: '##oma', 260: 'su', 341: 'closure', 44: 'sub', 188: 'per', 129: ',', 45: '##cut', 50: 'to', 154: ',', 28: 'inc', 99: 'su', 216: 'statistical', 283: '##ate', 10: 'der', 25: 'closing', 243: '@', 337: 'while', 274: 'while', 226: 'skin', 132: '.', 144: '##yl', 122: 'manufacturer', 353: '@', 292: 'patient', 354: ')', 160: 'problems', 170: 'post', 390: 'of', 96: '@', 63: '##ized', 345: 'was', 375: 'and', 288: '@', 330: '##ate', 134: 'the', 231: '##cy', 340: 'for', 295: 'wound'}
loss:  20.91472053527832
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 66.67%
Average score: 14.22
{'compared': 'compared', '##oma': '##ision', 'su': 'su', 'closure': 'closure', 'sub': 'sub', 'per': 'per', ',': ',', '##cut': '##cut', 'to': 'to', 'inc': 'inc', 'statistical': 'the', '##ate': '##ate', 'der': 'che', 'closing': 'making', '@': '@', 'while': 'whereas', 'skin': 'wound', '.': '.', '##yl': '##yl', 'manufacturer': 'study', 'patient': 'case', ')': ')', 'problems': 'closure', 'post': 'post', 'of': 'of', '##ized': '##ized', 'was': 'was', 'and': 'and', 'the': 'the', '##cy': '##cy', 'for': 'per', 'wound': 'the'}
{'compared': tensor(9.1436), '##oma': tensor(16.2856), 'su': tensor(21.3074), 'closure': tensor(14.4324), 'sub': tensor(13.3270), 'per': tensor(12.1845), ',': tensor(15.5231), '##cut': tensor(18.6787), 'to': tensor(12.1762), 'inc': tensor(15.6645), 'statistical': tensor(9.4386), '##ate': tensor(23.8196), 'der': tensor(7.9619), 'closing': tensor(9.2100), '@': tensor(15.1289), 'while': tensor(12.7896), 'skin': tensor(9.0183), '.': tensor(13.8097), '##yl': tensor(23.7342), 'manufacturer': tensor(11.8525), 'patient': tensor(11.9664), ')': tensor(21.0389), 'problems': tensor(11.5012), 'post': tensor(14.2249), 'of': tensor(10.9260), '##ized': tensor(15.2704), 'was': tensor(13.6987), 'and': tensor(14.4540), 'the': tensor(11.1264), '##cy': tensor(23.2808), 'for': tensor(13.8687), 'wound': tensor(8.2123)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '(', 'der', '##ma', '##bon', '##d', ')', 'is', 'a', 'tissue', '`', '`', 'glue', "'", "'", 'useful', 'in', 'closing', 'surgical', 'skin', 'inc', '[MASK]', '##s', '.', 'objective', 'we', 'compared', 'skin', 'oct', '##yl', '[MASK]', '##ano', '##ac', '##ryl', '##ate', 'with', 'sub', '##cut', '##icular', 'skin', 'su', '##tures', '[MASK]', 'close', 'lap', '##aro', '##scopic', 'tr', '##oca', '##r', 'sites', '.', 'methods', 'a', 'random', '##ized', 'double', '-', 'armed', 'study', 'was', 'performed', 'with', '@', 'patients', '[MASK]', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '.', 'methods', 'twenty', '-', 'nine', 'patients', 'underwent', '[MASK]', '##cut', '##icular', '[MASK]', 'with', '@', '-', '@', 'absorb', '##able', 'su', '##ture', ',', 'and', 'thirty', '[MASK]', '[MASK]', '[MASK]', 'with', 'oct', '##yl', '##cy', '##ano', '[MASK]', '##ryl', '##ate', 'in', 'accordance', 'with', 'the', 'recommendations', '[MASK]', 'the', '[MASK]', '(', 'et', '##hic', '[MASK]', ';', 'somerville', ',', 'nj', ')', '.', 'methods', 'the', 'number', 'of', 'su', '##tures', 'or', 'vial', '##s', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'used', ',', 'closure', 'times', ',', 'and', '[MASK]', '##oper', '##ative', 'wound', 'problems', 'were', 'recorded', '.', '[MASK]', 'wounds', 'were', 'assessed', '@', 'weeks', 'post', '##oper', '##ative', '##ly', 'for', 'healing', '[MASK]', '.', 'methods', 'closure', '[MASK]', 'were', '[MASK]', 'using', 'published', 'operating', 'room', 'time', 'per', 'hour', 'plus', 'the', '[MASK]', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', 'student', "'", 's', 'paired', 't', '-', 'test', 'was', 'used', 'for', 'statistical', 'analysis', '.', 'results', 'the', 'overall', '[MASK]', '[MASK]', 'required', 'for', 'skin', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '[MASK]', '[MASK]', '##ture', 'was', '@', 'minutes', 'and', '@', 'minutes', '[MASK]', 'respectively', '[MASK]', 'p', '<', '@', ')', '.', 'results', 'an', 'average', 'of', '@', 'packets', 'of', 'su', '##ture', 'were', 'used', 'to', 'close', 'all', 'port', 'sites', 'in', 'a', 'particular', 'patient', ',', 'while', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '[MASK]', 'an', 'average', 'of', '@', 'vial', '##s', 'per', 'patient', '[MASK]', 'results', 'wound', 'complications', 'consisted', '[MASK]', 'sub', '##cut', '##icular', 'ser', '[MASK]', 'with', 'skin', 'separation', 'and', 'were', 'equally', 'common', 'in', '[MASK]', 'two', 'groups', '.', 'results', 'the', 'overall', 'average', 'cost', '[MASK]', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'was', '$', '@', 'us', 'dollars', ',', 'while', 'the', '[MASK]', 'for', '[MASK]', 'using', 'su', '##ture', 'was', '$', '@', 'us', 'dollars', '(', 'p', '<', '@', '[MASK]', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '[MASK]', '##cy', '##ano', '##ac', '[MASK]', '##ate', 'is', '[MASK]', 'and', 'effective', '.', 'conclusions', 'the', 'method', 'yields', 'cost', 'savings', 'and', 'a', 'decrease', 'in', 'operative', 'time', '[MASK]', 'more', 'than', '@', 'minutes', 'per', '[MASK]', '.', '[SEP]']
{222: 'mean', 303: '##oma', 164: 'methods', 371: '##ryl', 341: 'closure', 192: 'cost', 180: 'costs', 176: 'complications', 293: '.', 284: 'required', 92: 'closure', 106: 'closure', 89: 'sub', 29: '##ision', 247: '(', 354: ')', 38: '##cy', 50: 'to', 236: 'and', 321: 'per', 73: 'in', 223: 'time', 312: 'the', 122: 'manufacturer', 120: 'of', 126: '##on', 390: 'of', 396: 'case', 245: ',', 156: 'post', 298: 'of', 112: '##ac', 339: 'cost', 105: 'received', 237: 'su', 182: 'estimated', 104: 'patients', 374: 'rapid', 367: '##yl'}
loss:  21.105545043945312
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 58.97%
Average score: 15.42
{'mean': 'time', '##oma': '##omy', 'methods': '[UNK]', '##ryl': '##ryl', 'closure': 'treated', 'cost': 'cost', 'costs': 'times', 'complications': 'time', '.': '.', 'required': 'required', 'sub': 'sub', '##ision': '##ision', '(': '(', ')': ')', '##cy': '##cy', 'to': 'to', 'and': 'or', 'per': 'for', 'in': 'in', 'time': 'time', 'the': 'the', 'manufacturer': 'study', 'of': 'of', '##on': '@', 'case': 'patient', ',': ',', 'post': 'post', '##ac': '##ac', 'received': 'were', 'su': 'su', 'estimated': 'assessed', 'patients': '-', 'rapid': 'safe', '##yl': '##yl'}
{'mean': tensor(9.5935), '##oma': tensor(13.1644), 'methods': tensor(9.6509), '##ryl': tensor(28.2914), 'closure': tensor(10.6100), 'cost': tensor(13.2519), 'costs': tensor(13.2855), 'complications': tensor(9.2479), '.': tensor(16.4434), 'required': tensor(13.2654), 'sub': tensor(16.4887), '##ision': tensor(23.0442), '(': tensor(19.3292), ')': tensor(24.6292), '##cy': tensor(23.5022), 'to': tensor(11.7854), 'and': tensor(13.3065), 'per': tensor(13.1147), 'in': tensor(13.2523), 'time': tensor(14.1294), 'the': tensor(14.6773), 'manufacturer': tensor(12.6765), 'of': tensor(13.0194), '##on': tensor(7.4911), 'case': tensor(12.8937), ',': tensor(14.1321), 'post': tensor(16.3152), '##ac': tensor(26.1818), 'received': tensor(10.6071), 'su': tensor(21.9617), 'estimated': tensor(13.5380), 'patients': tensor(10.1395), 'rapid': tensor(16.7037), '##yl': tensor(24.6610)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '(', 'der', '##ma', '##bon', '##d', ')', 'is', 'a', 'tissue', '`', '[MASK]', 'glue', "'", "'", '[MASK]', 'in', 'closing', '[MASK]', 'skin', 'inc', '##ision', '##s', '.', 'objective', '[MASK]', 'compared', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '[MASK]', '##ate', 'with', 'sub', '[MASK]', '##icular', 'skin', 'su', '##tures', 'to', 'close', 'lap', '[MASK]', '##scopic', 'tr', '##oca', '##r', 'sites', '.', 'methods', '[MASK]', 'random', '##ized', 'double', '-', 'armed', 'study', 'was', 'performed', 'with', '[MASK]', 'patients', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '.', 'methods', 'twenty', '-', 'nine', 'patients', 'underwent', 'sub', '##cut', '[MASK]', 'closure', 'with', '@', '-', '@', 'absorb', '##able', 'su', '##ture', ',', 'and', 'thirty', 'patients', 'received', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '[MASK]', '##ate', 'in', 'accordance', 'with', 'the', '[MASK]', 'of', 'the', '[MASK]', '(', 'et', '##hic', '##on', ';', 'somerville', '[MASK]', 'nj', ')', '.', 'methods', 'the', 'number', 'of', 'su', '##tures', 'or', 'vial', '##s', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '[MASK]', ',', '[MASK]', 'times', ',', 'and', 'post', '##oper', '##ative', 'wound', 'problems', 'were', 'recorded', '.', 'methods', '[MASK]', '[MASK]', 'assessed', '@', 'weeks', 'post', '##oper', '##ative', '##ly', 'for', 'healing', 'complications', '.', 'methods', 'closure', 'costs', 'were', 'estimated', 'using', 'published', 'operating', 'room', 'time', 'per', 'hour', 'plus', 'the', 'cost', '[MASK]', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '[MASK]', '[MASK]', '##ture', '.', 'methods', 'student', '[MASK]', 's', 'paired', 't', '-', 'test', 'was', 'used', 'for', 'statistical', 'analysis', '.', '[MASK]', 'the', 'overall', 'mean', 'time', 'required', 'for', 'skin', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'and', 'su', '##ture', '[MASK]', '@', 'minutes', 'and', '[MASK]', 'minutes', ',', 'respectively', '(', 'p', '<', '@', '[MASK]', '.', 'results', 'an', 'average', 'of', '[MASK]', 'packets', '[MASK]', '[MASK]', '##ture', 'were', 'used', 'to', 'close', 'all', '[MASK]', 'sites', 'in', 'a', 'particular', 'patient', ',', 'while', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'required', 'an', '[MASK]', 'of', '@', 'vial', '##s', 'per', 'patient', '.', 'results', 'wound', 'complications', 'consisted', 'of', 'sub', '##cut', '##icular', 'ser', '##oma', 'with', 'skin', 'separation', '[MASK]', 'were', 'equally', 'common', '[MASK]', 'the', 'two', 'groups', '.', 'results', 'the', 'overall', 'average', 'cost', 'per', '[MASK]', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'was', '$', '@', 'us', 'dollars', ',', 'while', 'the', 'cost', 'for', 'closure', 'using', 'su', '[MASK]', 'was', '$', '@', 'us', '[MASK]', '(', 'p', '<', '@', ')', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', '[MASK]', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', 'and', 'effective', '.', 'conclusions', 'the', '[MASK]', 'yields', 'cost', 'savings', 'and', 'a', 'decrease', 'in', '[MASK]', 'time', 'of', 'more', 'than', '@', 'minutes', 'per', 'case', '.', '[SEP]']
{307: 'and', 257: '@', 71: '@', 207: "'", 129: ',', 349: 'dollars', 365: 'with', 243: '@', 311: 'in', 152: 'closure', 193: 'of', 122: 'manufacturer', 388: 'operative', 201: 'or', 166: 'were', 23: 'useful', 61: 'a', 344: '##ture', 267: 'port', 19: '`', 259: 'of', 33: 'we', 53: '##aro', 239: 'was', 251: ')', 150: 'used', 322: 'closure', 119: 'recommendations', 202: 'su', 45: '##cut', 219: 'results', 26: 'surgical', 165: 'wounds', 41: '##ryl', 113: '##ryl', 286: 'average', 380: 'method', 260: 'su', 91: '##icular'}
loss:  21.311222076416016
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 64.10%
Average score: 15.39
{'and': 'and', '@': '@', "'": "'", ',': ',', 'dollars': 'dollars', 'with': 'with', 'in': 'between', 'closure': 'patient', 'of': 'of', 'manufacturer': 'study', 'operative': 'recovery', 'or': 'and', 'were': 'were', 'useful': 'used', 'a': 'a', '##ture': '##ture', 'port': 'three', '`': '`', 'we': 'study', '##aro': '##aro', 'was': 'was', ')': ')', 'used': 'used', 'recommendations': 'requirements', 'su': 'su', '##cut': '##cut', 'results': '[UNK]', 'surgical': 'the', 'wounds': 'were', '##ryl': '##ryl', 'average': 'average', 'method': 'study', '##icular': '##icular'}
{'and': tensor(12.1563), '@': tensor(16.8841), "'": tensor(16.2637), ',': tensor(13.1165), 'dollars': tensor(18.5547), 'with': tensor(13.6949), 'in': tensor(14.6398), 'closure': tensor(10.7334), 'of': tensor(11.9324), 'manufacturer': tensor(12.4894), 'operative': tensor(9.6660), 'or': tensor(11.1576), 'were': tensor(14.2800), 'useful': tensor(14.4985), 'a': tensor(10.2537), '##ture': tensor(23.9975), 'port': tensor(8.9546), '`': tensor(16.8653), 'we': tensor(11.6681), '##aro': tensor(28.1499), 'was': tensor(16.4329), ')': tensor(21.0283), 'used': tensor(9.7421), 'recommendations': tensor(10.0208), 'su': tensor(21.8787), '##cut': tensor(26.2949), 'results': tensor(11.9484), 'surgical': tensor(8.3934), 'wounds': tensor(9.6014), '##ryl': tensor(28.2241), 'average': tensor(20.6978), 'method': tensor(12.5646), '##icular': tensor(20.9850)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '[MASK]', '##ac', '##ryl', '##ate', '[MASK]', 'der', '[MASK]', '[MASK]', '##d', ')', 'is', 'a', 'tissue', '`', '`', 'glue', "'", "'", 'useful', 'in', '[MASK]', 'surgical', 'skin', '[MASK]', '##ision', '##s', '.', 'objective', 'we', 'compared', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'with', 'sub', '##cut', '[MASK]', '[MASK]', 'su', '[MASK]', 'to', 'close', 'lap', '##aro', '##scopic', 'tr', '##oca', '##r', 'sites', '.', 'methods', 'a', 'random', '##ized', 'double', '-', 'armed', 'study', 'was', 'performed', 'with', '@', 'patients', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '.', 'methods', 'twenty', '-', 'nine', 'patients', 'underwent', 'sub', '##cut', '##icular', 'closure', 'with', '@', '-', '[MASK]', 'absorb', '##able', 'su', '##ture', ',', 'and', 'thirty', 'patients', 'received', 'closure', 'with', 'oct', '##yl', '[MASK]', '##ano', '##ac', '##ryl', '##ate', 'in', 'accordance', '[MASK]', 'the', 'recommendations', 'of', '[MASK]', 'manufacturer', '(', 'et', '##hic', '##on', ';', 'somerville', ',', 'nj', ')', '.', 'methods', 'the', 'number', 'of', 'su', '##tures', 'or', 'vial', '[MASK]', 'of', 'oct', '##yl', '##cy', '##ano', '[MASK]', '##ryl', '##ate', 'used', ',', 'closure', 'times', ',', 'and', 'post', '[MASK]', '##ative', 'wound', '[MASK]', 'were', 'recorded', '.', 'methods', 'wounds', 'were', 'assessed', '@', 'weeks', 'post', '##oper', '##ative', '##ly', 'for', 'healing', 'complications', '.', 'methods', 'closure', 'costs', 'were', 'estimated', 'using', '[MASK]', 'operating', 'room', 'time', 'per', 'hour', 'plus', 'the', 'cost', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', 'student', '[MASK]', 's', 'paired', 't', '-', 'test', 'was', 'used', 'for', 'statistical', 'analysis', '.', 'results', 'the', 'overall', '[MASK]', 'time', 'required', 'for', 'skin', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'and', 'su', '##ture', 'was', '@', 'minutes', 'and', '@', 'minutes', ',', 'respectively', '(', 'p', '[MASK]', '[MASK]', '[MASK]', '.', 'results', 'an', 'average', 'of', '@', 'packets', 'of', 'su', '##ture', 'were', 'used', 'to', 'close', 'all', 'port', 'sites', 'in', 'a', '[MASK]', 'patient', '[MASK]', 'while', 'closure', 'with', '[MASK]', '##yl', '[MASK]', '##ano', '[MASK]', '[MASK]', '[MASK]', 'required', 'an', 'average', 'of', '@', 'vial', '##s', 'per', 'patient', '.', 'results', 'wound', 'complications', 'consisted', 'of', 'sub', '[MASK]', '##icular', 'ser', '##oma', 'with', '[MASK]', 'separation', 'and', 'were', 'equally', 'common', 'in', 'the', '[MASK]', 'groups', '.', 'results', 'the', 'overall', 'average', 'cost', 'per', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '[MASK]', 'was', '$', '@', '[MASK]', 'dollars', ',', 'while', 'the', 'cost', 'for', 'closure', 'using', '[MASK]', '##ture', 'was', '$', '@', 'us', 'dollars', '(', 'p', '<', '@', ')', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', 'and', 'effective', '.', 'conclusions', 'the', 'method', '[MASK]', 'cost', 'savings', 'and', '[MASK]', 'decrease', 'in', 'operative', 'time', 'of', 'more', 'than', '[MASK]', 'minutes', 'per', 'case', '.', '[SEP]']
{300: '##cut', 281: '##ac', 11: '##ma', 5: '##ano', 250: '@', 207: "'", 271: 'particular', 343: 'su', 273: ',', 49: '##tures', 279: '##cy', 277: 'oct', 12: '##bon', 334: 'us', 47: 'skin', 313: 'two', 385: 'a', 381: 'yields', 96: '@', 110: '##cy', 305: 'skin', 25: 'closing', 121: 'the', 330: '##ate', 282: '##ryl', 141: '##s', 283: '##ate', 46: '##icular', 160: 'problems', 393: '@', 249: '<', 222: 'mean', 147: '##ac', 184: 'published', 251: ')', 28: 'inc', 157: '##oper', 117: 'with', 9: '('}
loss:  21.697650909423828
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 69.23%
Average score: 16.42
{'##cut': '##cut', '##ac': '##ac', '##ma': '##mal', '##ano': '##ano', '@': '@', "'": "'", 'particular': 'single', 'su': 'su', ',': ',', '##tures': '##ture', '##cy': '##cy', 'oct': 'oct', '##bon': '##cise', 'us': 'us', 'skin': 'no', 'two': 'two', 'a': 'a', 'yields': 'showed', 'closing': 'making', 'the': 'the', '##ate': '##ate', '##ryl': '##ryl', '##s': '##s', '##icular': '##icular', 'problems': 'complications', '<': '<', 'mean': 'operative', 'published': 'the', ')': ')', 'inc': 'inc', '##oper': '##oper', 'with': 'with', '(': '('}
{'##cut': tensor(24.5924), '##ac': tensor(25.8505), '##ma': tensor(10.6669), '##ano': tensor(24.6191), '@': tensor(15.2270), "'": tensor(16.5318), 'particular': tensor(12.6582), 'su': tensor(23.7665), ',': tensor(13.5054), '##tures': tensor(21.9483), '##cy': tensor(23.5001), 'oct': tensor(15.5548), '##bon': tensor(10.1319), 'us': tensor(14.3078), 'skin': tensor(8.1829), 'two': tensor(13.1450), 'a': tensor(12.8619), 'yields': tensor(9.1956), 'closing': tensor(9.2465), 'the': tensor(12.7911), '##ate': tensor(17.0643), '##ryl': tensor(15.8069), '##s': tensor(16.9033), '##icular': tensor(20.9255), 'problems': tensor(14.0399), '<': tensor(16.8454), 'mean': tensor(12.7608), 'published': tensor(9.4803), ')': tensor(17.3054), 'inc': tensor(17.1058), '##oper': tensor(29.9760), 'with': tensor(18.0263), '(': tensor(17.4556)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test03.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', '[MASK]', 'der', '##ma', '##bon', '##d', ')', 'is', '[MASK]', 'tissue', '`', '`', 'glue', "'", '[MASK]', 'useful', 'in', 'closing', 'surgical', 'skin', 'inc', '##ision', '##s', '[MASK]', 'objective', 'we', '[MASK]', 'skin', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'with', 'sub', '[MASK]', '[MASK]', 'skin', '[MASK]', '##tures', 'to', 'close', 'lap', '##aro', '##scopic', 'tr', '##oca', '[MASK]', 'sites', '.', 'methods', 'a', 'random', '##ized', 'double', '-', 'armed', 'study', 'was', 'performed', 'with', '@', '[MASK]', 'in', 'whom', '@', 'tr', '##oca', '##r', 'sites', 'were', 'closed', '.', 'methods', '[MASK]', '[MASK]', 'nine', '[MASK]', 'underwent', 'sub', '##cut', '##icular', 'closure', 'with', '@', '-', '@', '[MASK]', '##able', 'su', '##ture', ',', 'and', 'thirty', '[MASK]', '[MASK]', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'in', 'accordance', 'with', 'the', '[MASK]', 'of', 'the', 'manufacturer', '(', 'et', '##hic', '##on', ';', 'somerville', ',', 'nj', ')', '.', 'methods', 'the', 'number', 'of', 'su', '##tures', 'or', 'vial', '##s', 'of', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'used', ',', 'closure', 'times', ',', 'and', 'post', '##oper', '##ative', 'wound', 'problems', 'were', 'recorded', '.', 'methods', 'wounds', 'were', 'assessed', '@', 'weeks', 'post', '##oper', '##ative', '##ly', 'for', 'healing', 'complications', '.', '[MASK]', 'closure', 'costs', 'were', 'estimated', 'using', 'published', 'operating', 'room', 'time', 'per', 'hour', 'plus', 'the', 'cost', 'of', '[MASK]', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'or', 'su', '##ture', '.', 'methods', 'student', "'", 's', 'paired', 't', '-', 'test', 'was', 'used', 'for', 'statistical', 'analysis', '.', 'results', '[MASK]', 'overall', 'mean', 'time', 'required', 'for', 'skin', 'closure', '[MASK]', 'oct', '##yl', '##cy', '[MASK]', '[MASK]', '##ryl', '##ate', 'and', 'su', '[MASK]', 'was', '@', 'minutes', 'and', '@', 'minutes', ',', 'respectively', '(', 'p', '<', '@', ')', '[MASK]', 'results', 'an', 'average', 'of', '@', 'packets', 'of', 'su', '##ture', 'were', 'used', 'to', 'close', 'all', 'port', 'sites', 'in', 'a', 'particular', '[MASK]', ',', 'while', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'required', 'an', 'average', 'of', '@', 'vial', '[MASK]', 'per', 'patient', '.', 'results', 'wound', 'complications', '[MASK]', 'of', 'sub', '##cut', '##icular', '[MASK]', '##oma', '[MASK]', 'skin', 'separation', 'and', 'were', 'equally', 'common', '[MASK]', 'the', 'two', 'groups', '.', '[MASK]', 'the', 'overall', '[MASK]', 'cost', 'per', 'closure', 'using', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'was', '$', '@', 'us', 'dollars', ',', 'while', 'the', 'cost', 'for', 'closure', 'using', 'su', '##ture', 'was', '$', '@', 'us', '[MASK]', '(', 'p', '[MASK]', '@', ')', '.', 'conclusions', 'lap', '##aro', '##scopic', 'port', '-', 'site', 'skin', 'closure', 'with', 'oct', '##yl', '##cy', '##ano', '##ac', '##ryl', '##ate', 'is', 'rapid', 'and', 'effective', '.', 'conclusions', 'the', '[MASK]', 'yields', 'cost', 'savings', '[MASK]', 'a', 'decrease', 'in', 'operative', '[MASK]', 'of', '[MASK]', 'than', '@', 'minutes', 'per', 'case', '.', '[SEP]']
{380: 'method', 272: 'patient', 352: '<', 105: 'received', 22: "'", 389: 'time', 319: 'average', 290: '##s', 252: '.', 297: 'consisted', 48: 'su', 97: 'absorb', 194: 'oct', 316: 'results', 57: '##r', 84: 'twenty', 311: 'in', 220: 'the', 304: 'with', 119: 'recommendations', 31: '.', 72: 'patients', 45: '##cut', 228: 'using', 384: 'and', 233: '##ac', 9: '(', 85: '-', 34: 'compared', 238: '##ture', 178: 'methods', 349: 'dollars', 391: 'more', 232: '##ano', 46: '##icular', 87: 'patients', 16: 'a', 104: 'patients', 302: 'ser'}
loss:  20.201242446899414
prediction_scores:  torch.Size([1, 399, 30522])
Accuracy: 51.28%
Average score: 14.25
{'method': 'study', 'patient': 'area', '<': '<', 'received': 'underwent', "'": '`', 'time': 'time', 'average': 'total', '##s': '##s', '.': '.', 'consisted': 'consist', 'su': 'su', 'absorb': 'implant', 'oct': 'oct', 'results': '[UNK]', '##r': '##r', 'twenty': 'total', 'in': 'between', 'the': 'the', 'with': '##tic', 'recommendations': 'requirements', 'patients': 'underwent', '##cut': '##cut', 'using': 'with', 'and': 'with', '##ac': '##ac', '(': '(', '-': ',', 'compared': 'used', '##ture': '##ture', 'methods': '[UNK]', 'dollars': 'dollars', 'more': 'more', '##ano': '##ano', '##icular': '##icular', 'a': 'a', 'ser': 'st'}
{'method': tensor(12.7762), 'patient': tensor(10.3177), '<': tensor(19.2583), 'received': tensor(11.0801), "'": tensor(13.6733), 'time': tensor(12.5205), 'average': tensor(10.5444), '##s': tensor(16.0305), '.': tensor(15.0711), 'consisted': tensor(10.6801), 'su': tensor(20.2935), 'absorb': tensor(10.6473), 'oct': tensor(15.1194), 'results': tensor(11.9996), '##r': tensor(21.7321), 'twenty': tensor(8.3622), 'in': tensor(14.7177), 'the': tensor(13.5979), 'with': tensor(9.1592), 'recommendations': tensor(12.2092), 'patients': tensor(13.5080), '##cut': tensor(19.5493), 'using': tensor(13.7991), 'and': tensor(11.5474), '##ac': tensor(23.5059), '(': tensor(16.3966), '-': tensor(9.2741), 'compared': tensor(11.0716), '##ture': tensor(21.6819), 'methods': tensor(11.2425), 'dollars': tensor(17.8992), 'more': tensor(15.6505), '##ano': tensor(20.8758), '##icular': tensor(17.1399), 'a': tensor(10.9101), 'ser': tensor(9.3038)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', '[MASK]', '[MASK]', 'associated', '[MASK]', 'left', 'vent', '##ric', '##ular', '[MASK]', '(', 'l', '##v', '##m', ')', 'in', 'insulin', '-', '[MASK]', 'individuals', '.', 'background', 'anti', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', '[MASK]', 'and', 'insulin', 'metabolism', '[MASK]', 'gi', '##m', ')', 'and', 'on', 'l', '##v', '[MASK]', '.', 'background', 'to', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '##per', '##tens', '[MASK]', 'therapy', 'on', 'l', '##v', '##m', 'are', 'associated', 'with', 'its', '[MASK]', 'on', '[MASK]', '##m', ',', 'we', 'compared', 'the', 'effects', 'of', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', '[MASK]', 'these', 'parameters', 'in', 'a', 'group', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', '[MASK]', '[MASK]', '##ives', '.', 'results', 'a', 'total', '[MASK]', '@', 'obe', '##se', ',', 'non', '##dia', '##bet', '##ic', 'hyper', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '/', '-', '@', 'years', ',', 'had', 'a', 'body', 'mass', 'index', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '@', ')', ',', '[MASK]', 'free', 'of', 'corona', '##ry', 'or', 'val', '##vu', '##lar', 'heart', 'disease', ',', 'and', 'had', 'normal', 'l', '##v', 'function', 'were', 'random', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '[MASK]', '(', 'n', '=', '@', ')', 'or', 'per', '##ind', '##op', '##ril', '(', 'n', '=', '@', ')', '.', 'results', 'echo', '##card', '[MASK]', '##graphic', 'l', '##v', '[MASK]', 'corrected', 'for', 'height', '(', 'l', '##v', '##m', '[MASK]', 'height', ')', 'and', 'gi', '##m', '[MASK]', '@', '-', 'hour', 'intra', '##ven', '[MASK]', '[MASK]', 'tolerance', 'test', ')', 'were', '[MASK]', 'after', '@', 'to', '@', 'weeks', 'of', 'wash', '##out', 'and', '@', 'months', 'of', 'treatment', '[MASK]', 'results', 'baseline', 'characteristics', 'were', 'similar', 'in', 'both', 'groups', '[MASK]', 'results', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'effectively', 'reduced', 'blood', 'pressure', '(', 'from', '@', '+', '/', '-', '@', '[MASK]', '@', '+', '/', '-', '[MASK]', 'to', '@', '[MASK]', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', 'and', 'from', '@', '+', '[MASK]', '-', '@', '/', '@', '+', '[MASK]', '-', '@', '[MASK]', '@', '+', '/', '-', '@', '/', '@', '+', '[MASK]', '-', '@', 'mm', '[MASK]', '##g', ',', '[MASK]', ',', '[MASK]', 'the', 'ate', '##no', '[MASK]', '[MASK]', 'and', 'per', '##ind', '##op', '##ril', 'groups', ';', 'p', ':', '=', '@', '[MASK]', '.', 'results', 'ate', '##no', '##lo', '##l', 'significantly', 'worsened', 'gi', '##m', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', 'mm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', ',', 'fast', '##ing', 'insulin', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '[MASK]', 'pm', '##ol', '/', 'l', ';', 'p', ':', '=', '[MASK]', ')', ',', 'and', 'most', 'other', 'relevant', 'metabolic', 'measures', '(', 'p', ':', '[MASK]', '@', 'for', 'all', ')', '.', '[SEP]']
{22: 'resistant', 8: 'with', 13: 'mass', 417: '<', 5: 'levels', 221: '##ous', 322: 'respectively', 103: 'hyper', 71: 'effects', 250: '.', 61: '##ive', 306: 'to', 328: '##lo', 329: '##l', 396: '@', 177: '##l', 197: '##io', 341: ')', 227: 'measured', 324: 'for', 150: 'were', 110: 'of', 73: 'gi', 405: '@', 215: '(', 104: '##tens', 277: '@', 209: '/', 6: 'are', 48: '##m', 272: '/', 90: 'on', 201: '##m', 222: 'glucose', 315: '/', 297: '/', 36: 'glucose', 319: 'h', 241: '.', 303: '/', 40: '(', 280: '+'}
loss:  23.044227600097656
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 83.33%
Average score: 17.08
{'resistant': 'sensitive', 'with': 'with', 'mass': 'disease', '<': '=', 'levels': 'metabolism', '##ous': '##ous', 'respectively': 'respectively', 'hyper': 'hyper', 'effects': 'effects', '.': '.', '##ive': '##ive', 'to': 'to', '##lo': '##lo', '##l': '##l', '@': '@', '##io': '##io', ')': ')', 'measured': 'performed', 'for': 'in', 'were': 'were', 'of': 'of', 'gi': 'gi', '(': '(', '##tens': '##tens', '/': '/', 'are': 'are', '##m': '##m', 'on': 'on', 'glucose': 'glucose', 'h': 'h', '+': '+'}
{'resistant': tensor(13.5047), 'with': tensor(15.6696), 'mass': tensor(12.7539), '<': tensor(15.9930), 'levels': tensor(14.2102), '##ous': tensor(22.5108), 'respectively': tensor(15.1827), 'hyper': tensor(14.6567), 'effects': tensor(14.6042), '.': tensor(14.9589), '##ive': tensor(21.6672), 'to': tensor(15.7831), '##lo': tensor(25.1761), '##l': tensor(24.2460), '@': tensor(15.7790), '##io': tensor(25.5533), ')': tensor(17.1632), 'measured': tensor(13.0315), 'for': tensor(13.3286), 'were': tensor(15.8813), 'of': tensor(16.9125), 'gi': tensor(15.7405), '(': tensor(20.1742), '##tens': tensor(20.8387), '/': tensor(19.1582), 'are': tensor(13.4651), '##m': tensor(15.2285), 'on': tensor(15.0718), 'glucose': tensor(14.2053), 'h': tensor(15.3398), '+': tensor(21.8055)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', 'levels', 'are', '[MASK]', 'with', 'left', 'vent', '##ric', '[MASK]', 'mass', '(', 'l', '##v', '##m', ')', 'in', 'insulin', '-', 'resistant', '[MASK]', '.', 'background', 'anti', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', 'and', 'insulin', 'metabolism', '(', 'gi', '##m', ')', 'and', 'on', 'l', '##v', '##m', '.', 'background', 'to', 'evaluate', 'whether', 'the', '[MASK]', '[MASK]', 'anti', '##hy', '##per', '##tens', '##ive', 'therapy', 'on', 'l', '##v', '##m', 'are', 'associated', 'with', 'its', 'effects', 'on', 'gi', '##m', ',', 'we', 'compared', 'the', 'effects', 'of', 'ate', '[MASK]', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'on', 'these', 'parameters', 'in', 'a', 'group', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', 'hyper', '##tens', '##ives', '.', 'results', 'a', 'total', 'of', '@', '[MASK]', '##se', ',', 'non', '##dia', '##bet', '##ic', '[MASK]', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '/', '-', '@', '[MASK]', ',', 'had', 'a', 'body', 'mass', 'index', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '[MASK]', ')', ',', '[MASK]', 'free', 'of', 'corona', '##ry', 'or', 'val', '##vu', '##lar', 'heart', '[MASK]', ',', 'and', 'had', 'normal', 'l', '##v', '[MASK]', 'were', 'random', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '##l', '(', 'n', '=', '@', '[MASK]', 'or', '[MASK]', '##ind', '##op', '[MASK]', '(', 'n', '=', '[MASK]', ')', '.', 'results', 'echo', '##card', '[MASK]', '##graphic', 'l', '##v', '##m', 'corrected', 'for', 'height', '[MASK]', 'l', '##v', '##m', '/', 'height', ')', '[MASK]', 'gi', '[MASK]', '[MASK]', '@', '-', 'hour', 'intra', '##ven', '##ous', '[MASK]', '[MASK]', 'test', ')', 'were', 'measured', 'after', '@', 'to', '@', 'weeks', 'of', '[MASK]', '##out', 'and', '@', 'months', '[MASK]', 'treatment', '.', 'results', 'baseline', 'characteristics', 'were', 'similar', 'in', 'both', 'groups', '.', 'results', 'ate', '##no', '##lo', '[MASK]', 'and', 'per', '##ind', '##op', '##ril', '[MASK]', 'reduced', 'blood', 'pressure', '[MASK]', 'from', '@', '+', '/', '[MASK]', '@', '[MASK]', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '[MASK]', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', 'and', 'from', '@', '+', '/', '-', '@', '[MASK]', '[MASK]', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', ',', 'respectively', ',', 'for', 'the', 'ate', '##no', '##lo', '[MASK]', 'and', 'per', '##ind', '##op', '##ril', 'groups', ';', 'p', ':', '=', '[MASK]', ')', '.', 'results', 'ate', '##no', '##lo', '##l', 'significantly', 'worsened', 'gi', '##m', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '[MASK]', '@', 'to', '@', '+', '/', '-', '@', 'mm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', ',', 'fast', '##ing', 'insulin', 'levels', '(', '[MASK]', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '[MASK]', 'pm', '##ol', '/', 'l', ';', 'p', '[MASK]', '=', '@', ')', ',', 'and', 'most', 'other', '[MASK]', 'metabolic', 'measures', '(', 'p', ':', '<', '@', 'for', 'all', ')', '[MASK]', '[SEP]']
{112: 'obe', 234: 'wash', 205: '(', 329: '##l', 184: 'per', 160: 'disease', 7: 'associated', 130: 'years', 272: '/', 12: '##ular', 422: '.', 411: 'relevant', 191: '@', 23: 'individuals', 167: 'function', 340: '@', 119: 'hyper', 187: '##ril', 55: 'effects', 239: 'of', 222: 'glucose', 56: 'of', 182: ')', 396: '@', 301: '@', 147: '@', 82: '##no', 261: 'effectively', 223: 'tolerance', 270: '-', 386: '@', 214: '##m', 403: ':', 212: 'and', 300: '/', 197: '##io', 362: '-', 215: '(', 283: '@', 255: '##l', 150: 'were', 265: '('}
loss:  23.231101989746094
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 83.33%
Average score: 17.14
{'obe': 'obe', 'wash': 'wash', '(': '(', '##l': '##l', 'per': 'per', 'disease': 'failure', 'associated': 'associated', 'years': 'years', '/': '/', '##ular': '##ular', '.': '.', 'relevant': 'important', '@': '@', 'individuals': 'patients', 'function': '##m', 'hyper': 'hyper', '##ril': '##ril', 'effects': 'effects', 'of': 'of', 'glucose': 'glucose', ')': ')', '##no': '##no', 'effectively': 'significantly', 'tolerance': '[UNK]', '-': '-', '##m': '##m', ':': ':', 'and': 'and', '##io': '##io', 'were': 'were'}
{'obe': tensor(23.7241), 'wash': tensor(11.9232), '(': tensor(11.6530), '##l': tensor(23.8214), 'per': tensor(18.1243), 'disease': tensor(14.5928), 'associated': tensor(16.3839), 'years': tensor(15.8060), '/': tensor(11.8016), '##ular': tensor(21.1289), '.': tensor(18.4000), 'relevant': tensor(9.4827), '@': tensor(15.9494), 'individuals': tensor(14.5320), 'function': tensor(17.2465), 'hyper': tensor(22.5018), '##ril': tensor(26.7584), 'effects': tensor(16.1218), 'of': tensor(13.6242), 'glucose': tensor(7.5542), ')': tensor(21.1190), '##no': tensor(29.2124), 'effectively': tensor(16.1049), 'tolerance': tensor(8.3437), '-': tensor(20.5507), '##m': tensor(17.0581), ':': tensor(17.6579), 'and': tensor(12.0945), '##io': tensor(25.3639), 'were': tensor(15.5985)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', '[MASK]', 'are', 'associated', 'with', 'left', 'vent', '##ric', '##ular', 'mass', '(', 'l', '##v', '##m', ')', 'in', 'insulin', '-', '[MASK]', 'individuals', '.', 'background', 'anti', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', 'and', 'insulin', 'metabolism', '(', '[MASK]', '##m', ')', 'and', 'on', 'l', '##v', '##m', '.', 'background', '[MASK]', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '[MASK]', '##tens', '##ive', '[MASK]', 'on', 'l', '[MASK]', '##m', 'are', '[MASK]', 'with', 'its', 'effects', 'on', 'gi', '##m', ',', 'we', '[MASK]', 'the', 'effects', 'of', 'ate', '##no', '[MASK]', '##l', 'and', 'per', '##ind', '##op', '##ril', 'on', 'these', '[MASK]', '[MASK]', 'a', 'group', 'of', 'insulin', '-', 'resistant', ',', 'obe', '##se', 'hyper', '##tens', '##ives', '.', 'results', 'a', 'total', 'of', '@', 'obe', '##se', ',', '[MASK]', '##dia', '##bet', '##ic', 'hyper', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '[MASK]', '-', '@', 'years', '[MASK]', '[MASK]', 'a', 'body', 'mass', 'index', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '@', ')', ',', 'were', 'free', 'of', 'corona', '[MASK]', 'or', '[MASK]', '##vu', '##lar', 'heart', 'disease', ',', 'and', 'had', 'normal', 'l', '##v', 'function', '[MASK]', 'random', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '##l', '(', 'n', '=', '@', ')', 'or', '[MASK]', '##ind', '##op', '##ril', '(', 'n', '=', '@', ')', '.', 'results', 'echo', '[MASK]', '[MASK]', '##graphic', 'l', '##v', '##m', 'corrected', 'for', 'height', '(', 'l', '##v', '##m', '/', 'height', '[MASK]', 'and', 'gi', '##m', '(', '@', '-', '[MASK]', 'intra', '##ven', '##ous', 'glucose', 'tolerance', 'test', ')', 'were', 'measured', 'after', '@', 'to', '@', 'weeks', 'of', 'wash', '##out', 'and', '@', 'months', 'of', 'treatment', '.', 'results', 'baseline', 'characteristics', 'were', 'similar', 'in', 'both', 'groups', '.', 'results', 'ate', '##no', '##lo', '##l', '[MASK]', 'per', '##ind', '##op', '[MASK]', 'effectively', 'reduced', '[MASK]', 'pressure', '(', 'from', '@', '+', '/', '-', '[MASK]', '[MASK]', '[MASK]', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', '[MASK]', 'from', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', ',', 'respectively', ',', '[MASK]', 'the', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '[MASK]', '[MASK]', 'groups', ';', 'p', ':', '=', '@', ')', '.', 'results', '[MASK]', '##no', '##lo', '##l', 'significantly', 'worsened', 'gi', '##m', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '[MASK]', '-', '@', 'mm', '##ol', '/', 'l', ';', 'p', ':', '[MASK]', '@', ')', ',', 'fast', '[MASK]', 'insulin', 'levels', '(', '@', '+', '/', '-', '[MASK]', 'to', '@', '+', '/', '-', '@', 'pm', '##ol', '/', 'l', ';', 'p', '[MASK]', '=', '@', ')', ',', 'and', 'most', 'other', 'relevant', 'metabolic', 'measures', '[MASK]', 'p', '[MASK]', '<', '@', 'for', 'all', ')', '.', '[SEP]']
{154: '##ry', 131: ',', 65: '##v', 115: 'non', 197: '##io', 263: 'blood', 293: 'and', 127: '/', 184: 'per', 5: 'levels', 390: '@', 68: 'associated', 51: 'to', 92: 'parameters', 256: 'and', 377: '=', 367: '/', 196: '##card', 218: 'hour', 414: '(', 93: 'in', 156: 'val', 403: ':', 59: '##per', 382: '##ing', 344: 'ate', 324: 'for', 211: ')', 168: 'were', 333: '##op', 271: '@', 83: '##lo', 273: '@', 22: 'resistant', 77: 'compared', 62: 'therapy', 260: '##ril', 41: 'gi', 334: '##ril', 272: '/', 416: ':', 132: 'had'}
loss:  22.94333267211914
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 76.19%
Average score: 16.49
{'##ry': '##ry', ',': ',', '##v': '##v', 'non': 'non', '##io': 'radio', 'blood': 'blood', 'and': 'and', '/': '/', 'per': 'per', 'levels': 'metabolism', '@': '@', 'associated': 'associated', 'to': 'studies', 'parameters': 'effects', '=': '=', '##card': '##mo', 'hour': 'item', '(': '(', 'in': 'in', 'val': 'val', ':': ':', '##per': '##per', '##ing': '##ing', 'ate': 'ate', 'for': 'in', ')': ')', 'were': 'were', '##op': '##op', '##lo': '##lo', 'resistant': 'sensitive', 'compared': 'compare', 'therapy': 'drugs', '##ril': '##ril', 'gi': 'gi', 'had': 'had'}
{'##ry': tensor(20.4561), ',': tensor(13.1553), '##v': tensor(21.8311), 'non': tensor(16.5385), '##io': tensor(12.8799), 'blood': tensor(14.0710), 'and': tensor(13.9248), '/': tensor(14.7712), 'per': tensor(18.5169), 'levels': tensor(13.8439), '@': tensor(15.4569), 'associated': tensor(15.1341), 'to': tensor(11.4715), 'parameters': tensor(11.4099), '=': tensor(17.2190), '##card': tensor(8.6628), 'hour': tensor(9.4958), '(': tensor(17.0030), 'in': tensor(13.6679), 'val': tensor(16.6424), ':': tensor(17.0599), '##per': tensor(27.3619), '##ing': tensor(18.4650), 'ate': tensor(20.7197), 'for': tensor(15.4369), ')': tensor(17.5612), 'were': tensor(12.6684), '##op': tensor(25.8763), '##lo': tensor(28.9389), 'resistant': tensor(13.5310), 'compared': tensor(14.6182), 'therapy': tensor(15.6677), '##ril': tensor(23.0769), 'gi': tensor(15.7035), 'had': tensor(14.3463)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', '[MASK]', 'are', 'associated', 'with', 'left', 'vent', '##ric', '##ular', 'mass', '(', 'l', '[MASK]', '##m', ')', 'in', 'insulin', '-', 'resistant', '[MASK]', '.', '[MASK]', 'anti', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', 'effects', 'on', 'glucose', '[MASK]', 'insulin', '[MASK]', '(', 'gi', '##m', ')', '[MASK]', 'on', 'l', '##v', '##m', '.', 'background', 'to', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '##per', '##tens', '##ive', 'therapy', 'on', 'l', '##v', '##m', 'are', 'associated', 'with', '[MASK]', 'effects', 'on', '[MASK]', '##m', ',', 'we', 'compared', 'the', 'effects', 'of', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'on', 'these', 'parameters', 'in', 'a', 'group', '[MASK]', 'insulin', '-', 'resistant', ',', 'obe', '[MASK]', 'hyper', '[MASK]', '##ives', '.', 'results', 'a', 'total', 'of', '@', 'obe', '##se', ',', 'non', '##dia', '##bet', '##ic', 'hyper', '##tens', '##ives', 'who', 'were', 'aged', '@', '+', '/', '-', '@', 'years', ',', 'had', 'a', 'body', '[MASK]', 'index', 'of', '@', '+', '/', '[MASK]', '@', 'kg', '[MASK]', '[MASK]', '(', '@', '[MASK]', ',', 'were', 'free', '[MASK]', 'corona', '##ry', 'or', 'val', '##vu', '##lar', '[MASK]', 'disease', '[MASK]', 'and', 'had', 'normal', 'l', '##v', 'function', 'were', 'random', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '##l', '(', 'n', '=', '@', ')', 'or', 'per', '##ind', '##op', '##ril', '(', 'n', '=', '[MASK]', ')', '.', 'results', 'echo', '##card', '##io', '##graphic', 'l', '##v', '##m', 'corrected', 'for', 'height', '(', 'l', '##v', '##m', '/', 'height', ')', 'and', 'gi', '##m', '(', '@', '-', 'hour', 'intra', '##ven', '##ous', 'glucose', 'tolerance', 'test', ')', 'were', 'measured', 'after', '@', 'to', '@', 'weeks', 'of', '[MASK]', '##out', 'and', '@', 'months', 'of', '[MASK]', '[MASK]', 'results', 'baseline', 'characteristics', 'were', 'similar', 'in', 'both', 'groups', '.', 'results', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'effectively', 'reduced', 'blood', 'pressure', '(', 'from', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'to', '@', '+', '[MASK]', '-', '[MASK]', '/', '@', '+', '[MASK]', '-', '@', 'mm', 'h', '##g', 'and', 'from', '@', '+', '/', '-', '[MASK]', '/', '@', '+', '/', '-', '@', '[MASK]', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', 'h', '##g', ',', 'respectively', '[MASK]', 'for', 'the', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'groups', ';', 'p', ':', '[MASK]', '@', ')', '.', 'results', 'ate', '##no', '##lo', '[MASK]', 'significantly', 'worsened', 'gi', '##m', 'parameters', ',', 'fast', '##ing', '[MASK]', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', 'mm', '##ol', '/', 'l', '[MASK]', 'p', ':', '=', '@', ')', ',', 'fast', '##ing', 'insulin', '[MASK]', '[MASK]', '@', '[MASK]', '/', '[MASK]', '@', 'to', '@', '+', '[MASK]', '[MASK]', '@', 'pm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', ')', ',', 'and', 'most', 'other', 'relevant', '[MASK]', 'measures', '(', 'p', ':', '[MASK]', '@', 'for', 'all', ')', '.', '[SEP]']
{39: 'metabolism', 299: '@', 144: '/', 159: 'heart', 16: '##v', 141: '-', 152: 'of', 281: '/', 374: ';', 347: '##l', 148: ')', 339: '=', 241: '.', 287: '/', 417: '<', 240: 'treatment', 385: '(', 191: '@', 23: 'individuals', 387: '+', 25: 'background', 104: '##tens', 44: 'and', 96: 'of', 323: ',', 5: 'levels', 356: 'glucose', 283: '@', 37: 'and', 135: 'mass', 161: ',', 234: 'wash', 73: 'gi', 70: 'its', 145: 'm', 384: 'levels', 412: 'metabolic', 389: '-', 395: '-', 102: '##se', 306: 'to', 394: '/'}
loss:  22.38833236694336
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 76.19%
Average score: 15.53
{'metabolism': 'tolerance', '@': '@', '/': '/', 'heart': 'heart', '##v': '##v', '-': '-', 'of': 'of', ';': ';', '##l': '##l', ')': ')', '=': '=', '.': '.', '<': '=', 'treatment': 'treatment', '(': '(', 'individuals': 'patients', '+': '+', 'background': 'two', '##tens': '##tens', 'and': 'and', ',': ',', 'levels': 'levels', 'glucose': 'insulin', 'mass': 'mass', 'wash': 'wash', 'gi': 'gi', 'its': 'similar', 'm': '[UNK]', 'metabolic': 'glucose', '##se': '##se', 'to': 'to'}
{'metabolism': tensor(14.0061), '@': tensor(15.4124), '/': tensor(18.8512), 'heart': tensor(13.4918), '##v': tensor(22.5327), '-': tensor(13.4062), 'of': tensor(15.0225), ';': tensor(18.0045), '##l': tensor(22.1972), ')': tensor(16.5239), '=': tensor(16.8028), '.': tensor(12.5828), '<': tensor(15.4042), 'treatment': tensor(12.3660), '(': tensor(12.8924), 'individuals': tensor(14.8456), '+': tensor(20.3019), 'background': tensor(10.1692), '##tens': tensor(24.2322), 'and': tensor(12.7454), ',': tensor(16.0472), 'levels': tensor(13.8678), 'glucose': tensor(16.1899), 'mass': tensor(16.9643), 'wash': tensor(11.2416), 'gi': tensor(15.9788), 'its': tensor(9.6690), 'm': tensor(9.2389), 'metabolic': tensor(10.5959), '##se': tensor(23.5100), 'to': tensor(16.4269)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test04.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'background', 'glucose', 'and', 'insulin', 'levels', 'are', 'associated', 'with', 'left', 'vent', '[MASK]', '##ular', 'mass', '(', 'l', '##v', '##m', '[MASK]', 'in', 'insulin', '-', 'resistant', 'individuals', '.', 'background', 'anti', '##hy', '##per', '##tens', '##ive', 'drugs', 'have', 'different', '[MASK]', 'on', 'glucose', 'and', 'insulin', 'metabolism', '(', 'gi', '##m', ')', 'and', 'on', 'l', '##v', '##m', '.', 'background', 'to', 'evaluate', 'whether', 'the', 'effects', 'of', 'anti', '##hy', '##per', '[MASK]', '##ive', 'therapy', 'on', 'l', '##v', '##m', 'are', '[MASK]', 'with', 'its', '[MASK]', '[MASK]', 'gi', '##m', ',', '[MASK]', 'compared', 'the', 'effects', 'of', 'ate', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '[MASK]', 'on', '[MASK]', '[MASK]', 'in', 'a', 'group', 'of', 'insulin', '-', '[MASK]', ',', 'obe', '##se', 'hyper', '##tens', '[MASK]', '.', 'results', 'a', 'total', 'of', '@', 'obe', '##se', '[MASK]', 'non', '[MASK]', '##bet', '##ic', 'hyper', '##tens', '##ives', '[MASK]', 'were', 'aged', '@', '+', '/', '-', '@', 'years', ',', 'had', 'a', 'body', 'mass', 'index', 'of', '@', '+', '/', '-', '@', 'kg', '/', 'm', '(', '@', ')', ',', 'were', '[MASK]', '[MASK]', 'corona', '##ry', 'or', 'val', '##vu', '##lar', 'heart', 'disease', ',', 'and', 'had', '[MASK]', 'l', '##v', 'function', 'were', 'random', '##ized', 'to', 'treatment', 'with', 'ate', '##no', '##lo', '##l', '(', 'n', '=', '@', ')', 'or', '[MASK]', '##ind', '##op', '##ril', '(', 'n', '=', '@', ')', '.', 'results', 'echo', '##card', '##io', '##graphic', 'l', '##v', '##m', 'corrected', 'for', 'height', '(', '[MASK]', '##v', '##m', '/', '[MASK]', ')', 'and', 'gi', '##m', '(', '@', '-', 'hour', 'intra', '##ven', '##ous', 'glucose', 'tolerance', 'test', ')', 'were', 'measured', 'after', '@', 'to', '@', 'weeks', 'of', 'wash', '##out', 'and', '@', 'months', 'of', 'treatment', '.', 'results', 'baseline', 'characteristics', 'were', 'similar', 'in', '[MASK]', '[MASK]', '.', 'results', '[MASK]', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'effectively', 'reduced', 'blood', 'pressure', '(', 'from', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'to', '@', '[MASK]', '/', '-', '@', '/', '@', '+', '/', '-', '@', 'mm', '[MASK]', '##g', 'and', 'from', '@', '+', '/', '[MASK]', '@', '[MASK]', '@', '+', '/', '-', '@', '[MASK]', '@', '+', '/', '-', '@', '/', '@', '+', '/', '-', '@', '[MASK]', '[MASK]', '[MASK]', ',', 'respectively', ',', 'for', 'the', '[MASK]', '##no', '##lo', '##l', 'and', 'per', '##ind', '##op', '##ril', 'groups', ';', 'p', ':', '=', '@', ')', '.', 'results', 'ate', '##no', '##lo', '##l', 'significantly', 'worsened', '[MASK]', '[MASK]', 'parameters', ',', 'fast', '##ing', 'glucose', 'levels', '(', '@', '+', '/', '-', '@', 'to', '@', '+', '/', '-', '@', 'mm', '[MASK]', '/', 'l', ';', 'p', '[MASK]', '=', '@', ')', ',', 'fast', '##ing', 'insulin', 'levels', '(', '[MASK]', '+', '/', '-', '@', 'to', '@', '+', '[MASK]', '-', '@', 'pm', '##ol', '/', 'l', ';', 'p', ':', '=', '@', '[MASK]', ',', 'and', 'most', 'other', 'relevant', 'metabolic', 'measures', '(', 'p', '[MASK]', '<', '@', 'for', 'all', ')', '.', '[SEP]']
{298: '-', 406: ')', 34: 'effects', 18: ')', 249: 'groups', 306: 'to', 252: 'ate', 116: '##dia', 416: ':', 71: 'effects', 291: 'h', 152: 'of', 280: '+', 351: '##m', 114: ',', 318: 'mm', 11: '##ric', 300: '/', 326: 'ate', 210: 'height', 89: '##ril', 320: '##g', 91: 'these', 68: 'associated', 394: '/', 164: 'normal', 206: 'l', 386: '@', 184: 'per', 76: 'we', 376: ':', 371: '##ol', 72: 'on', 350: 'gi', 319: 'h', 92: 'parameters', 99: 'resistant', 105: '##ives', 151: 'free', 248: 'both', 60: '##tens', 122: 'who'}
loss:  22.150230407714844
prediction_scores:  torch.Size([1, 424, 30522])
Accuracy: 71.43%
Average score: 15.43
{'-': '-', ')': ')', 'effects': 'effects', 'groups': 'groups', 'to': 'to', 'ate': 'ate', '##dia': '##dia', ':': ':', 'h': '##ol', 'of': 'with', '+': '+', '##m': 'metabolic', ',': ',', 'mm': 'mm', '##ric': '##ric', '/': '/', 'height': 'm', '##ril': '##ril', '##g': '##ol', 'these': 'glucose', 'associated': 'associated', 'normal': 'impaired', 'l': 'l', '@': '@', 'per': 'per', 'we': 'we', '##ol': '##ol', 'on': 'on', 'gi': 'the', 'parameters': 'metabolism', 'resistant': 'resistant', '##ives': '##ives', 'free': 'associated', 'both': 'both', '##tens': '##tens', 'who': 'who'}
{'-': tensor(19.8501), ')': tensor(18.9834), 'effects': tensor(8.1604), 'groups': tensor(13.6086), 'to': tensor(15.4339), 'ate': tensor(20.6985), '##dia': tensor(20.5995), ':': tensor(16.5660), 'h': tensor(10.1819), 'of': tensor(13.1470), '+': tensor(21.4166), '##m': tensor(9.1213), ',': tensor(14.2234), 'mm': tensor(11.2831), '##ric': tensor(25.2103), '/': tensor(21.0216), 'height': tensor(12.3002), '##ril': tensor(27.6452), '##g': tensor(11.0478), 'these': tensor(12.0927), 'associated': tensor(14.9360), 'normal': tensor(9.6674), 'l': tensor(12.9438), '@': tensor(14.6322), 'per': tensor(17.9932), 'we': tensor(13.7638), '##ol': tensor(21.5758), 'on': tensor(9.0802), 'gi': tensor(7.7856), 'parameters': tensor(11.3451), 'resistant': tensor(13.2922), '##ives': tensor(20.2933), 'free': tensor(8.7063), 'both': tensor(11.0112), '##tens': tensor(29.5086), 'who': tensor(16.5316)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', '[MASK]', 'of', 'the', '[MASK]', 'was', '[MASK]', 'assess', '[MASK]', 'pri', '##ming', 'to', 'emotion', '[MASK]', 'none', '##mot', '##ion', 'cue', 'words', '[MASK]', 'a', 'novel', '[MASK]', 'of', 'association', '##al', 'breadth', 'for', 'participants', 'who', 'either', 'took', 'rapid', 'eye', 'movement', '(', 're', '##m', ')', 'or', 'non', '[MASK]', '##pid', 'eye', 'movement', '(', 'nr', '##em', ')', 'nap', '##s', 'or', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', '[MASK]', '[MASK]', 'to', 're', '##m', 'sleep', 'consolidation', 'and', 're', '##m', 'sleep', 'in', '[MASK]', '##ia', 'effects', '.', 'methods', '[MASK]', 'association', '##al', 'breadth', '[MASK]', 'was', 'applied', '[MASK]', 'both', 'a', 'pri', '##ming', 'condition', ',', 'where', 'cue', '-', 'words', 'were', '[MASK]', '[MASK]', 'be', 'memo', '##rized', 'prior', '[MASK]', 'sleep', '[MASK]', 'prime', '##d', ')', ',', 'and', 'a', 'non', '##pr', '[MASK]', '##ng', 'condition', ',', 'where', 'cue', 'words', 'were', '[MASK]', 'memo', '##rized', '(', 'non', '##pr', '##ime', '##d', ')', '.', 'methods', 'cue', 'words', 'were', 'either', 'emotional', '[MASK]', 'positive', ',', 'negative', ')', 'or', 'none', '##mot', '##ional', '.', '[MASK]', 'participants', 'were', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', 'a', 'sleep', 'condition', ',', 'which', 'was', 'subsequently', 'split', 'into', 'nr', '##em', 'or', 're', '##m', 'groups', 'depending', 'on', 'stage', 'at', '[MASK]', '.', 'methods', 'hospital', '-', 'based', 'sleep', 'laboratory', '[MASK]', 'methods', 'fifty', '-', 'eight', 'healthy', 'participants', '(', '@', 'male', ')', 'ages', '@', 'to', '@', 'y', '(', 'mage', '=', '@', '@', 'y', ')', '.', 'results', 'the', 're', '##m', 'group', 'scored', 'higher', 'than', 'the', 'nr', '##em', 'or', 'wake', 'groups', 'on', 'prime', '[MASK]', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', '[MASK]', 'was', 'stronger', 'for', 'positive', 'than', 'for', 'negative', 'cue', 'words', '.', 'results', 'however', ',', 're', '##m', 'time', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', 'of', '[MASK]', 'pri', '[MASK]', '.', 'results', 'pri', '##ming', 'occurred', 'for', 're', '##m', 'awakening', '##s', 'but', 'not', 'for', 'nr', '##em', 'awakening', '##s', ',', 'even', 'when', 'the', 'latter', 'sleep', 'episodes', 'contained', 'some', 're', '##m', 'sleep', '.', 'conclusions', 'association', '##al', 'breadth', '[MASK]', 'be', 'selective', '##ly', 'consolidated', 'during', 're', '##m', 'sleep', 'for', 'stimuli', 'that', 'have', 'been', 'tagged', 'as', 'important', '[MASK]', 'future', 'memory', 'retrieval', '.', 'conclusions', 'that', 'pri', '##ming', 'decreased', 'with', '[MASK]', '[MASK]', 'time', 'and', 'was', 'higher', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', '[MASK]', 'two', '[MASK]', '##pl', '##ana', '##tory', 're', '##m', 'sleep', 'processes', ':', '[MASK]', '[MASK]', 'sleep', 'consolidation', 'serving', 'emotional', 'down', '##re', '##gul', '##ation', 'and', '[MASK]', '##m', 'sleep', 'in', '##ert', '##ia', '.', '[SEP]']
{148: 'methods', 82: 'task', 3: 'goal', 356: 're', 228: '##d', 24: 'measure', 319: 'for', 138: '(', 105: '(', 331: '##m', 347: 'ex', 122: 'not', 21: 'using', 302: 'may', 367: 're', 345: 'with', 85: 'in', 265: 'emotional', 241: 'effect', 97: 'signaled', 180: 'awakening', 78: 'the', 103: 'to', 267: '##ming', 8: 'to', 10: 'semantic', 15: 'and', 6: 'study', 330: 're', 98: 'to', 188: '.', 43: '##ra', 357: '##m', 61: 'pri', 62: '##ming', 114: '##imi', 73: '##ert'}
loss:  19.957061767578125
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 56.76%
Average score: 13.05
{'methods': 'all', 'task': 'analysis', 'goal': 'aim', 're': '[UNK]', '##d': 'words', 'measure': 'measure', 'for': 'for', '(': '(', '##m': '##m', 'ex': 'ex', 'not': 'not', 'using': ',', 'may': 'can', 'with': 'with', 'in': 'to', 'emotional': 'emotional', 'effect': 'effect', 'signaled': 'required', 'awakening': 'time', 'the': 'of', 'to': 'to', '##ming': 'words', 'semantic': 'whether', 'and': 'and', 'study': 'study', '.': '.', '##ra': '##tro', 'pri': 'cue', '##imi': '##ime', '##ert': '##ert'}
{'methods': tensor(9.4993), 'task': tensor(9.9369), 'goal': tensor(14.7262), 're': tensor(7.4364), '##d': tensor(11.9231), 'measure': tensor(11.9800), 'for': tensor(13.7060), '(': tensor(14.5078), '##m': tensor(16.3460), 'ex': tensor(19.3989), 'not': tensor(11.9816), 'using': tensor(9.5457), 'may': tensor(15.7406), 'with': tensor(13.6405), 'in': tensor(13.7217), 'emotional': tensor(12.8817), 'effect': tensor(12.4641), 'signaled': tensor(11.3447), 'awakening': tensor(10.5171), 'the': tensor(9.0011), 'to': tensor(15.6061), '##ming': tensor(11.5425), 'semantic': tensor(10.5263), 'and': tensor(8.8396), 'study': tensor(14.2919), '.': tensor(9.4087), '##ra': tensor(14.0361), 'pri': tensor(9.3084), '##imi': tensor(24.4488), '##ert': tensor(23.2815)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', 'of', 'the', 'study', '[MASK]', '[MASK]', 'assess', 'semantic', 'pri', '##ming', 'to', 'emotion', 'and', 'none', '##mot', '##ion', 'cue', 'words', '[MASK]', 'a', '[MASK]', 'measure', 'of', 'association', '##al', '[MASK]', 'for', 'participants', 'who', 'either', 'took', 'rapid', 'eye', '[MASK]', '(', 're', '##m', ')', 'or', '[MASK]', '##ra', '##pid', 'eye', 'movement', '(', 'nr', '[MASK]', ')', 'nap', '##s', 'or', '[MASK]', 'remained', 'awake', ';', 'assess', 'relation', 'of', '[MASK]', '##ming', 'to', 're', '##m', '[MASK]', 'consolidation', 'and', 're', '##m', '[MASK]', 'in', '##ert', '##ia', 'effects', '.', 'methods', 'the', 'association', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', 'pri', '##ming', 'condition', ',', 'where', 'cue', '-', 'words', 'were', 'signaled', 'to', 'be', 'memo', '##rized', 'prior', 'to', 'sleep', '(', 'prime', '##d', ')', ',', 'and', 'a', 'non', '##pr', '##imi', '##ng', 'condition', ',', 'where', 'cue', '[MASK]', 'were', 'not', 'memo', '##rized', '(', 'non', '##pr', '##ime', '[MASK]', ')', '.', '[MASK]', '[MASK]', 'words', 'were', '[MASK]', 'emotional', '(', 'positive', ',', 'negative', ')', 'or', 'none', '[MASK]', '##ional', '.', 'methods', 'participants', 'were', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', '[MASK]', '[MASK]', 'condition', ',', 'which', 'was', 'subsequently', 'split', 'into', 'nr', '##em', 'or', 're', '##m', '[MASK]', 'depending', 'on', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', 'based', '[MASK]', 'laboratory', '.', 'methods', 'fifty', '-', 'eight', 'healthy', '[MASK]', '(', '@', 'male', ')', 'ages', '@', 'to', '@', 'y', '(', 'mage', '=', '@', '@', 'y', ')', '[MASK]', 'results', 'the', 're', '##m', 'group', '[MASK]', 'higher', 'than', 'the', 'nr', '##em', 'or', 'wake', 'groups', 'on', 'prime', '##d', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', 'effect', 'was', 'stronger', 'for', 'positive', 'than', 'for', 'negative', '[MASK]', 'words', '.', 'results', 'however', ',', 're', '##m', '[MASK]', 'and', 'percent', 'correlated', 'negatively', 'with', '[MASK]', 'of', 'emotional', 'pri', '##ming', '[MASK]', 'results', 'pri', '##ming', 'occurred', '[MASK]', 're', '##m', 'awakening', '##s', 'but', 'not', 'for', 'nr', '##em', 'awakening', '##s', ',', 'even', 'when', 'the', 'latter', 'sleep', 'episodes', 'contained', 'some', 're', '##m', 'sleep', '.', 'conclusions', 'association', '##al', 'breadth', 'may', 'be', 'selective', '##ly', 'consolidated', 'during', 're', '##m', 'sleep', 'for', 'stimuli', 'that', 'have', 'been', 'tagged', 'as', 'important', 'for', 'future', 'memory', 'retrieval', '.', 'conclusions', 'that', 'pri', '##ming', 'decreased', 'with', 're', '##m', 'time', 'and', 'was', '[MASK]', 'only', 'for', 're', '[MASK]', 'sleep', 'awakening', '##s', 'is', '[MASK]', 'with', 'two', 'ex', '##pl', '##ana', '##tory', 're', '##m', 'sleep', 'processes', ':', 're', '##m', '[MASK]', '[MASK]', 'serving', 'emotional', 'down', '##re', '##gul', '##ation', 'and', 're', '[MASK]', 'sleep', 'in', '##ert', '[MASK]', '.', '[SEP]']
{359: 'consolidation', 120: 'words', 132: 'methods', 21: 'using', 42: 'non', 372: '##ia', 186: 'sleep', 175: 'groups', 217: 'scored', 129: '##d', 211: '.', 133: 'cue', 263: 'degree', 54: 'who', 136: 'either', 368: '##m', 344: 'consistent', 8: 'to', 66: 'sleep', 249: 'cue', 358: 'sleep', 161: 'a', 61: 'pri', 268: '.', 257: 'time', 23: 'novel', 194: 'participants', 36: 'movement', 7: 'was', 145: '##mot', 162: 'sleep', 71: 'sleep', 339: '##m', 335: 'higher', 49: '##em', 273: 'for', 28: 'breadth'}
loss:  19.780250549316406
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 51.35%
Average score: 14.14
{'consolidation': '-', 'words': 'words', 'methods': '[UNK]', 'using': 'as', 'non': 'the', '##ia': '##ia', 'sleep': 'sleep', 'groups': ',', 'scored': 'was', '##d': '##d', '.': '.', 'cue': 'cue', 'degree': 'that', 'who': 'who', 'either': 'either', '##m': '##m', 'consistent': 'associated', 'to': ':', 'a': 'nr', 'pri': 'pri', 'time': 'time', 'novel': 'standard', 'participants': 'volunteers', 'movement': 'movement', 'was': 'was', '##mot': '##mot', 'higher': 'used', '##em': '##em', 'for': 'during', 'breadth': 'depth'}
{'consolidation': tensor(9.5465), 'words': tensor(17.6339), 'methods': tensor(10.1798), 'using': tensor(11.6650), 'non': tensor(11.0709), '##ia': tensor(19.0879), 'sleep': tensor(15.9420), 'groups': tensor(11.8239), 'scored': tensor(14.0254), '##d': tensor(19.9361), '.': tensor(12.3812), 'cue': tensor(14.2700), 'degree': tensor(10.6369), 'who': tensor(11.3489), 'either': tensor(12.4655), '##m': tensor(19.9842), 'consistent': tensor(14.1431), 'to': tensor(13.8142), 'a': tensor(7.5837), 'pri': tensor(20.4272), 'time': tensor(10.2634), 'novel': tensor(9.8625), 'participants': tensor(12.7801), 'movement': tensor(17.1869), 'was': tensor(14.7600), '##mot': tensor(23.2446), 'higher': tensor(11.1692), '##em': tensor(20.9797), 'for': tensor(13.4109), 'breadth': tensor(12.6479)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', 'of', 'the', 'study', 'was', 'to', 'assess', 'semantic', 'pri', '##ming', 'to', '[MASK]', 'and', 'none', '##mot', '##ion', 'cue', 'words', 'using', 'a', 'novel', 'measure', 'of', 'association', '##al', 'breadth', '[MASK]', 'participants', 'who', 'either', 'took', 'rapid', 'eye', 'movement', '(', 're', '##m', ')', 'or', 'non', '##ra', '##pid', 'eye', 'movement', '(', 'nr', '##em', ')', 'nap', '##s', 'or', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', '[MASK]', '##ming', 'to', 're', '##m', 'sleep', 'consolidation', 'and', 're', '##m', 'sleep', 'in', '##ert', '##ia', 'effects', '.', 'methods', 'the', 'association', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', '[MASK]', '##ming', 'condition', '[MASK]', 'where', 'cue', '[MASK]', 'words', 'were', 'signaled', 'to', 'be', 'memo', '##rized', 'prior', 'to', 'sleep', '(', '[MASK]', '[MASK]', ')', ',', 'and', 'a', 'non', '##pr', '##imi', '##ng', 'condition', ',', 'where', 'cue', 'words', 'were', '[MASK]', 'memo', '##rized', '(', 'non', '##pr', '##ime', '##d', ')', '.', 'methods', 'cue', 'words', 'were', 'either', 'emotional', '(', 'positive', ',', '[MASK]', ')', 'or', 'none', '##mot', '##ional', '.', 'methods', 'participants', '[MASK]', 'randomly', 'assigned', 'to', 'either', '[MASK]', 'awake', '[MASK]', 'wake', ')', '[MASK]', 'a', 'sleep', '[MASK]', ',', 'which', 'was', 'subsequently', '[MASK]', '[MASK]', 'nr', '##em', 'or', 're', '##m', 'groups', 'depending', 'on', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', 'based', 'sleep', 'laboratory', '.', 'methods', 'fifty', '-', 'eight', 'healthy', 'participants', '(', '@', 'male', '[MASK]', 'ages', '@', 'to', '@', 'y', '(', 'mage', '=', '@', '@', 'y', ')', '[MASK]', 'results', 'the', 're', '##m', 'group', 'scored', '[MASK]', 'than', 'the', 'nr', '##em', '[MASK]', 'wake', 'groups', 'on', 'prime', '##d', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', 'effect', 'was', 'stronger', 'for', 'positive', 'than', 'for', 'negative', 'cue', 'words', '.', 'results', '[MASK]', ',', 're', '##m', 'time', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', '[MASK]', 'emotional', 'pri', '##ming', '.', 'results', 'pri', '##ming', 'occurred', 'for', 're', '[MASK]', 'awakening', '##s', 'but', 'not', 'for', 'nr', '[MASK]', 'awakening', '##s', ',', 'even', '[MASK]', 'the', 'latter', 'sleep', 'episodes', 'contained', 'some', '[MASK]', '##m', 'sleep', '.', '[MASK]', 'association', '##al', 'breadth', 'may', '[MASK]', 'selective', '##ly', 'consolidated', 'during', 're', '[MASK]', 'sleep', 'for', 'stimuli', 'that', 'have', 'been', 'tagged', 'as', 'important', 'for', '[MASK]', 'memory', 'retrieval', '.', 'conclusions', 'that', 'pri', '##ming', 'decreased', 'with', 're', '##m', 'time', 'and', '[MASK]', '[MASK]', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', '[MASK]', 'ex', '##pl', '[MASK]', '##tory', 're', '##m', 'sleep', 'processes', ':', 're', '##m', '[MASK]', 'consolidation', 'serving', 'emotional', 'down', '##re', '##gul', '##ation', 'and', 're', '##m', 'sleep', 'in', '[MASK]', '##ia', '.', '[SEP]']
{253: 'however', 303: 'be', 223: 'or', 168: 'split', 334: 'was', 346: 'two', 358: 'sleep', 169: 'into', 198: ')', 264: 'of', 122: 'not', 287: 'when', 94: '-', 349: '##ana', 141: 'negative', 275: '##m', 282: '##em', 335: 'higher', 294: 're', 320: 'future', 163: 'condition', 157: '(', 218: 'higher', 107: '##d', 88: 'pri', 160: 'or', 29: 'for', 155: 'an', 106: 'prime', 14: 'emotion', 61: 'pri', 309: '##m', 371: '##ert', 150: 'were', 91: ',', 211: '.', 298: 'conclusions'}
loss:  20.161052703857422
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 51.35%
Average score: 13.33
{'however': 'were', 'be': 'be', 'or': 'or', 'split': 'divided', 'was': 'was', 'two': 'two', 'sleep': 'sleep', 'into': 'into', ')': ',', 'of': 'of', 'not': 'not', 'when': 'if', '-': 'cue', '##ana': '##ora', 'negative': 'sleep', '##m': '##m', '##em': '##em', 'higher': 'better', 're': 're', 'future': 'verbal', 'condition': 'group', '(': '(', '##d': '##m', 'pri': 'pri', 'for': 'in', 'an': 'stay', 'prime': '[UNK]', 'emotion': 'verbal', '##ert': '##ert', 'were': 'were', ',': ',', '.': '.', 'conclusions': '[UNK]'}
{'however': tensor(9.1827), 'be': tensor(15.6682), 'or': tensor(12.9307), 'split': tensor(13.0619), 'was': tensor(9.1408), 'two': tensor(10.7305), 'sleep': tensor(14.5349), 'into': tensor(12.2601), ')': tensor(11.8086), 'of': tensor(14.3693), 'not': tensor(12.5108), 'when': tensor(14.0929), '-': tensor(9.5128), '##ana': tensor(22.6375), 'negative': tensor(10.4053), '##m': tensor(20.1828), '##em': tensor(19.7769), 'higher': tensor(14.9604), 're': tensor(15.9359), 'future': tensor(7.4853), 'condition': tensor(10.4335), '(': tensor(13.5140), '##d': tensor(9.5968), 'pri': tensor(19.7089), 'for': tensor(10.7046), 'an': tensor(9.7384), 'prime': tensor(7.3685), 'emotion': tensor(9.4584), '##ert': tensor(23.0156), 'were': tensor(17.2879), ',': tensor(17.0603), '.': tensor(12.0504), 'conclusions': tensor(8.8897)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', 'of', 'the', 'study', 'was', '[MASK]', 'assess', 'semantic', 'pri', '##ming', 'to', 'emotion', 'and', 'none', '[MASK]', '##ion', 'cue', 'words', 'using', 'a', 'novel', 'measure', 'of', 'association', '[MASK]', 'breadth', '[MASK]', 'participants', 'who', 'either', 'took', 'rapid', 'eye', 'movement', '(', 're', '##m', ')', '[MASK]', 'non', '##ra', '##pid', 'eye', 'movement', '(', 'nr', '##em', ')', '[MASK]', '##s', 'or', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', 'pri', '##ming', 'to', 're', '##m', 'sleep', 'consolidation', 'and', '[MASK]', '##m', '[MASK]', 'in', '##ert', '[MASK]', 'effects', '.', 'methods', 'the', '[MASK]', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', 'pri', '##ming', 'condition', ',', 'where', 'cue', '-', 'words', 'were', 'signaled', 'to', 'be', 'memo', '##rized', 'prior', 'to', 'sleep', '(', 'prime', '##d', ')', ',', 'and', 'a', 'non', '##pr', '##imi', '##ng', 'condition', ',', 'where', 'cue', 'words', 'were', 'not', 'memo', '##rized', '(', '[MASK]', '##pr', '##ime', '##d', ')', '.', 'methods', 'cue', 'words', 'were', 'either', 'emotional', '(', 'positive', ',', 'negative', ')', '[MASK]', 'none', '##mot', '[MASK]', '[MASK]', 'methods', 'participants', 'were', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', 'a', 'sleep', 'condition', ',', 'which', 'was', 'subsequently', 'split', 'into', 'nr', '##em', 'or', 're', '##m', '[MASK]', 'depending', '[MASK]', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', 'based', '[MASK]', 'laboratory', '[MASK]', 'methods', 'fifty', '-', 'eight', 'healthy', 'participants', '(', '[MASK]', 'male', ')', 'ages', '@', 'to', '@', 'y', '(', 'mage', '=', '@', '@', 'y', ')', '[MASK]', 'results', '[MASK]', 're', '##m', 'group', 'scored', 'higher', '[MASK]', 'the', 'nr', '##em', '[MASK]', 'wake', 'groups', 'on', 'prime', '##d', ',', 'but', 'not', 'non', '##pr', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', 'effect', '[MASK]', 'stronger', 'for', 'positive', 'than', '[MASK]', 'negative', 'cue', 'words', '.', 'results', 'however', ',', 're', '##m', 'time', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', 'of', 'emotional', 'pri', '[MASK]', '.', 'results', 'pri', '##ming', 'occurred', '[MASK]', 're', '##m', 'awakening', '##s', 'but', 'not', 'for', 'nr', '##em', 'awakening', '##s', ',', 'even', 'when', 'the', 'latter', 'sleep', 'episodes', 'contained', 'some', 're', '##m', '[MASK]', '.', 'conclusions', 'association', '##al', 'breadth', 'may', 'be', 'selective', '##ly', '[MASK]', 'during', '[MASK]', '##m', 'sleep', 'for', 'stimuli', 'that', 'have', 'been', 'tagged', 'as', 'important', 'for', 'future', 'memory', 'retrieval', '.', 'conclusions', 'that', 'pri', '##ming', 'decreased', 'with', 're', '##m', 'time', 'and', 'was', 'higher', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', 'two', 'ex', '##pl', '##ana', '##tory', 're', '##m', '[MASK]', '[MASK]', ':', 're', '[MASK]', '[MASK]', '[MASK]', 'serving', '[MASK]', 'down', '##re', '##gul', '##ation', 'and', '[MASK]', '##m', 'sleep', 'in', '##ert', '##ia', '.', '[SEP]']
{273: 'for', 306: 'consolidated', 29: 'for', 211: '.', 308: 're', 79: 'association', 213: 'the', 146: '##ional', 41: 'or', 27: '##al', 126: 'non', 143: 'or', 219: 'than', 361: 'emotional', 247: 'for', 147: '.', 354: 'processes', 242: 'was', 357: '##m', 71: 'sleep', 196: '@', 267: '##ming', 358: 'sleep', 175: 'groups', 353: 'sleep', 296: 'sleep', 51: 'nap', 367: 're', 74: '##ia', 186: 'sleep', 223: 'or', 17: '##mot', 188: '.', 359: 'consolidation', 177: 'on', 8: 'to', 69: 're'}
loss:  20.495759963989258
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 67.57%
Average score: 14.32
{'for': 'for', 'consolidated': 'used', '.': 'study', 're': 're', 'association': 'association', 'the': 'the', '##ional': '##ion', 'or': 'and', '##al': '##al', 'non': 'non', 'than': 'than', 'emotional': 'memory', 'processes': 'effects', 'was': 'was', '##m': '##m', 'sleep': 'clinical', '@': '@', '##ming': '##ming', 'groups': ',', 'nap': 'awakening', '##ia': '##ia', '##mot': '##mot', 'consolidation': ',', 'on': 'on', 'to': 'to'}
{'for': tensor(12.1203), 'consolidated': tensor(12.5282), '.': tensor(8.4885), 're': tensor(15.2732), 'association': tensor(17.3297), 'the': tensor(11.1415), '##ional': tensor(17.8864), 'or': tensor(13.2955), '##al': tensor(21.2239), 'non': tensor(15.2282), 'than': tensor(15.3894), 'emotional': tensor(7.5765), 'processes': tensor(12.2414), 'was': tensor(15.8000), '##m': tensor(17.5046), 'sleep': tensor(7.7018), '@': tensor(12.2589), '##ming': tensor(23.3952), 'groups': tensor(10.7151), 'nap': tensor(14.0139), '##ia': tensor(14.7426), '##mot': tensor(24.4258), 'consolidation': tensor(6.7409), 'on': tensor(14.3184), 'to': tensor(16.7826)}
================================================================================
File: /Users/michaelbenitah/Documents/UdeM/COMP550/Project/tests/test05.txt
Masking 10.00% of the words
Using fine-tuned model
--------------------------------------------------------------------------------
['[CLS]', 'objective', 'the', 'goal', 'of', 'the', '[MASK]', 'was', 'to', '[MASK]', 'semantic', 'pri', '##ming', 'to', 'emotion', 'and', 'none', '##mot', '##ion', 'cue', 'words', 'using', 'a', 'novel', 'measure', '[MASK]', 'association', '##al', 'breadth', '[MASK]', 'participants', 'who', 'either', '[MASK]', 'rapid', 'eye', 'movement', '(', 're', '[MASK]', ')', 'or', 'non', '##ra', '##pid', 'eye', 'movement', '(', 'nr', '##em', ')', 'nap', '##s', 'or', 'who', 'remained', 'awake', ';', 'assess', 'relation', 'of', 'pri', '##ming', 'to', 're', '##m', 'sleep', 'consolidation', 'and', 're', '##m', 'sleep', 'in', '[MASK]', '##ia', 'effects', '.', 'methods', 'the', 'association', '##al', 'breadth', 'task', 'was', 'applied', 'in', 'both', 'a', 'pri', '##ming', 'condition', ',', 'where', 'cue', '-', 'words', 'were', '[MASK]', 'to', 'be', 'memo', '##rized', 'prior', '[MASK]', 'sleep', '(', 'prime', '##d', ')', ',', 'and', 'a', 'non', '##pr', '##imi', '##ng', 'condition', ',', 'where', 'cue', 'words', 'were', '[MASK]', 'memo', '##rized', '(', 'non', '##pr', '##ime', '##d', ')', '.', 'methods', 'cue', 'words', 'were', 'either', 'emotional', '(', 'positive', ',', 'negative', ')', 'or', 'none', '##mot', '[MASK]', '.', 'methods', 'participants', 'were', 'randomly', 'assigned', 'to', 'either', 'an', 'awake', '(', 'wake', ')', 'or', 'a', 'sleep', 'condition', ',', 'which', 'was', 'subsequently', 'split', 'into', 'nr', '[MASK]', 'or', '[MASK]', '##m', 'groups', 'depending', 'on', 'stage', 'at', 'awakening', '.', 'methods', 'hospital', '-', 'based', 'sleep', 'laboratory', '.', 'methods', 'fifty', '-', 'eight', 'healthy', 'participants', '(', '@', '[MASK]', ')', 'ages', '@', 'to', '@', '[MASK]', '(', '[MASK]', '=', '@', '@', 'y', ')', '.', '[MASK]', 'the', 're', '##m', '[MASK]', '[MASK]', 'higher', 'than', 'the', 'nr', '##em', 'or', 'wake', 'groups', 'on', 'prime', '##d', ',', 'but', 'not', 'non', '[MASK]', '##ime', '##d', 'emotional', 'cue', 'words', ';', 'the', '[MASK]', 'was', 'stronger', 'for', 'positive', 'than', 'for', 'negative', 'cue', 'words', '.', 'results', 'however', ',', 're', '##m', 'time', 'and', 'percent', 'correlated', 'negatively', 'with', 'degree', 'of', '[MASK]', 'pri', '##ming', '.', 'results', 'pri', '##ming', 'occurred', 'for', 're', '##m', 'awakening', '##s', 'but', 'not', 'for', 'nr', '##em', 'awakening', '##s', '[MASK]', 'even', 'when', 'the', '[MASK]', 'sleep', 'episodes', 'contained', 'some', 're', '##m', 'sleep', '.', 'conclusions', 'association', '##al', '[MASK]', 'may', 'be', '[MASK]', '##ly', 'consolidated', '[MASK]', 're', '##m', '[MASK]', 'for', 'stimuli', 'that', 'have', 'been', 'tagged', '[MASK]', '[MASK]', 'for', 'future', '[MASK]', 'retrieval', '.', 'conclusions', 'that', '[MASK]', '##ming', 'decreased', '[MASK]', 're', '##m', 'time', 'and', 'was', '[MASK]', 'only', 'for', 're', '##m', 'sleep', 'awakening', '##s', 'is', 'consistent', 'with', 'two', 'ex', '##pl', '##ana', '##tory', 're', '##m', 'sleep', 'processes', ':', 're', '##m', 'sleep', 'consolidation', 'serving', 'emotional', 'down', '[MASK]', '[MASK]', '##ation', 'and', 're', '##m', 'sleep', '[MASK]', '##ert', '##ia', '.', '[SEP]']
{318: 'important', 317: 'as', 217: 'scored', 363: '##re', 103: 'to', 39: '##m', 173: 're', 73: '##ert', 197: 'male', 205: 'mage', 29: 'for', 304: 'selective', 289: 'latter', 203: 'y', 122: 'not', 171: '##em', 216: 'group', 329: 'with', 9: 'assess', 33: 'took', 233: '##pr', 301: 'breadth', 307: 'during', 241: 'effect', 285: ',', 364: '##gul', 25: 'of', 335: 'higher', 97: 'signaled', 212: 'results', 321: 'memory', 146: '##ional', 6: 'study', 310: 'sleep', 326: 'pri', 370: 'in', 265: 'emotional'}
loss:  19.569000244140625
prediction_scores:  torch.Size([1, 375, 30522])
Accuracy: 48.65%
Average score: 13.77
{'important': 'coded', 'as': 'as', 'scored': 'was', '##re': '##com', 'to': 'to', '##m': '##m', 're': 're', '##ert': '##ert', 'male': '%', 'mage': 'n', 'for': '.', 'selective': 'experimental', 'latter': 'early', 'y': 'years', 'not': 'not', '##em': '##em', 'group': 'group', 'with': 'semantic', 'assess': 'apply', 'took': 'had', '##pr': '##pr', 'breadth': 'breadth', 'during': 'in', 'effect': 'effect', ',': ',', '##gul': '##fl', 'of': 'of', 'higher': 'used', 'signaled': 'required', 'results': '[UNK]', 'memory': 'memory', '##ional': '##ion', 'study': 'study', 'sleep': 'sleep', 'pri': 'pri', 'in': 'in', 'emotional': 'semantic'}
{'important': tensor(8.7388), 'as': tensor(9.7262), 'scored': tensor(14.0169), '##re': tensor(10.2340), 'to': tensor(15.2155), '##m': tensor(21.6891), 're': tensor(14.2617), '##ert': tensor(20.9605), 'male': tensor(10.0059), 'mage': tensor(13.6851), 'for': tensor(10.1533), 'selective': tensor(12.1517), 'latter': tensor(9.0009), 'y': tensor(14.4315), 'not': tensor(12.5405), '##em': tensor(21.4608), 'group': tensor(12.3198), 'with': tensor(10.8551), 'assess': tensor(12.9170), 'took': tensor(12.4293), '##pr': tensor(26.2920), 'breadth': tensor(10.5127), 'during': tensor(10.2429), 'effect': tensor(12.9325), ',': tensor(15.1655), '##gul': tensor(15.2011), 'of': tensor(12.7149), 'higher': tensor(10.4642), 'signaled': tensor(11.3933), 'results': tensor(11.3650), 'memory': tensor(11.4253), '##ional': tensor(18.2425), 'study': tensor(13.7167), 'sleep': tensor(11.4746), 'pri': tensor(17.9496), 'in': tensor(18.9523), 'emotional': tensor(14.7173)}
